{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import initializers, regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Embedding, RNN, LSTM, LSTMCell, Dense, Dropout, Concatenate\n",
    "from keras.layers import TimeDistributed, Bidirectional, Lambda, Layer\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.core import Reshape\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure gpu is available\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import embedding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pretrained GloVe embeddings unpacked\n",
    "\n",
    "file = 'glove.6B.300d.txt'\n",
    "embed_dim = 300\n",
    "\n",
    "w2idx = {}\n",
    "w2vec = {}\n",
    "\n",
    "with open(file) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        line = [part.strip() for part in line.split()]\n",
    "        word = line[0]\n",
    "        vec = np.asarray(line[1 : embed_dim + 1], dtype='float32')\n",
    "        \n",
    "        w2idx[word] = idx\n",
    "        w2vec[word] = vec\n",
    "        \n",
    "# include empty character for padding - put last\n",
    "w2idx[''] = len(w2idx)\n",
    "w2vec[''] = np.zeros(embed_dim)\n",
    "\n",
    "# create embedding matrix\n",
    "embeddings = np.zeros((len(w2idx), embed_dim))\n",
    "\n",
    "for word, idx in w2idx.items():\n",
    "    embeddings[idx] = np.array(w2vec[word])\n",
    "    \n",
    "# save\n",
    "with open('glv_embed_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "    \n",
    "with open('glv_w2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(w2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)\n",
    "    \n",
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "pad = len(w2idx) - 1\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not</td>\n",
       "      <td>don't</td>\n",
       "      <td>I do not know what to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not</td>\n",
       "      <td>won't</td>\n",
       "      <td>The girl will not go to bed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>will not</td>\n",
       "      <td>won't</td>\n",
       "      <td>He will not come tomorrow night.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would not</td>\n",
       "      <td>wouldn't</td>\n",
       "      <td>They would not want you to do that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can not</td>\n",
       "      <td>can't</td>\n",
       "      <td>We can not believe that this happened.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Original Replacement                                Sentence\n",
       "0     do not       don't              I do not know what to say.\n",
       "1   will not       won't            The girl will not go to bed.\n",
       "2   will not       won't        He will not come tomorrow night.\n",
       "3  would not    wouldn't     They would not want you to do that.\n",
       "4    can not       can't  We can not believe that this happened."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder dataset\n",
    "\n",
    "df = pd.DataFrame({'Sentence': [\"I do not know what to say.\", \n",
    "                                \"The girl will not go to bed.\",\n",
    "                               \"He will not come tomorrow night.\",\n",
    "                               \"They would not want you to do that.\",\n",
    "                               \"We can not believe that this happened.\",\n",
    "                               \"I could not handle the truth.\"], \n",
    "                  'Original': [\"do not\", \"will not\", \"will not\", \"would not\", \"can not\", \"could not\"],\n",
    "                  'Replacement': [\"don't\", \"won't\", \"won't\", \"wouldn't\", \"can't\", \"couldn't\"]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imagine that you have just written what you be...</td>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are ready to get it off your plate and sen...</td>\n",
       "      <td>You are</td>\n",
       "      <td>You 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before you hit the publish button , are you po...</td>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After all , you have probably worked hard to c...</td>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maybe you are already asking yourself some of ...</td>\n",
       "      <td>you are</td>\n",
       "      <td>you 're</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Original Replacement\n",
       "0  Imagine that you have just written what you be...  you have     you 've\n",
       "1  You are ready to get it off your plate and sen...   You are     You 're\n",
       "2  Before you hit the publish button , are you po...  you have     you 've\n",
       "3  After all , you have probably worked hard to c...  you have     you 've\n",
       "4  Maybe you are already asking yourself some of ...   you are     you 're"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/Acrolinx Blog Posts/acrolinx_blog_annotated_df.pkl')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "# NOTE: there is word lowering in this because the pretrained word vectors, GloVe, only include\n",
    "# lowercase tokens\n",
    "\n",
    "def preprocess(df):\n",
    "    x_token = []\n",
    "    y_idx_start = []\n",
    "    y_idx_end = []\n",
    "    y_repl = []\n",
    "    x_orig = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        \n",
    "        # Converting sentence strings to lists of indices.\n",
    "        # Adding BOS (\"\\t\") and EOS (\"\\n\") markers to all.\n",
    "        \n",
    "        sent = word_tokenize(row['Sentence'])\n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        #sent = ['\\t'] + sent + ['\\n']\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            #else:\n",
    "            #    sent_indices.append(pad) # This adds padding instead of unknown. Fix?         \n",
    "        if len(sent_indices) == 0:\n",
    "            x_token.append(np.nan)\n",
    "            y_idx_start.append(np.nan)\n",
    "            y_idx_end.append(np.nan)\n",
    "            y_repl.append(np.nan)\n",
    "            x_orig.append(np.nan)\n",
    "            print('Empty sentence: ' + row['Sentence'])\n",
    "            continue\n",
    "        x_token.append(sent_indices)\n",
    "        \n",
    "        # Finding original segment locations in sentence.\n",
    "        \n",
    "        orig = word_tokenize(row['Original'])\n",
    "        orig_indices = []\n",
    "        for word in orig:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                orig_indices.append(w2idx[word])\n",
    "            #else:\n",
    "            #    orig_indices.append(pad) # This adds padding instead of unknown. Fix?         \n",
    "        if len(orig_indices) == 0:    \n",
    "            y_idx_start.append(np.nan)\n",
    "            y_idx_end.append(np.nan)\n",
    "            y_repl.append(np.nan)\n",
    "            x_orig.append(np.nan)\n",
    "            print('Empty fragment: ' + row['Original'])\n",
    "            continue\n",
    "        x_orig.append(orig_indices)\n",
    "                \n",
    "        # take indices and find the 1st occurrence of the slice in the whole sentence\n",
    "        starts = [i for i, x in enumerate(sent_indices) if x == orig_indices[0]]\n",
    "        y_s = np.nan\n",
    "        y_e = np.nan\n",
    "        for potential_start in starts:\n",
    "            potential_slice = sent_indices[potential_start : potential_start + len(orig_indices)]\n",
    "            if (potential_slice == np.array(orig_indices)).all():\n",
    "                y_s = potential_start\n",
    "                y_e = potential_start + len(orig_indices) + 1\n",
    "                break\n",
    "        if np.isnan(y_s) or np.isnan(y_e):\n",
    "            print('Original not found in sentence.')\n",
    "            print(row['Sentence'])\n",
    "            print(row['Original'])\n",
    "        y_idx_start.append(y_s)\n",
    "        y_idx_end.append(y_e)\n",
    "                \n",
    "        # Tokenize, put through w2idx, add BOS/EOS markers to replacement text.\n",
    "        \n",
    "        repl = word_tokenize(row['Replacement'])\n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to these\n",
    "        # this, the replacement/target text, will be used in the decoder step of training only\n",
    "        repl = ['\\t'] + repl + ['\\n']\n",
    "        repl_indices = []\n",
    "        for word in repl:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                repl_indices.append(w2idx[word])\n",
    "            #else:\n",
    "            #    repl_indices.append(pad) # This adds padding instead of unknown. Fix?\n",
    "        y_repl.append(repl_indices)\n",
    "                \n",
    "    df['x_token'] = x_token\n",
    "    df['y_idx_start'] = y_idx_start\n",
    "    df['y_idx_end'] = y_idx_end\n",
    "    df['y_repl'] = y_repl\n",
    "    df['x_orig'] = x_orig\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e1a663add34cecbbd6b2241005566f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4848), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original not found in sentence.\n",
      "Now you have seen all of the problem words that we have collectedd .\n",
      "that we have collected\n",
      "Original not found in sentence.\n",
      "Yet the separation of technical content creation makes it difficultr to ensure consistency , both across all technical output and compared with a company 's other branded content .\n",
      "makes it difficult\n",
      "Original not found in sentence.\n",
      "It does not mean… We 're rigid or uptight .\n",
      "It does not mean\n",
      "Empty fragment: Acrolinx\n",
      "Original not found in sentence.\n",
      "It is a great event and one that you should definitely check out if you have not't before ( by the way , you can still register for it by clicking here ) .\n",
      "have not\n",
      "Original not found in sentence.\n",
      "Thmay be conference is all about being smarter with your content — whether you 're a marketer or in tech docs — and following the lead of pioneering companies such as Google , IBM , and Cisco Systems .\n",
      "This\n",
      "Original not found in sentence.\n",
      "Thmay be conference is all about being smarter with your content — whether you 're a marketer or in tech docs — and following the lead of pioneering companies such as Google , IBM , and Cisco Systems .\n",
      "may be\n",
      "Original not found in sentence.\n",
      "Considering that Americans eat over ten billion doughnut every year ( that 's 31 donuts per person if you 're wondering ) , it 's a food that many of us seem to be familiarr with .\n",
      "familiar\n",
      "Original not found in sentence.\n",
      "`` Content Connections is a great event because it not only packs a real punch in terms of ideas , takeaways , and insight , it 's alvery so convenient , '' continues Bredenkamp .\n",
      "very\n",
      "Original not found in sentence.\n",
      "That is because that websites finally gave us a place to put all of the collateral we had been creating about our companies ' products and services .\n",
      "that we\n",
      "Original not found in sentence.\n",
      "You will get a sense of achievement , and it is often easierr to edit what is there than to start creating from scratch .\n",
      "easier\n",
      "Original not found in sentence.\n",
      "This handy rethereforeurce gathers all of the most established style guides for you , so you can choose the best one for your brand of writing .\n",
      "therefore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>x_token</th>\n",
       "      <th>y_idx_start</th>\n",
       "      <th>y_idx_end</th>\n",
       "      <th>y_repl</th>\n",
       "      <th>x_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imagine that you have just written what you be...</td>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "      <td>[4779, 12, 81, 33, 120, 982, 102, 81, 733, 14,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[400001, 81, 462, 400002]</td>\n",
       "      <td>[81, 33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are ready to get it off your plate and sen...</td>\n",
       "      <td>You are</td>\n",
       "      <td>You 're</td>\n",
       "      <td>[81, 32, 1188, 4, 169, 20, 138, 392, 4364, 5, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[400001, 81, 267, 400002]</td>\n",
       "      <td>[81, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before you hit the publish button , are you po...</td>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "      <td>[106, 81, 416, 0, 6231, 6910, 1, 32, 81, 1335,...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>[400001, 81, 462, 400002]</td>\n",
       "      <td>[81, 33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>After all , you have probably worked hard to c...</td>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "      <td>[49, 64, 1, 81, 33, 965, 762, 605, 4, 1210, 12...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[400001, 81, 462, 400002]</td>\n",
       "      <td>[81, 33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maybe you are already asking yourself some of ...</td>\n",
       "      <td>you are</td>\n",
       "      <td>you 're</td>\n",
       "      <td>[1881, 81, 32, 411, 2619, 4961, 77, 3, 101, 1,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[400001, 81, 267, 400002]</td>\n",
       "      <td>[81, 32]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Original Replacement  \\\n",
       "0  Imagine that you have just written what you be...  you have     you 've   \n",
       "1  You are ready to get it off your plate and sen...   You are     You 're   \n",
       "2  Before you hit the publish button , are you po...  you have     you 've   \n",
       "3  After all , you have probably worked hard to c...  you have     you 've   \n",
       "4  Maybe you are already asking yourself some of ...   you are     you 're   \n",
       "\n",
       "                                             x_token  y_idx_start  y_idx_end  \\\n",
       "0  [4779, 12, 81, 33, 120, 982, 102, 81, 733, 14,...          2.0        5.0   \n",
       "1  [81, 32, 1188, 4, 169, 20, 138, 392, 4364, 5, ...          0.0        3.0   \n",
       "2  [106, 81, 416, 0, 6231, 6910, 1, 32, 81, 1335,...         11.0       14.0   \n",
       "3  [49, 64, 1, 81, 33, 965, 762, 605, 4, 1210, 12...          3.0        6.0   \n",
       "4  [1881, 81, 32, 411, 2619, 4961, 77, 3, 101, 1,...          1.0        4.0   \n",
       "\n",
       "                      y_repl    x_orig  \n",
       "0  [400001, 81, 462, 400002]  [81, 33]  \n",
       "1  [400001, 81, 267, 400002]  [81, 32]  \n",
       "2  [400001, 81, 462, 400002]  [81, 33]  \n",
       "3  [400001, 81, 462, 400002]  [81, 33]  \n",
       "4  [400001, 81, 267, 400002]  [81, 32]  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4848"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4836"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-29c5e3ba0815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_idx_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_idx_start'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_idx_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y_idx_end'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'int64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0my_repl_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_repl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# extract data to arrays from df, add PRE-padding\n",
    "\n",
    "X = pad_sequences(df['x_token'], value = pad).astype('int64')\n",
    "X_orig = pad_sequences(df['x_orig'], value = pad).astype('int64')\n",
    "y_repl = pad_sequences(df['y_repl'], value = pad).astype('int64')\n",
    "\n",
    "# set up target data from output sequence, 1 timestep off from y_rep\n",
    "y_idx_start = to_categorical(np.array(df['y_idx_start']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_idx_end = to_categorical(np.array(df['y_idx_end']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_repl_cat = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in y_repl]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400003"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 256\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.1\n",
    "\n",
    "input_len = X.shape[1]\n",
    "orig_len = X_orig.shape[1]\n",
    "repl_len = y_repl.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function taken from https://github.com/datalogue/keras-attention/issues/15\n",
    "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
    "                        input_dim=None, output_dim=None,\n",
    "                        timesteps=None, training=None):\n",
    "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        w: weight matrix.\n",
    "        b: optional bias vector.\n",
    "        dropout: wether to apply dropout (same dropout mask\n",
    "            for every temporal slice of the input).\n",
    "        input_dim: integer; optional dimensionality of the input.\n",
    "        output_dim: integer; optional dimensionality of the output.\n",
    "        timesteps: integer; optional number of timesteps.\n",
    "        training: training phase tensor or boolean.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if not input_dim:\n",
    "        input_dim = K.shape(x)[2]\n",
    "    if not timesteps:\n",
    "        timesteps = K.shape(x)[1]\n",
    "    if not output_dim:\n",
    "        output_dim = K.shape(w)[1]\n",
    "\n",
    "    if dropout is not None and 0. < dropout < 1.:\n",
    "        # apply the same dropout pattern at every timestep\n",
    "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
    "        dropout_matrix = K.dropout(ones, dropout)\n",
    "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
    "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
    "\n",
    "    # collapse time dimension and batch dimension together\n",
    "    x = K.reshape(x, (-1, input_dim))\n",
    "    x = K.dot(x, w)\n",
    "    if b is not None:\n",
    "        x = K.bias_add(x, b)\n",
    "        \n",
    "    # reshape to 3D tensor\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
    "        x.set_shape([None, None, output_dim])\n",
    "    else:\n",
    "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
    "        \n",
    "    return x\n",
    "\n",
    "# pointer network implementation\n",
    "class PointerNet(LSTM):\n",
    "    def __init__(self, units, *args, **kwargs):\n",
    "        super().__init__(units, *args, **kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # immediately set variables for later use\n",
    "        # keep same number as units as encoder LSTM by default\n",
    "        self.num_units = input_shape[2]\n",
    "        self.seq_len = input_shape[1]\n",
    "        \n",
    "        # add trainable attention weights\n",
    "        self.W1 = self.add_weight(name=\"W1\",\n",
    "                                  shape=(self.num_units, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.W2 = self.add_weight(name=\"W2\",\n",
    "                                  shape=(self.num_units, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.vt = self.add_weight(name=\"vt\",\n",
    "                                  shape=(self.seq_len, 1),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        \n",
    "        super(PointerNet, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        initial_state = self.get_initial_state(x)\n",
    "                \n",
    "        pointer, _, _ = K.rnn(self.step, x, initial_state, \n",
    "                              constants = [x], input_length = self.seq_len)\n",
    "        \n",
    "        return pointer # only need 1 pointer for whole sequence, so h/c don't matter for this task\n",
    "    \n",
    "    def step(self, x_input, states):\n",
    "        # x_input = original input at current time stamp (batch_size, num_units)\n",
    "        # states = 3 tensors:\n",
    "        # states[0] = h hidden state (batch_size, num_units)\n",
    "        # states[1] = c cell state/memory (batch_size, num_units)\n",
    "        # states[2] = x next word input (batch_size, seq_len, num_units)        \n",
    "        encoded = states[2]\n",
    "        _, [h, c] = self.cell.call(x_input, states[0:2])\n",
    "        decoded = K.repeat(h, self.seq_len)\n",
    "\n",
    "        # vt*tanh(W1*e+W2*d)\n",
    "        W1_eij = _time_distributed_dense(encoded, self.W1, output_dim=1)\n",
    "        W2_dij = _time_distributed_dense(decoded, self.W2, output_dim=1)\n",
    "        U = self.vt * tanh(W1_eij + W2_dij)\n",
    "        U = K.squeeze(U, 2) # removes a 1-dimension at 2nd axis\n",
    "\n",
    "        # softmax over U to get probability distribution over input length\n",
    "        pointer = softmax(U)\n",
    "        return pointer, [h, c]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input shape should be (batch_size, seq_len, units)\n",
    "        # output shape should be (batch_size, seq_len)\n",
    "        return (input_shape[0], input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          name = 'embedding_layer')\n",
    "    input_embed = embedding_layer(main_input)\n",
    "    orig_embed = embedding_layer(orig_input)\n",
    "    repl_embed = embedding_layer(repl_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(return_sequences = True, units = num_units, name = 'lstm')(input_embed)\n",
    "y_start = PointerNet(units = num_units, activation=\"softmax\", input_shape = (input_len, num_units), name = 'y_start')(lstm)\n",
    "y_end = PointerNet(units = num_units, activation=\"softmax\", input_shape = (input_len, num_units), name = 'y_end')(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_embed)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "\n",
    "dec_tdd = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), \n",
    "                               name = 'y_rep_output')\n",
    "y_repl_output = dec_tdd(dec_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Pointer - find indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 6s 1s/step - loss: 4.3934 - y_start_loss: 2.1978 - y_end_loss: 2.1955 - y_start_acc: 0.0000e+00 - y_end_acc: 0.6667\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3700 - y_start_loss: 2.1955 - y_end_loss: 2.1745 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3552 - y_start_loss: 2.1923 - y_end_loss: 2.1629 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3463 - y_start_loss: 2.1879 - y_end_loss: 2.1583 - y_start_acc: 0.1667 - y_end_acc: 0.8333\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3408 - y_start_loss: 2.1842 - y_end_loss: 2.1566 - y_start_acc: 0.1667 - y_end_acc: 0.8333\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3375 - y_start_loss: 2.1817 - y_end_loss: 2.1558 - y_start_acc: 0.3333 - y_end_acc: 0.8333\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.3354 - y_start_loss: 2.1799 - y_end_loss: 2.1555 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3335 - y_start_loss: 2.1782 - y_end_loss: 2.1553 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3318 - y_start_loss: 2.1766 - y_end_loss: 2.1552 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 4.3300 - y_start_loss: 2.1749 - y_end_loss: 2.1551 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3282 - y_start_loss: 2.1732 - y_end_loss: 2.1550 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.3265 - y_start_loss: 2.1715 - y_end_loss: 2.1550 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3249 - y_start_loss: 2.1699 - y_end_loss: 2.1550 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3233 - y_start_loss: 2.1683 - y_end_loss: 2.1550 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3218 - y_start_loss: 2.1668 - y_end_loss: 2.1550 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.3204 - y_start_loss: 2.1655 - y_end_loss: 2.1549 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3192 - y_start_loss: 2.1643 - y_end_loss: 2.1549 - y_start_acc: 0.5000 - y_end_acc: 0.8333\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.3182 - y_start_loss: 2.1633 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3174 - y_start_loss: 2.1625 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.3168 - y_start_loss: 2.1619 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3163 - y_start_loss: 2.1614 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3158 - y_start_loss: 2.1609 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3153 - y_start_loss: 2.1604 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4.3147 - y_start_loss: 2.1598 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3141 - y_start_loss: 2.1593 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3135 - y_start_loss: 2.1587 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3129 - y_start_loss: 2.1581 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3124 - y_start_loss: 2.1576 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3120 - y_start_loss: 2.1572 - y_end_loss: 2.1549 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3117 - y_start_loss: 2.1569 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.3114 - y_start_loss: 2.1566 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3112 - y_start_loss: 2.1563 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3109 - y_start_loss: 2.1561 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3106 - y_start_loss: 2.1558 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3104 - y_start_loss: 2.1556 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.3101 - y_start_loss: 2.1553 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3099 - y_start_loss: 2.1551 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3097 - y_start_loss: 2.1549 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 4.3096 - y_start_loss: 2.1548 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3095 - y_start_loss: 2.1546 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3093 - y_start_loss: 2.1545 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3092 - y_start_loss: 2.1544 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3091 - y_start_loss: 2.1543 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3091 - y_start_loss: 2.1543 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3090 - y_start_loss: 2.1542 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3089 - y_start_loss: 2.1541 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.3088 - y_start_loss: 2.1540 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3087 - y_start_loss: 2.1539 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3086 - y_start_loss: 2.1539 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.3086 - y_start_loss: 2.1538 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3085 - y_start_loss: 2.1537 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3084 - y_start_loss: 2.1536 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3083 - y_start_loss: 2.1535 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3082 - y_start_loss: 2.1534 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3081 - y_start_loss: 2.1534 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 4.3080 - y_start_loss: 2.1533 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3079 - y_start_loss: 2.1532 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3078 - y_start_loss: 2.1531 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3077 - y_start_loss: 2.1530 - y_end_loss: 2.1548 - y_start_acc: 0.6667 - y_end_acc: 0.8333\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 4.3076 - y_start_loss: 2.1529 - y_end_loss: 2.1548 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.3075 - y_start_loss: 2.1528 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3074 - y_start_loss: 2.1527 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3073 - y_start_loss: 2.1526 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3072 - y_start_loss: 2.1525 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3071 - y_start_loss: 2.1524 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3070 - y_start_loss: 2.1522 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3069 - y_start_loss: 2.1521 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4.3067 - y_start_loss: 2.1520 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3066 - y_start_loss: 2.1519 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.3065 - y_start_loss: 2.1518 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4.3064 - y_start_loss: 2.1517 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3063 - y_start_loss: 2.1516 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.3061 - y_start_loss: 2.1514 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3060 - y_start_loss: 2.1513 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.3059 - y_start_loss: 2.1512 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 4.3058 - y_start_loss: 2.1511 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3057 - y_start_loss: 2.1510 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 4.3056 - y_start_loss: 2.1509 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3054 - y_start_loss: 2.1508 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3053 - y_start_loss: 2.1507 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3052 - y_start_loss: 2.1505 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3051 - y_start_loss: 2.1504 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3050 - y_start_loss: 2.1503 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 4.3049 - y_start_loss: 2.1502 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3048 - y_start_loss: 2.1501 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3046 - y_start_loss: 2.1500 - y_end_loss: 2.1547 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3045 - y_start_loss: 2.1499 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 4.3044 - y_start_loss: 2.1498 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3043 - y_start_loss: 2.1497 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 4.3042 - y_start_loss: 2.1495 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 4.3041 - y_start_loss: 2.1494 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4.3039 - y_start_loss: 2.1493 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.3038 - y_start_loss: 2.1492 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 4.3037 - y_start_loss: 2.1491 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 4.3036 - y_start_loss: 2.1490 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4.3035 - y_start_loss: 2.1489 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 4.3033 - y_start_loss: 2.1487 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4.3032 - y_start_loss: 2.1486 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4.3031 - y_start_loss: 2.1485 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 4.3030 - y_start_loss: 2.1484 - y_end_loss: 2.1546 - y_start_acc: 0.8333 - y_end_acc: 0.8333\n"
     ]
    }
   ],
   "source": [
    "pointer_model = Model(inputs = main_input, outputs = [y_start, y_end])\n",
    "pointer_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "pointer_history = pointer_model.fit(X, [y_idx_start, y_idx_end], epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   main_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 9, 512)       1665024     embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "y_start (PointerNet)            (None, 9)            2099200     lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "y_end (PointerNet)              (None, 9)            2099200     lstm[0][0]                       \n",
      "==================================================================================================\n",
      "Total params: 125,864,324\n",
      "Trainable params: 5,863,424\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pointer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7febd12f0630>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pointer_history.history['y_start_acc'], label='y_start')\n",
    "plt.plot(pointer_history.history['y_end_acc'], label='y_end')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7febd1270198>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pointer_history.history['y_start_loss'], label='y_start')\n",
    "plt.plot(pointer_history.history['y_end_loss'], label='y_end')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECOND: turn index into slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_idx_pred = pointer_model.predict(X, batch_size = batch_size)\n",
    "y_idx_pred = np.argmax(y_idx_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in X:\n",
    "\n",
    "y_idx_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET PARAMETER ORIG_LEN HERE BASED ON PADDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: NMT for finding suggestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently does NOT include whole context of sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1024,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/y_rep_output/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e1439941a5e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m              metrics = ['accuracy'])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mnmt_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_repl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_repl_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1024,400003] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/y_rep_output/MatMul_grad/MatMul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "# other parameters\n",
    "# https://keras.io/examples/lstm_seq2seq/\n",
    "\n",
    "nmt_model = Model(inputs = [orig_input, repl_input], outputs = y_repl_output)\n",
    "\n",
    "nmt_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "nmt_history = nmt_model.fit([X_orig, y_repl], y_repl_cat, epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "repl_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "orig_input (InputLayer)         (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   orig_input[0][0]                 \n",
      "                                                                 repl_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Bidirectional)         [(None, 1024), (None 3330048     embedding_layer[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           encoder[0][1]                    \n",
      "                                                                 encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1024)         0           encoder[0][2]                    \n",
      "                                                                 encoder[0][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  [(None, 4, 1024), (N 5427200     embedding_layer[2][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "y_rep_output (TimeDistributed)  (None, 4, 400003)    410003075   decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 538,761,223\n",
      "Trainable params: 418,760,323\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nmt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nmt_history.history['acc'], label='accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nmt_history.history['loss'], label='loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference mode for NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"orig_input:0\", shape=(?, 4), dtype=int64) at layer \"orig_input\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7388e6f7fae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0minf_dec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec_tdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minf_dec_main\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minf_enc_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menc_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0minf_dec_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrepl_input\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minf_dec_states_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minf_dec_output\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minf_dec_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 231\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                                          \u001b[0;34m'The following previous layers '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                          \u001b[0;34m'were accessed without issue: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                          str(layers_with_complete_input))\n\u001b[0m\u001b[1;32m   1444\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m                     \u001b[0mcomputable_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"orig_input:0\", shape=(?, 4), dtype=int64) at layer \"orig_input\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "inf_dec_h_input = Input(shape=(num_units * 2,))\n",
    "inf_dec_c_input = Input(shape=(num_units * 2,))\n",
    "inf_dec_states_input = [inf_dec_h_input, inf_dec_c_input]\n",
    "\n",
    "inf_dec_main, inf_dec_h, inf_dec_c = decoder(repl_embed, initial_state = inf_dec_states_input)\n",
    "inf_dec_states = [inf_dec_h, inf_dec_c]\n",
    "inf_dec_output = dec_tdd(inf_dec_main)\n",
    "\n",
    "inf_enc_model = Model(inputs = [orig_input], outputs = [enc_h, enc_c])\n",
    "inf_dec_model = Model([repl_input] + inf_dec_states_input, [inf_dec_output] + inf_dec_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_seq):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: put it together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
