{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In replicating Rao & Tetreault (2018) we need to vectorize text data using word embeddings (GloVe) trained on the whole Yahoo Answers corpus. Word vector dimensions are 300 and total vocabulary size is 50,000.\n",
    "\n",
    "Note: \"At test time, we replace unknown tokens with the source token that has the highest attention weight.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data: extract answers from XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cramerus\\Documents\\Thesis\\Yahoo Answers Corpus\n",
      " Volume in Laufwerk C: hat keine Bezeichnung.\n",
      " Volumeseriennummer: D638-A535\n",
      "\n",
      " Verzeichnis von C:\\Users\\cramerus\\Documents\\Thesis\\Yahoo Answers Corpus\n",
      "\n",
      "09.04.2019  12:29    <DIR>          .\n",
      "09.04.2019  12:29    <DIR>          ..\n",
      "09.04.2019  12:31    12.263.270.226 FullOct2007.xml\n",
      "16.09.2009  22:27     6.131.634.176 FullOct2007.xml.part1\n",
      "16.09.2009  22:43     1.770.876.044 FullOct2007.xml.part1.gz\n",
      "17.09.2009  02:01     6.131.636.050 FullOct2007.xml.part2\n",
      "17.09.2009  02:18     1.936.135.644 FullOct2007.xml.part2.gz\n",
      "17.09.2009  23:51             4.195 README.txt\n",
      "16.09.2009  21:49            19.457 small_sample.xml\n",
      "16.09.2009  21:49             1.874 WebscopeReadMe.txt\n",
      "               8 Datei(en), 28.233.577.666 Bytes\n",
      "               2 Verzeichnis(se), 260.927.369.216 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\Users\\cramerus\\Documents\\Thesis\\Yahoo Answers Corpus\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.replace('<br />', '<br />', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'FullOct2007.xml'\n",
    "small_file = 'small_sample.xml'\n",
    "new_output = 'YahooCorpus.txt'\n",
    "sample_output = 'SampleCorpus.txt'\n",
    "\n",
    "def xml_to_txt(input_file, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for event, elem in tqdm(ET.iterparse(input_file, events=('start', 'end'))):\n",
    "            if event == 'start' and elem.tag == 'vespaadd': # start new question\n",
    "                texts = []\n",
    "                language = None\n",
    "            if elem.tag == 'answer_item':\n",
    "                if elem.text == None:\n",
    "                    continue\n",
    "                text = str.replace(elem.text, '<br />', '') # remove tags\n",
    "                text = re.sub(r'\\s+', ' ', text).strip() # remove whitespace\n",
    "                if text not in texts:\n",
    "                    texts.append(text)\n",
    "            if elem.tag == 'language':\n",
    "                language = elem.text # should be None or en-us\n",
    "\n",
    "            if event == 'end' and elem.tag == 'vespaadd':\n",
    "                if language == None or language == 'en-us':\n",
    "                    for text in texts:\n",
    "                        tokens = word_tokenize(text)\n",
    "                        for token in tokens:\n",
    "                            f.write(token + ' ')\n",
    "                        f.write('\\n')\n",
    "                elem.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65adfa5d30a441da7f77fef65ce41ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xml_to_txt(small_file, sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db94c4d57c964178acdd131151821ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xml_to_txt(file, new_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train glove model on corpus, test"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# done in command line\n",
    "# input is Yahoo Answers corpus, created in the correct format above\n",
    "\n",
    "# $ cd ./Documents\n",
    "# $ GloVe/build/vocab_count -max-vocab 50000 -verbose 2 < YahooAnswers/YahooCorpus.txt > YahooAnswers/YahooVocab.txt\n",
    "# $ GloVe/build/cooccur -memory 10.0 -vocab-file YahooAnswers/YahooVocab.txt -verbose 2 -window-size 15 < YahooAnswers/YahooCorpus.txt > YahooAnswers/YahooCooccur.bin\n",
    "# $ GloVe/build/shuffle -memory 10.0 -verbose 2 < YahooAnswers/YahooCooccur.bin > YahooAnswers/YahooCooccur.shuf.bin\n",
    "# $ GloVe/build/glove -save-file YahooAnswers/YahooVectors -threads 8 -input-file YahooAnswers/YahooCooccur.shuf.bin -vector-size 300 -binary 2 -vocab-file YahooAnswers/YahooVocab.txt -verbose 2\n",
    "\n",
    "# output is at Documents/YahooAnswers/YahooVectors.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "% cd /home/rebekah/Documents/YahooAnswers \n",
    "glove = 'YahooVectors.txt'\n",
    "w2v = \"YahooVectors.w2v.txt\"\n",
    "glove2word2vec(glove, w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(\"YahooVectors.w2v.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('OMG', 0.726203978061676),\n",
       " ('lmao', 0.6339886784553528),\n",
       " ('wow', 0.6241101622581482),\n",
       " ('Omg', 0.6220057010650635),\n",
       " ('soo', 0.6049739122390747),\n",
       " ('hahaha', 0.601554274559021),\n",
       " ('sooo', 0.5800875425338745),\n",
       " ('haha', 0.5698546171188354),\n",
       " ('omfg', 0.5645304322242737),\n",
       " ('wtf', 0.5600650310516357)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('omg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
