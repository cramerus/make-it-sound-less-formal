{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Embedding, LSTM, Dense, Dropout, Layer, Concatenate\n",
    "from keras.layers import TimeDistributed, Bidirectional, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.core import Reshape\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.engine import InputSpec\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure gpu is available\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import embedding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pretrained GloVe embeddings unpacked\n",
    "\n",
    "file = 'glove.6B.300d.txt'\n",
    "embed_dim = 300\n",
    "\n",
    "w2idx = {}\n",
    "w2vec = {}\n",
    "\n",
    "with open(file) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        line = [part.strip() for part in line.split()]\n",
    "        word = line[0]\n",
    "        vec = np.asarray(line[1 : embed_dim + 1], dtype='float32')\n",
    "        \n",
    "        w2idx[word] = idx\n",
    "        w2vec[word] = vec\n",
    "        \n",
    "# include empty character for padding - put last\n",
    "w2idx[''] = len(w2idx)\n",
    "w2vec[''] = np.zeros(embed_dim)\n",
    "\n",
    "# create embedding matrix\n",
    "embeddings = np.zeros((len(w2idx), embed_dim))\n",
    "\n",
    "for word, idx in w2idx.items():\n",
    "    embeddings[idx] = np.array(w2vec[word])\n",
    "    \n",
    "# save\n",
    "with open('glv_embed_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "    \n",
    "with open('glv_w2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(w2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not</td>\n",
       "      <td>don't</td>\n",
       "      <td>I do not know what to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not</td>\n",
       "      <td>won't</td>\n",
       "      <td>The girl will not go to bed.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Replacement                      Sentence\n",
       "0    do not       don't    I do not know what to say.\n",
       "1  will not       won't  The girl will not go to bed."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder dataset\n",
    "\n",
    "df = pd.DataFrame({'Sentence': [\"I do not know what to say.\", \"The girl will not go to bed.\"], \n",
    "                  'Original': [\"do not\", \"will not\"],\n",
    "                  'Replacement': [\"don't\", \"won't\"]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "def sent_to_word_idx(df):\n",
    "    new = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        \n",
    "        sent = word_tokenize(row['Sentence'])\n",
    "        \n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        \n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "                                \n",
    "        new.append(sent_indices)\n",
    "    \n",
    "    df['x_word'] = new\n",
    "    return df\n",
    "\n",
    "def orig_to_place_idx(df):\n",
    "    # takes the part of the sentence to be replaced and turns it into a pair of start/end indices\n",
    "    \n",
    "    y_start = []\n",
    "    y_end = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Original'])\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "        \n",
    "        # take indices and find the slice in the whole sentence\n",
    "        slice_length = len(sent_indices)\n",
    "        starts = [i for i, x in enumerate(row['x_word']) if x == sent_indices[0]]\n",
    "        slice_idx = np.nan\n",
    "        \n",
    "        for potential_start in starts:\n",
    "            potential_slice = row['x_word'][potential_start : potential_start + slice_length]\n",
    "            if (potential_slice == np.array(sent_indices)).all():\n",
    "                y_start.append(potential_start)\n",
    "                y_end.append(potential_start + slice_length - 1)\n",
    "                break\n",
    "            \n",
    "    df['y_start'] = y_start\n",
    "    df['y_end'] = y_end\n",
    "    return df\n",
    "\n",
    "def repl_to_word_idx(df):\n",
    "    # takes original & replacement texts and turns them into both decoder input and decoder output\n",
    "    # both so that teacher forcing can be done\n",
    "    \n",
    "    y_rep = []\n",
    "    y_orig = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Replacement'])\n",
    "                \n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        \n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "                \n",
    "        y_rep.append(sent_indices)\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Original'])\n",
    "                \n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        \n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "        y_orig.append(sent_indices)\n",
    "        \n",
    "    df['y_orig'] = y_orig\n",
    "    df['y_rep'] = y_rep\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e508b7707c84b698b4f48ce753f72f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e148226da1a441e913be454cfe817d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be5a3cdc54a48adacb72f89885cee31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe03726c88740a48384870139e7b167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>x_word</th>\n",
       "      <th>y_start</th>\n",
       "      <th>y_end</th>\n",
       "      <th>y_orig</th>\n",
       "      <th>y_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not</td>\n",
       "      <td>don't</td>\n",
       "      <td>I do not know what to say.</td>\n",
       "      <td>[400001, 41, 88, 36, 346, 102, 4, 203, 2, 400002]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[400001, 88, 36, 400002]</td>\n",
       "      <td>[400001, 88, 70, 400002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not</td>\n",
       "      <td>won't</td>\n",
       "      <td>The girl will not go to bed.</td>\n",
       "      <td>[400001, 0, 1749, 43, 36, 242, 4, 3827, 2, 400...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[400001, 43, 36, 400002]</td>\n",
       "      <td>[400001, 1369, 70, 400002]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Replacement                      Sentence  \\\n",
       "0    do not       don't    I do not know what to say.   \n",
       "1  will not       won't  The girl will not go to bed.   \n",
       "\n",
       "                                              x_word  y_start  y_end  \\\n",
       "0  [400001, 41, 88, 36, 346, 102, 4, 203, 2, 400002]        2      3   \n",
       "1  [400001, 0, 1749, 43, 36, 242, 4, 3827, 2, 400...        3      4   \n",
       "\n",
       "                     y_orig                       y_rep  \n",
       "0  [400001, 88, 36, 400002]    [400001, 88, 70, 400002]  \n",
       "1  [400001, 43, 36, 400002]  [400001, 1369, 70, 400002]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sent_to_word_idx(df)\n",
    "df = orig_to_place_idx(df)\n",
    "df = repl_to_word_idx(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add pre-padding\n",
    "\n",
    "X = pad_sequences(df['x_word'], value = len(w2idx)).astype('int64')\n",
    "y_rep = pad_sequences(df['y_rep'], value = len(w2idx)).astype('int64')\n",
    "y_orig = pad_sequences(df['y_orig'], value = len(w2idx)).astype('int64')\n",
    "\n",
    "# set up target data from output sequence, 1 timestep off from y_rep\n",
    "#y_rep_output\n",
    "\n",
    "y_start = to_categorical(np.array(df['y_start']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_end = to_categorical(np.array(df['y_end']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_rep_cat = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in y_rep]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 64 # I think 512 is standard - lessening for memory purposes for now\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "learning_rate = 0.1\n",
    "\n",
    "input_len = X.shape[1]\n",
    "orig_len = y_orig.shape[1]\n",
    "repl_len = y_rep.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# input sentences in form of word indices\n",
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "\n",
    "# embedding layer\n",
    "# note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                      output_dim = embedding.shape[1],\n",
    "                      weights = [embedding],\n",
    "                      trainable = False, \n",
    "                      name = 'embedding_layer')\n",
    "\n",
    "input_embed = embedding_layer(main_input)\n",
    "repl_embed = embedding_layer(repl_input)\n",
    "orig_embed = embedding_layer(orig_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get indices\n",
    "\n",
    "# return_sequences would be True when this is an encoder to lead to PointerLSTM\n",
    "lstm = Bidirectional(LSTM(return_sequences = False, units = num_units), name='lstm')(input_embed)\n",
    "\n",
    "# these ones should change later to the PointerLSTM layer\n",
    "y_start_output = Dense(input_len, activation = 'softmax', name = 'y_start_output')(lstm)\n",
    "y_end_output = Dense(input_len, activation = 'softmax', name = 'y_end_output')(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### connect indices to main_input\n",
    "\n",
    "## later use this to slice and concatenate with context\n",
    "## in the meantime just assume y_orig is somehow the output\n",
    "\n",
    "#y_indices = concatenate([K.argmax(y_start_output, axis = 1), K.argmax(y_end_output, axis = 1)])\n",
    "#y_start_sparse = Lambda(lambda x : K.argmax(x, axis = 1))(y_start_output)\n",
    "#y_end_sparse = Lambda(lambda x : K.argmax(x, axis = 1))(y_end_output)\n",
    "#y_start_reshape = Reshape((1,))(y_start_sparse)\n",
    "#y_end_reshape = Reshape((1,))(y_end_sparse)\n",
    "#return_input = concatenate([y_start_reshape, y_end_reshape, main_input], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_embed)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "\n",
    "y_rep_output = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), \n",
    "                               name = 'y_rep_output')(dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 7s 3s/step - loss: 17.6354 - y_start_output_loss: 2.4477 - y_end_output_loss: 2.2888 - y_rep_output_loss: 12.8989 - y_start_output_acc: 0.0000e+00 - y_end_output_acc: 0.0000e+00 - y_rep_output_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 16.8633 - y_start_output_loss: 2.0448 - y_end_output_loss: 1.9461 - y_rep_output_loss: 12.8725 - y_start_output_acc: 0.0000e+00 - y_end_output_acc: 0.5000 - y_rep_output_acc: 0.7500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 16.1739 - y_start_output_loss: 1.6948 - y_end_output_loss: 1.6401 - y_rep_output_loss: 12.8390 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 15.5552 - y_start_output_loss: 1.3954 - y_end_output_loss: 1.3680 - y_rep_output_loss: 12.7917 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 14.9979 - y_start_output_loss: 1.1420 - y_end_output_loss: 1.1289 - y_rep_output_loss: 12.7270 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 14.4953 - y_start_output_loss: 0.9296 - y_end_output_loss: 0.9228 - y_rep_output_loss: 12.6429 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 14.0406 - y_start_output_loss: 0.7528 - y_end_output_loss: 0.7489 - y_rep_output_loss: 12.5390 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 13.6239 - y_start_output_loss: 0.6057 - y_end_output_loss: 0.6032 - y_rep_output_loss: 12.4151 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 13.2369 - y_start_output_loss: 0.4833 - y_end_output_loss: 0.4818 - y_rep_output_loss: 12.2718 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 12.8699 - y_start_output_loss: 0.3793 - y_end_output_loss: 0.3810 - y_rep_output_loss: 12.1096 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 12.5180 - y_start_output_loss: 0.2917 - y_end_output_loss: 0.2970 - y_rep_output_loss: 11.9293 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 12.1753 - y_start_output_loss: 0.2171 - y_end_output_loss: 0.2274 - y_rep_output_loss: 11.7307 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 11.8431 - y_start_output_loss: 0.1561 - y_end_output_loss: 0.1709 - y_rep_output_loss: 11.5160 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 11.5203 - y_start_output_loss: 0.1086 - y_end_output_loss: 0.1278 - y_rep_output_loss: 11.2839 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 11.2062 - y_start_output_loss: 0.0739 - y_end_output_loss: 0.0959 - y_rep_output_loss: 11.0365 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.9010 - y_start_output_loss: 0.0498 - y_end_output_loss: 0.0723 - y_rep_output_loss: 10.7789 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.5995 - y_start_output_loss: 0.0335 - y_end_output_loss: 0.0549 - y_rep_output_loss: 10.5111 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10.3037 - y_start_output_loss: 0.0229 - y_end_output_loss: 0.0419 - y_rep_output_loss: 10.2389 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10.0146 - y_start_output_loss: 0.0161 - y_end_output_loss: 0.0324 - y_rep_output_loss: 9.9661 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9.7272 - y_start_output_loss: 0.0116 - y_end_output_loss: 0.0252 - y_rep_output_loss: 9.6904 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9.4445 - y_start_output_loss: 0.0086 - y_end_output_loss: 0.0200 - y_rep_output_loss: 9.4159 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9.1690 - y_start_output_loss: 0.0065 - y_end_output_loss: 0.0160 - y_rep_output_loss: 9.1464 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.8984 - y_start_output_loss: 0.0051 - y_end_output_loss: 0.0130 - y_rep_output_loss: 8.8802 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.6320 - y_start_output_loss: 0.0041 - y_end_output_loss: 0.0107 - y_rep_output_loss: 8.6172 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.3710 - y_start_output_loss: 0.0034 - y_end_output_loss: 0.0089 - y_rep_output_loss: 8.3586 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8.1122 - y_start_output_loss: 0.0029 - y_end_output_loss: 0.0075 - y_rep_output_loss: 8.1017 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.8546 - y_start_output_loss: 0.0025 - y_end_output_loss: 0.0065 - y_rep_output_loss: 7.8456 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 7.5982 - y_start_output_loss: 0.0022 - y_end_output_loss: 0.0056 - y_rep_output_loss: 7.5904 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 7.3422 - y_start_output_loss: 0.0019 - y_end_output_loss: 0.0049 - y_rep_output_loss: 7.3353 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.0860 - y_start_output_loss: 0.0017 - y_end_output_loss: 0.0043 - y_rep_output_loss: 7.0799 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 6.8293 - y_start_output_loss: 0.0016 - y_end_output_loss: 0.0039 - y_rep_output_loss: 6.8239 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.5727 - y_start_output_loss: 0.0015 - y_end_output_loss: 0.0035 - y_rep_output_loss: 6.5678 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.3159 - y_start_output_loss: 0.0014 - y_end_output_loss: 0.0032 - y_rep_output_loss: 6.3114 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 6.0593 - y_start_output_loss: 0.0013 - y_end_output_loss: 0.0029 - y_rep_output_loss: 6.0551 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.8032 - y_start_output_loss: 0.0012 - y_end_output_loss: 0.0027 - y_rep_output_loss: 5.7993 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 5.5476 - y_start_output_loss: 0.0011 - y_end_output_loss: 0.0025 - y_rep_output_loss: 5.5439 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 5.2928 - y_start_output_loss: 0.0011 - y_end_output_loss: 0.0023 - y_rep_output_loss: 5.2894 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 5.0393 - y_start_output_loss: 0.0010 - y_end_output_loss: 0.0022 - y_rep_output_loss: 5.0361 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 4.7876 - y_start_output_loss: 9.9925e-04 - y_end_output_loss: 0.0021 - y_rep_output_loss: 4.7846 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.5383 - y_start_output_loss: 9.6464e-04 - y_end_output_loss: 0.0019 - y_rep_output_loss: 4.5354 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.2919 - y_start_output_loss: 9.3386e-04 - y_end_output_loss: 0.0019 - y_rep_output_loss: 4.2891 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.0493 - y_start_output_loss: 9.0641e-04 - y_end_output_loss: 0.0018 - y_rep_output_loss: 4.0466 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.8109 - y_start_output_loss: 8.8177e-04 - y_end_output_loss: 0.0017 - y_rep_output_loss: 3.8083 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.5782 - y_start_output_loss: 8.5952e-04 - y_end_output_loss: 0.0016 - y_rep_output_loss: 3.5757 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.3523 - y_start_output_loss: 8.3924e-04 - y_end_output_loss: 0.0016 - y_rep_output_loss: 3.3499 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.1342 - y_start_output_loss: 8.2086e-04 - y_end_output_loss: 0.0015 - y_rep_output_loss: 3.1319 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 2.9256 - y_start_output_loss: 8.0398e-04 - y_end_output_loss: 0.0015 - y_rep_output_loss: 2.9233 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 2.7275 - y_start_output_loss: 7.8853e-04 - y_end_output_loss: 0.0014 - y_rep_output_loss: 2.7253 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 2.5413 - y_start_output_loss: 7.7448e-04 - y_end_output_loss: 0.0014 - y_rep_output_loss: 2.5391 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2.3681 - y_start_output_loss: 7.6133e-04 - y_end_output_loss: 0.0013 - y_rep_output_loss: 2.3660 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#### define & train model\n",
    "\n",
    "model = Model(inputs = [main_input, orig_input, repl_input], outputs = [y_start_output, y_end_output, y_rep_output])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit([X, y_orig, y_rep], [y_start, y_end, y_rep_cat], epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repl_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "orig_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   main_input[0][0]                 \n",
      "                                                                 repl_input[0][0]                 \n",
      "                                                                 orig_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Bidirectional)         [(None, 128), (None, 186880      embedding_layer[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 128)          0           encoder[0][1]                    \n",
      "                                                                 encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 128)          0           encoder[0][2]                    \n",
      "                                                                 encoder[0][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (Bidirectional)            (None, 128)          186880      embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  [(None, 4, 128), (No 219648      embedding_layer[1][0]            \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "y_start_output (Dense)          (None, 10)           1290        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "y_end_output (Dense)            (None, 10)           1290        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "y_rep_output (TimeDistributed)  (None, 4, 400003)    51600387    decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 172,197,275\n",
      "Trainable params: 52,196,375\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd989172320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['y_start_output_acc'], label='y_start accuracy')\n",
    "plt.plot(history.history['y_end_output_acc'], label='y_end accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd989153ac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='overall train loss')\n",
    "plt.plot(history.history['y_start_output_loss'], label='y_start loss')\n",
    "plt.plot(history.history['y_end_output_loss'], label='y_end loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer bidirectional_41: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-e520fdd52224>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#lstm_out = LSTM(32)(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlstm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lstm_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#decoder = Bidirectional(LSTM(return_sequences = False, name = \"decoder\", units = seq_len))(encoder)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer bidirectional_41: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "main_input = Input(shape=(seq_len,), dtype='float32', name='main_input')\n",
    "\n",
    "lstm_1 = Bidirectional(LSTM(return_sequences = False, name = \"lstm_1\", units = num_units))(main_input)\n",
    "#decoder = Bidirectional(LSTM(return_sequences = False, name = \"decoder\", units = seq_len))(encoder)\n",
    "\n",
    "index_output = Dense(1, activation = 'sigmoid', name = 'index_output')(lstm_1)\n",
    "#dense = TimeDistributed(Dense(1, activation='softmax', name='time_dist_dense'))(decoder)\n",
    "#decoder = PointerLSTM(num_units, name = \"decoder\", units = 5)(encoder)\n",
    "\n",
    "reshape_idx = Reshape((1, 1))(index_output)\n",
    "return_input = concatenate([reshape_idx, main_input], axis=1)\n",
    "\n",
    "lstm_2 = Bidirectional(LSTM(return_sequences = False, name = \"lstm_2\", units = num_units))(return_input)\n",
    "final_output = Dense(1, activation = 'sigmoid', name = 'final_output')(lstm_2)\n",
    "\n",
    "model = Model(inputs = main_input, outputs = [index_output, final_output])\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             loss_weights = [1., .5],\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X, [y_idx, y_rep], epochs = epochs, batch_size = batch_size)\n",
    "\n",
    "#history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), epochs=epochs,\n",
    "#validation_data=(x_test, y_test), steps_per_epoch=x_train.shape[0]//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointerLSTM(LSTM):\n",
    "    def __init__(self, hidden_shape, *args, **kwargs):\n",
    "        self.hidden_shape = hidden_shape\n",
    "        self.input_length = []\n",
    "        super(PointerLSTM, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def get_initial_states(self, x_input):\n",
    "        return Recurrent.get_initial_state(self, x_input)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PointerLSTM, self).build(input_shape)\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.W1 = self.add_weight(name=\"W1\",\n",
    "                                  shape=(self.hidden_shape, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.W2 = self.add_weight(name=\"W2\",\n",
    "                                  shape=(self.hidden_shape, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.vt = self.add_weight(name=\"vt\",\n",
    "                                  shape=(input_shape[1], 1),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        #self.trainable_weights += [self.W1, self.W2, self.vt]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        en_seq = x\n",
    "        x_input = x[:, input_shape[1] - 1, :]\n",
    "        x_input = K.repeat(x_input, input_shape[1])\n",
    "        initial_states = self.get_initial_states(x_input)\n",
    "\n",
    "        constants = super(PointerLSTM, self).get_constants(x_input)\n",
    "        constants.append(en_seq)\n",
    "        preprocessed_input = self.preprocess_input(x_input)\n",
    "\n",
    "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
    "                                             initial_states,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             constants=constants,\n",
    "                                             input_length=input_shape[1])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def step(self, x_input, states):\n",
    "        # print \"x_input:\", x_input, x_input.shape\n",
    "        # <TensorType(float32, matrix)>\n",
    "\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        en_seq = states[-1]\n",
    "        _, [h, c] = super(PointerLSTM, self).step(x_input, states[:-1])\n",
    "\n",
    "        # vt*tanh(W1*e+W2*d)\n",
    "        dec_seq = K.repeat(h, input_shape[1])\n",
    "        Eij = TimeDistributed(Dense(en_seq, self.W1, output_dim=1))\n",
    "        Dij = TimeDistributed(Dense(dec_seq, self.W2, output_dim=1))\n",
    "        U = self.vt * tanh(Eij + Dij)\n",
    "        U = K.squeeze(U, 2)\n",
    "\n",
    "        # make probability tensor\n",
    "        pointer = softmax(U)\n",
    "        return pointer, [h, c]\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        # output shape is not affected by the attention component\n",
    "        return (input_shape[0], input_shape[1], input_shape[1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.layers import LSTM, Input\n",
    "from keras.models import Model\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from PointerLSTM import PointerLSTM\n",
    "from tsp_data import Tsp\n",
    "\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < nb_epochs / 4:\n",
    "        return learning_rate\n",
    "    elif epoch < nb_epochs / 2:\n",
    "        return learning_rate * 0.5\n",
    "    return learning_rate * 0.1\n",
    "\n",
    "\n",
    "print(\"preparing dataset...\")\n",
    "t = Tsp()\n",
    "X, Y = t.next_batch(10)\n",
    "x_test, y_test = t.next_batch(1)\n",
    "\n",
    "YY = []\n",
    "for y in Y:\n",
    "    YY.append(to_categorical(y))\n",
    "YY = np.asarray(YY)\n",
    "\n",
    "hidden_size = 128\n",
    "seq_len = 10\n",
    "nb_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "print(\"building model...\")\n",
    "main_input = Input(shape=(seq_len, 2), name='main_input')\n",
    "\n",
    "# encoder = LSTM(output_dim = hidden_size, return_sequences = True, name=\"encoder\")(main_input)\n",
    "encoder = LSTM(units=hidden_size, return_sequences=True, name=\"encoder\")(main_input)\n",
    "# decoder = PointerLSTM(hidden_size, output_dim=hidden_size, name=\"decoder\")(encoder)\n",
    "decoder = PointerLSTM(hidden_shape=hidden_size, units=hidden_size, name=\"decoder\")(encoder)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=decoder)\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, YY, epochs=nb_epochs, batch_size=64, callbacks=[LearningRateScheduler(scheduler), ])\n",
    "print(model.predict(x_test))\n",
    "print(\"------\")\n",
    "print(to_categorical(y_test))\n",
    "model.save_weights('model_weight_100.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
