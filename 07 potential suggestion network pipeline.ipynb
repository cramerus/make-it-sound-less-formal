{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from keras import initializers, regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Embedding, RNN, LSTM, LSTMCell, Dense, Dropout, Concatenate\n",
    "from keras.layers import TimeDistributed, Bidirectional, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.core import Reshape\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure gpu is available\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import embedding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pretrained GloVe embeddings unpacked\n",
    "\n",
    "file = 'glove.6B.300d.txt'\n",
    "embed_dim = 300\n",
    "\n",
    "w2idx = {}\n",
    "w2vec = {}\n",
    "\n",
    "with open(file) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        line = [part.strip() for part in line.split()]\n",
    "        word = line[0]\n",
    "        vec = np.asarray(line[1 : embed_dim + 1], dtype='float32')\n",
    "        \n",
    "        w2idx[word] = idx\n",
    "        w2vec[word] = vec\n",
    "        \n",
    "# include empty character for padding - put last\n",
    "w2idx[''] = len(w2idx)\n",
    "w2vec[''] = np.zeros(embed_dim)\n",
    "\n",
    "# create embedding matrix\n",
    "embeddings = np.zeros((len(w2idx), embed_dim))\n",
    "\n",
    "for word, idx in w2idx.items():\n",
    "    embeddings[idx] = np.array(w2vec[word])\n",
    "    \n",
    "# save\n",
    "with open('glv_embed_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "    \n",
    "with open('glv_w2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(w2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)\n",
    "    \n",
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "pad = len(w2idx) - 1\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder dataset\n",
    "\n",
    "df = pd.DataFrame({'Sentence': [\"I do not know what to say.\", \n",
    "                                \"The girl will not go to bed.\",\n",
    "                               \"He will not come tomorrow night.\",\n",
    "                               \"They would not want you to do that.\",\n",
    "                               \"We can not believe that this happened.\",\n",
    "                               \"I could not handle the truth.\"], \n",
    "                  'Original': [\"do not\", \"will not\", \"will not\", \"would not\", \"can not\", \"could not\"],\n",
    "                  'Replacement': [\"don't\", \"won't\", \"won't\", \"wouldn't\", \"can't\", \"couldn't\"]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "def sent_to_word_idx(df):\n",
    "    new = []\n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Sentence'])\n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(pad)            \n",
    "        new.append(sent_indices)\n",
    "    df['x_word'] = new\n",
    "    return df\n",
    "\n",
    "def orig_to_place_idx(df):\n",
    "    # takes the part of the sentence to be replaced and turns it into a pair of start/end indices\n",
    "    y_start = []\n",
    "    y_end = []\n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Original'])\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(pad)\n",
    "        # take indices and find the slice in the whole sentence\n",
    "        slice_length = len(sent_indices)\n",
    "        starts = [i for i, x in enumerate(row['x_word']) if x == sent_indices[0]]\n",
    "        slice_idx = np.nan\n",
    "        for potential_start in starts:\n",
    "            potential_slice = row['x_word'][potential_start : potential_start + slice_length]\n",
    "            if (potential_slice == np.array(sent_indices)).all():\n",
    "                y_start.append(potential_start)\n",
    "                y_end.append(potential_start + slice_length - 1)\n",
    "                break\n",
    "    df['y_start'] = y_start\n",
    "    df['y_end'] = y_end\n",
    "    return df\n",
    "\n",
    "def repl_to_word_idx(df):\n",
    "    # takes original & replacement texts and turns them into both decoder input and decoder output\n",
    "    # both so that teacher forcing can be done\n",
    "    y_rep = []\n",
    "    y_orig = []\n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Replacement'])\n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(pad)\n",
    "        y_rep.append(sent_indices)\n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Original'])\n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(pad)\n",
    "        y_orig.append(sent_indices)\n",
    "    df['y_orig'] = y_orig\n",
    "    df['y_rep'] = y_rep\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = sent_to_word_idx(df)\n",
    "df = orig_to_place_idx(df)\n",
    "df = repl_to_word_idx(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add pre-padding\n",
    "\n",
    "X = pad_sequences(df['x_word'], value = pad).astype('int64')\n",
    "y_rep = pad_sequences(df['y_rep'], value = pad).astype('int64')\n",
    "y_orig = pad_sequences(df['y_orig'], value = pad).astype('int64')\n",
    "\n",
    "# set up target data from output sequence, 1 timestep off from y_rep\n",
    "#y_rep_output\n",
    "\n",
    "y_start = to_categorical(np.array(df['y_start']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_end = to_categorical(np.array(df['y_end']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_rep_cat = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in y_rep]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 256 # I think 512 or 1028 is standard - lessening for memory purposes for now\n",
    "epochs = 50\n",
    "batch_size = len(X)\n",
    "learning_rate = 0.1\n",
    "\n",
    "input_len = X.shape[1]\n",
    "orig_len = y_orig.shape[1]\n",
    "repl_len = y_rep.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input sentences in form of word indices\n",
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "\n",
    "# embedding layer\n",
    "# note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          name = 'embedding_layer')\n",
    "\n",
    "    input_embed = embedding_layer(main_input)\n",
    "    repl_embed = embedding_layer(repl_input)\n",
    "    orig_embed = embedding_layer(orig_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function taken from https://github.com/datalogue/keras-attention/issues/15\n",
    "def _time_distributed_dense(x, w, b=None, dropout=None,\n",
    "                        input_dim=None, output_dim=None,\n",
    "                        timesteps=None, training=None):\n",
    "    \"\"\"Apply `y . w + b` for every temporal slice y of x.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        w: weight matrix.\n",
    "        b: optional bias vector.\n",
    "        dropout: wether to apply dropout (same dropout mask\n",
    "            for every temporal slice of the input).\n",
    "        input_dim: integer; optional dimensionality of the input.\n",
    "        output_dim: integer; optional dimensionality of the output.\n",
    "        timesteps: integer; optional number of timesteps.\n",
    "        training: training phase tensor or boolean.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if not input_dim:\n",
    "        input_dim = K.shape(x)[2]\n",
    "    if not timesteps:\n",
    "        timesteps = K.shape(x)[1]\n",
    "    if not output_dim:\n",
    "        output_dim = K.shape(w)[1]\n",
    "\n",
    "    if dropout is not None and 0. < dropout < 1.:\n",
    "        # apply the same dropout pattern at every timestep\n",
    "        ones = K.ones_like(K.reshape(x[:, 0, :], (-1, input_dim)))\n",
    "        dropout_matrix = K.dropout(ones, dropout)\n",
    "        expanded_dropout_matrix = K.repeat(dropout_matrix, timesteps)\n",
    "        x = K.in_train_phase(x * expanded_dropout_matrix, x, training=training)\n",
    "\n",
    "    # collapse time dimension and batch dimension together\n",
    "    x = K.reshape(x, (-1, input_dim))\n",
    "    x = K.dot(x, w)\n",
    "    if b is not None:\n",
    "        x = K.bias_add(x, b)\n",
    "        \n",
    "    # reshape to 3D tensor\n",
    "    if K.backend() == 'tensorflow':\n",
    "        x = K.reshape(x, K.stack([-1, timesteps, output_dim]))\n",
    "        x.set_shape([None, None, output_dim])\n",
    "    else:\n",
    "        x = K.reshape(x, (-1, timesteps, output_dim))\n",
    "        \n",
    "    return x\n",
    "\n",
    "# pointer network implementation\n",
    "class PointerNet(LSTM):\n",
    "    def __init__(self, units, *args, **kwargs):\n",
    "        super().__init__(units, *args, **kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # immediately set variables for later use\n",
    "        # keep same number as units as encoder LSTM by default\n",
    "        self.num_units = input_shape[2]\n",
    "        self.seq_len = input_shape[1]\n",
    "        \n",
    "        # add trainable attention weights\n",
    "        self.W1 = self.add_weight(name=\"W1\",\n",
    "                                  shape=(self.num_units, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.W2 = self.add_weight(name=\"W2\",\n",
    "                                  shape=(self.num_units, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.vt = self.add_weight(name=\"vt\",\n",
    "                                  shape=(self.seq_len, 1),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        \n",
    "        super(PointerNet, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        initial_state = self.get_initial_state(x)\n",
    "                \n",
    "        pointer, _, _ = K.rnn(self.step, x, initial_state, \n",
    "                              constants = [x], input_length = self.seq_len)\n",
    "        \n",
    "        return pointer # only need 1 pointer for whole sequence, so h/c don't matter for this task\n",
    "    \n",
    "    def step(self, x_input, states):\n",
    "        # x_input = original input at current time stamp (batch_size, num_units)\n",
    "        # states = 3 tensors:\n",
    "        # states[0] = h hidden state (batch_size, num_units)\n",
    "        # states[1] = c cell state/memory (batch_size, num_units)\n",
    "        # states[2] = x next word input (batch_size, seq_len, num_units)        \n",
    "        encoded = states[2]\n",
    "        _, [h, c] = self.cell.call(x_input, states[0:2])\n",
    "        decoded = K.repeat(h, self.seq_len)\n",
    "\n",
    "        # vt*tanh(W1*e+W2*d)\n",
    "        W1_eij = _time_distributed_dense(encoded, self.W1, output_dim=1)\n",
    "        W2_dij = _time_distributed_dense(decoded, self.W2, output_dim=1)\n",
    "        U = self.vt * tanh(W1_eij + W2_dij)\n",
    "        U = K.squeeze(U, 2) # removes a 1-dimension at 2nd axis\n",
    "\n",
    "        # softmax over U to get probability distribution over input length\n",
    "        pointer = softmax(U)\n",
    "        return pointer, [h, c]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # input shape should be (batch_size, seq_len, units)\n",
    "        # output shape should be (batch_size, seq_len)\n",
    "        return (input_shape[0], input_shape[1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get indices\n",
    "\n",
    "lstm = LSTM(return_sequences = True, units = num_units, name = 'lstm')(input_embed)\n",
    "\n",
    "y_start_output = PointerNet(units = num_units, activation=\"softmax\", input_shape = (batch_size, input_len, num_units), name = 'y_start_output')(lstm)\n",
    "y_end_output = PointerNet(units = num_units, activation=\"softmax\", input_shape = (batch_size, input_len, num_units), name = 'y_end_output')(lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### connect indices to main_input\n",
    "\n",
    "## later use this to slice and concatenate with context\n",
    "## in the meantime just assume y_orig is somehow the output\n",
    "\n",
    "#y_indices = concatenate([K.argmax(y_start_output, axis = 1), K.argmax(y_end_output, axis = 1)])\n",
    "y_start_sparse = Lambda(lambda x : K.argmax(x, axis = 1))(y_start_output)\n",
    "y_end_sparse = Lambda(lambda x : K.argmax(x, axis = 1))(y_end_output)\n",
    "y_start_reshape = Reshape((1,))(y_start_sparse)\n",
    "y_end_reshape = Reshape((1,))(y_end_sparse)\n",
    "y_indices = K.cast(concatenate([y_start_reshape, y_end_reshape]), 'int32')\n",
    "#return_input = concatenate([y_start_reshape, y_end_reshape, main_input], axis = 1)\n",
    "return_input = tf.gather_nd(input_embed, y_indices)\n",
    "\n",
    "# https://stackoverflow.com/questions/50820639/keras-how-to-slice-tensor-using-information-from-another-tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_input)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "\n",
    "y_rep_output = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), \n",
    "                               name = 'y_rep_output')(dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### define & train model\n",
    "\n",
    "# other parameters\n",
    "# https://keras.io/examples/lstm_seq2seq/\n",
    "\n",
    "model = Model(inputs = [main_input, orig_input, repl_input], outputs = [y_start_output, y_end_output, y_rep_output])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit([X, y_orig, y_rep], [y_start, y_end, y_rep_cat], epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['y_start_output_acc'], label='y_start accuracy')\n",
    "plt.plot(history.history['y_end_output_acc'], label='y_end accuracy')\n",
    "plt.plot(history.history['y_rep_output_acc'], label='y_rep accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='overall train loss')\n",
    "plt.plot(history.history['y_start_output_loss'], label='y_start loss')\n",
    "plt.plot(history.history['y_end_output_loss'], label='y_end loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_nmt(hidden_size, batch_size, en_timesteps, en_vsize, fr_timesteps, fr_vsize):\n",
    "    \"\"\" Defining a NMT model \"\"\"\n",
    "\n",
    "    # Define an input sequence and process it.\n",
    "    if batch_size:\n",
    "        encoder_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize), name='encoder_inputs')\n",
    "        decoder_inputs = Input(batch_shape=(batch_size, fr_timesteps - 1, fr_vsize), name='decoder_inputs')\n",
    "    else:\n",
    "        encoder_inputs = Input(shape=(en_timesteps, en_vsize), name='encoder_inputs')\n",
    "        decoder_inputs = Input(shape=(fr_timesteps - 1, fr_vsize), name='decoder_inputs')\n",
    "\n",
    "    # Encoder GRU\n",
    "    encoder_gru = Bidirectional(GRU(hidden_size, return_sequences=True, return_state=True, name='encoder_gru'), name='bidirectional_encoder')\n",
    "    encoder_out, encoder_fwd_state, encoder_back_state = encoder_gru(encoder_inputs)\n",
    "\n",
    "    # Set up the decoder GRU, using `encoder_states` as initial state.\n",
    "    decoder_gru = Bidirectional(GRU(hidden_size, return_sequences=True, return_state=True, name='decoder_gru'), name='bidirectional_decoder')\n",
    "    decoder_out, decoder_fwd_state, decoder_back_state = decoder_gru(decoder_inputs, initial_state=[encoder_fwd_state, encoder_back_state])\n",
    "\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    dense = Dense(fr_vsize, activation='softmax', name='softmax_layer')\n",
    "    dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
    "    decoder_pred = dense_time(decoder_concat_input)\n",
    "\n",
    "    # Full model\n",
    "    full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "    full_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    full_model.summary()\n",
    "\n",
    "    \"\"\" Inference model \"\"\"\n",
    "    batch_size = 1\n",
    "\n",
    "    \"\"\" Encoder (Inference) model \"\"\"\n",
    "    encoder_inf_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize), name='encoder_inf_inputs')\n",
    "    encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state = encoder_gru(encoder_inf_inputs)\n",
    "    encoder_model = Model(inputs=encoder_inf_inputs, outputs=[encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state])\n",
    "\n",
    "    \"\"\" Decoder (Inference) model \"\"\"\n",
    "    decoder_inf_inputs = Input(batch_shape=(batch_size, 1, fr_vsize), name='decoder_word_inputs')\n",
    "    encoder_inf_states = Input(batch_shape=(batch_size, en_timesteps, 2*hidden_size), name='encoder_inf_states')\n",
    "    decoder_init_fwd_state = Input(batch_shape=(batch_size, hidden_size), name='decoder_fwd_init')\n",
    "    decoder_init_back_state = Input(batch_shape=(batch_size, hidden_size), name='decoder_back_init')\n",
    "\n",
    "    decoder_inf_out, decoder_inf_fwd_state, decoder_inf_back_state = decoder_gru(decoder_inf_inputs, initial_state=[decoder_init_fwd_state, decoder_init_back_state])\n",
    "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "    decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "    decoder_model = Model(inputs=[encoder_inf_states, decoder_init_fwd_state, decoder_init_back_state, decoder_inf_inputs],\n",
    "                          outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_fwd_state, decoder_inf_back_state])\n",
    "\n",
    "    return full_model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/oarriaga/7ac353a70fd68f953514f4d404c203ae\n",
    "# https://machinelearningmastery.com/encoder-decoder-attention-sequence-to-sequence-prediction-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
