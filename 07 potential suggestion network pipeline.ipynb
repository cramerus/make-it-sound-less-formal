{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm import tqdm_pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Embedding, LSTM, Dense, Dropout, Layer, Concatenate\n",
    "from keras.layers import TimeDistributed, Bidirectional, Lambda\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.core import Reshape\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.engine import InputSpec\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure gpu is available\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import embedding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# pretrained GloVe embeddings unpacked\n",
    "\n",
    "file = 'glove.6B.300d.txt'\n",
    "embed_dim = 300\n",
    "\n",
    "w2idx = {}\n",
    "w2vec = {}\n",
    "\n",
    "with open(file) as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        line = [part.strip() for part in line.split()]\n",
    "        word = line[0]\n",
    "        vec = np.asarray(line[1 : embed_dim + 1], dtype='float32')\n",
    "        \n",
    "        w2idx[word] = idx\n",
    "        w2vec[word] = vec\n",
    "        \n",
    "# include empty character for padding - put last\n",
    "w2idx[''] = len(w2idx)\n",
    "w2vec[''] = np.zeros(embed_dim)\n",
    "\n",
    "# create embedding matrix\n",
    "embeddings = np.zeros((len(w2idx), embed_dim))\n",
    "\n",
    "for word, idx in w2idx.items():\n",
    "    embeddings[idx] = np.array(w2vec[word])\n",
    "    \n",
    "# save\n",
    "with open('glv_embed_matrix.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "    \n",
    "with open('glv_w2idx.pkl', 'wb') as f:\n",
    "    pickle.dump(w2idx, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not</td>\n",
       "      <td>don't</td>\n",
       "      <td>I do not know what to say.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not</td>\n",
       "      <td>won't</td>\n",
       "      <td>The girl will not go to bed.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Replacement                      Sentence\n",
       "0    do not       don't    I do not know what to say.\n",
       "1  will not       won't  The girl will not go to bed."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# placeholder dataset\n",
    "\n",
    "df = pd.DataFrame({'Sentence': [\"I do not know what to say.\", \"The girl will not go to bed.\"], \n",
    "                  'Original': [\"do not\", \"will not\"],\n",
    "                  'Replacement': [\"don't\", \"won't\"]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "def sent_to_word_idx(df):\n",
    "    new = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        \n",
    "        sent = word_tokenize(row['Sentence'])\n",
    "        \n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        \n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "                                \n",
    "        new.append(sent_indices)\n",
    "    \n",
    "    df['x_word'] = new\n",
    "    return df\n",
    "\n",
    "def orig_to_place_idx(df):\n",
    "    # takes the part of the sentence to be replaced and turns it into a pair of start/end indices\n",
    "    \n",
    "    y_start = []\n",
    "    y_end = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Original'])\n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "        \n",
    "        # take indices and find the slice in the whole sentence\n",
    "        slice_length = len(sent_indices)\n",
    "        starts = [i for i, x in enumerate(row['x_word']) if x == sent_indices[0]]\n",
    "        slice_idx = np.nan\n",
    "        \n",
    "        for potential_start in starts:\n",
    "            potential_slice = row['x_word'][potential_start : potential_start + slice_length]\n",
    "            if (potential_slice == np.array(sent_indices)).all():\n",
    "                y_start.append(potential_start)\n",
    "                y_end.append(potential_start + slice_length - 1)\n",
    "                break\n",
    "            \n",
    "    df['y_start'] = y_start\n",
    "    df['y_end'] = y_end\n",
    "    return df\n",
    "\n",
    "def repl_to_word_idx(df):\n",
    "    # takes original & replacement texts and turns them into both decoder input and decoder output\n",
    "    # both so that teacher forcing can be done\n",
    "    \n",
    "    y_rep = []\n",
    "    y_orig = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Replacement'])\n",
    "                \n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        \n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "                \n",
    "        y_rep.append(sent_indices)\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        sent = word_tokenize(row['Original'])\n",
    "                \n",
    "        # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to all texts\n",
    "        sent = ['\\t'] + sent + ['\\n']\n",
    "        \n",
    "        sent_indices = []\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word in w2idx:\n",
    "                sent_indices.append(w2idx[word])\n",
    "            else:\n",
    "                sent_indices.append(len(w2idx))\n",
    "        y_orig.append(sent_indices)\n",
    "        \n",
    "    df['y_orig'] = y_orig\n",
    "    df['y_rep'] = y_rep\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266742582ef8429bbc77a89f6d614117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea834d1128764de2a2a8a400052e4846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b36aa105b6448a091a927405284a839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40609809cb454a3590baa827e39cea85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>x_word</th>\n",
       "      <th>y_start</th>\n",
       "      <th>y_end</th>\n",
       "      <th>y_orig</th>\n",
       "      <th>y_rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do not</td>\n",
       "      <td>don't</td>\n",
       "      <td>I do not know what to say.</td>\n",
       "      <td>[400001, 41, 88, 36, 346, 102, 4, 203, 2, 400002]</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[400001, 88, 36, 400002]</td>\n",
       "      <td>[400001, 88, 70, 400002]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>will not</td>\n",
       "      <td>won't</td>\n",
       "      <td>The girl will not go to bed.</td>\n",
       "      <td>[400001, 0, 1749, 43, 36, 242, 4, 3827, 2, 400...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[400001, 43, 36, 400002]</td>\n",
       "      <td>[400001, 1369, 70, 400002]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Original Replacement                      Sentence  \\\n",
       "0    do not       don't    I do not know what to say.   \n",
       "1  will not       won't  The girl will not go to bed.   \n",
       "\n",
       "                                              x_word  y_start  y_end  \\\n",
       "0  [400001, 41, 88, 36, 346, 102, 4, 203, 2, 400002]        2      3   \n",
       "1  [400001, 0, 1749, 43, 36, 242, 4, 3827, 2, 400...        3      4   \n",
       "\n",
       "                     y_orig                       y_rep  \n",
       "0  [400001, 88, 36, 400002]    [400001, 88, 70, 400002]  \n",
       "1  [400001, 43, 36, 400002]  [400001, 1369, 70, 400002]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sent_to_word_idx(df)\n",
    "df = orig_to_place_idx(df)\n",
    "df = repl_to_word_idx(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add pre-padding\n",
    "\n",
    "X = pad_sequences(df['x_word'], value = len(w2idx)).astype('int64')\n",
    "y_rep = pad_sequences(df['y_rep'], value = len(w2idx)).astype('int64')\n",
    "y_orig = pad_sequences(df['y_orig'], value = len(w2idx)).astype('int64')\n",
    "\n",
    "# set up target data from output sequence, 1 timestep off from y_rep\n",
    "#y_rep_output\n",
    "\n",
    "y_start = to_categorical(np.array(df['y_start']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_end = to_categorical(np.array(df['y_end']), num_classes = X.shape[1], dtype = 'int64')\n",
    "y_rep_cat = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in y_rep]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 128 # I think 512 or 1028 is standard - lessening for memory purposes for now\n",
    "epochs = 50\n",
    "batch_size = 2\n",
    "learning_rate = 0.1\n",
    "\n",
    "input_len = X.shape[1]\n",
    "orig_len = y_orig.shape[1]\n",
    "repl_len = y_rep.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# input sentences in form of word indices\n",
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "\n",
    "# embedding layer\n",
    "# note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                      output_dim = embedding.shape[1],\n",
    "                      weights = [embedding],\n",
    "                      trainable = False, \n",
    "                      name = 'embedding_layer')\n",
    "\n",
    "input_embed = embedding_layer(main_input)\n",
    "repl_embed = embedding_layer(repl_input)\n",
    "orig_embed = embedding_layer(orig_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define PtrNetLSTM\n",
    "\n",
    "class PtrNetLSTM(LSTM):\n",
    "    # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(PtrNetLSTM, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        super(PtrNetLSTM, self).build(input_shape)\n",
    "        pass\n",
    "    \n",
    "    def call(self, x):\n",
    "        pass\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        pass\n",
    "\n",
    "'''\n",
    "class PointerLSTM(LSTM):\n",
    "#    def __init__(self, hidden_shape, *args, **kwargs):\n",
    "        self.hidden_shape = hidden_shape\n",
    "        self.input_length = []\n",
    "#        super(PointerLSTM, self).__init__(*args, **kwargs)\n",
    "\n",
    "#    def get_initial_states(self, x_input):\n",
    "#        return Recurrent.get_initial_state(self, x_input)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PointerLSTM, self).build(input_shape)\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.W1 = self.add_weight(name=\"W1\",\n",
    "                                  shape=(self.hidden_shape, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.W2 = self.add_weight(name=\"W2\",\n",
    "                                  shape=(self.hidden_shape, 1),\n",
    "                                  initializer=\"uniform\",\n",
    "                                  trainable=True)\n",
    "        self.vt = self.add_weight(name=\"vt\",\n",
    "                                  shape=(input_shape[1], 1),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        #self.trainable_weights += [self.W1, self.W2, self.vt]\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        en_seq = x\n",
    "        x_input = x[:, input_shape[1] - 1, :]\n",
    "        x_input = K.repeat(x_input, input_shape[1])\n",
    "        initial_states = self.get_initial_states(x_input)\n",
    "\n",
    "        constants = super(PointerLSTM, self).get_constants(x_input)\n",
    "        constants.append(en_seq)\n",
    "        preprocessed_input = self.preprocess_input(x_input)\n",
    "\n",
    "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
    "                                             initial_states,\n",
    "                                             go_backwards=self.go_backwards,\n",
    "                                             constants=constants,\n",
    "                                             input_length=input_shape[1])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def step(self, x_input, states):\n",
    "        # print \"x_input:\", x_input, x_input.shape\n",
    "        # <TensorType(float32, matrix)>\n",
    "\n",
    "        input_shape = self.input_spec[0].shape\n",
    "        en_seq = states[-1]\n",
    "        _, [h, c] = super(PointerLSTM, self).step(x_input, states[:-1])\n",
    "\n",
    "        # vt*tanh(W1*e+W2*d)\n",
    "        dec_seq = K.repeat(h, input_shape[1])\n",
    "        Eij = TimeDistributed(Dense(en_seq, self.W1, output_dim=1))\n",
    "        Dij = TimeDistributed(Dense(dec_seq, self.W2, output_dim=1))\n",
    "        U = self.vt * tanh(Eij + Dij)\n",
    "        U = K.squeeze(U, 2)\n",
    "\n",
    "        # make probability tensor\n",
    "        pointer = softmax(U)\n",
    "        return pointer, [h, c]\n",
    "\n",
    "#    def get_output_shape_for(self, input_shape):\n",
    "#        # output shape is not affected by the attention component\n",
    "#        return (input_shape[0], input_shape[1], input_shape[1])\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1], input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get indices\n",
    "\n",
    "lstm = LSTM(return_sequences = False, units = num_units, name = 'lstm')(input_embed)\n",
    "# lstm = LSTM(return_sequences = True, units = num_units, name = 'lstm')(input_embed)\n",
    "\n",
    "y_start_output = Dense(input_len, activation = 'softmax', name = 'y_start_output')(lstm)\n",
    "y_end_output = Dense(input_len, activation = 'softmax', name = 'y_end_output')(lstm)\n",
    "# y_start_output = PointerLSTM(input_len, activation = 'softmax', name = 'y_start_output')(lstm)\n",
    "# y_end_output = PointerLSTM(input_len, activation = 'softmax', name = 'y_end_output')(lstm)\n",
    "# change inputs to (hidden_shape = num_units, units = num_units) ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### connect indices to main_input\n",
    "\n",
    "## later use this to slice and concatenate with context\n",
    "## in the meantime just assume y_orig is somehow the output\n",
    "\n",
    "#y_indices = concatenate([K.argmax(y_start_output, axis = 1), K.argmax(y_end_output, axis = 1)])\n",
    "#y_start_sparse = Lambda(lambda x : K.argmax(x, axis = 1))(y_start_output)\n",
    "#y_end_sparse = Lambda(lambda x : K.argmax(x, axis = 1))(y_end_output)\n",
    "#y_start_reshape = Reshape((1,))(y_start_sparse)\n",
    "#y_end_reshape = Reshape((1,))(y_end_sparse)\n",
    "#return_input = concatenate([y_start_reshape, y_end_reshape, main_input], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_embed)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "\n",
    "y_rep_output = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), \n",
    "                               name = 'y_rep_output')(dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 7s 3s/step - loss: 17.2116 - y_start_output_loss: 2.1692 - y_end_output_loss: 2.1433 - y_rep_output_loss: 12.8991 - y_start_output_acc: 0.0000e+00 - y_end_output_acc: 0.5000 - y_rep_output_acc: 0.0000e+00\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 15.9660 - y_start_output_loss: 1.5652 - y_end_output_loss: 1.5484 - y_rep_output_loss: 12.8524 - y_start_output_acc: 1.0000 - y_end_output_acc: 0.5000 - y_rep_output_acc: 0.7500\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 14.9787 - y_start_output_loss: 1.0974 - y_end_output_loss: 1.0897 - y_rep_output_loss: 12.7916 - y_start_output_acc: 1.0000 - y_end_output_acc: 0.5000 - y_rep_output_acc: 0.7500\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 14.2311 - y_start_output_loss: 0.7654 - y_end_output_loss: 0.7684 - y_rep_output_loss: 12.6973 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 13.6516 - y_start_output_loss: 0.5409 - y_end_output_loss: 0.5521 - y_rep_output_loss: 12.5586 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 13.1602 - y_start_output_loss: 0.3862 - y_end_output_loss: 0.4038 - y_rep_output_loss: 12.3702 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 12.7043 - y_start_output_loss: 0.2750 - y_end_output_loss: 0.2972 - y_rep_output_loss: 12.1322 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 12.2502 - y_start_output_loss: 0.1913 - y_end_output_loss: 0.2137 - y_rep_output_loss: 11.8452 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 11.7793 - y_start_output_loss: 0.1260 - y_end_output_loss: 0.1451 - y_rep_output_loss: 11.5082 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 11.2884 - y_start_output_loss: 0.0773 - y_end_output_loss: 0.0920 - y_rep_output_loss: 11.1191 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 10.7808 - y_start_output_loss: 0.0453 - y_end_output_loss: 0.0554 - y_rep_output_loss: 10.6801 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 10.2571 - y_start_output_loss: 0.0260 - y_end_output_loss: 0.0324 - y_rep_output_loss: 10.1987 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.7322 - y_start_output_loss: 0.0149 - y_end_output_loss: 0.0185 - y_rep_output_loss: 9.6988 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9.2184 - y_start_output_loss: 0.0086 - y_end_output_loss: 0.0106 - y_rep_output_loss: 9.1992 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 8.7148 - y_start_output_loss: 0.0051 - y_end_output_loss: 0.0062 - y_rep_output_loss: 8.7034 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 8.2223 - y_start_output_loss: 0.0032 - y_end_output_loss: 0.0038 - y_rep_output_loss: 8.2154 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 7.7439 - y_start_output_loss: 0.0021 - y_end_output_loss: 0.0024 - y_rep_output_loss: 7.7394 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 7.2727 - y_start_output_loss: 0.0015 - y_end_output_loss: 0.0016 - y_rep_output_loss: 7.2697 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 6.8059 - y_start_output_loss: 0.0011 - y_end_output_loss: 0.0011 - y_rep_output_loss: 6.8037 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 6.3406 - y_start_output_loss: 8.0807e-04 - y_end_output_loss: 8.2148e-04 - y_rep_output_loss: 6.3389 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 5.8739 - y_start_output_loss: 6.3731e-04 - y_end_output_loss: 6.2339e-04 - y_rep_output_loss: 5.8726 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 5.4056 - y_start_output_loss: 5.1719e-04 - y_end_output_loss: 4.8781e-04 - y_rep_output_loss: 5.4046 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 4.9372 - y_start_output_loss: 4.3123e-04 - y_end_output_loss: 3.9228e-04 - y_rep_output_loss: 4.9363 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 4.4710 - y_start_output_loss: 3.6793e-04 - y_end_output_loss: 3.2415e-04 - y_rep_output_loss: 4.4703 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 4.0113 - y_start_output_loss: 3.2040e-04 - y_end_output_loss: 2.7398e-04 - y_rep_output_loss: 4.0107 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.5635 - y_start_output_loss: 2.8376e-04 - y_end_output_loss: 2.3577e-04 - y_rep_output_loss: 3.5629 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.1346 - y_start_output_loss: 2.5455e-04 - y_end_output_loss: 2.0605e-04 - y_rep_output_loss: 3.1342 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 2.7341 - y_start_output_loss: 2.3085e-04 - y_end_output_loss: 1.8250e-04 - y_rep_output_loss: 2.7337 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2.3718 - y_start_output_loss: 2.1159e-04 - y_end_output_loss: 1.6381e-04 - y_rep_output_loss: 2.3714 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2.0572 - y_start_output_loss: 1.9567e-04 - y_end_output_loss: 1.4861e-04 - y_rep_output_loss: 2.0568 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 1.7952 - y_start_output_loss: 1.8211e-04 - y_end_output_loss: 1.3609e-04 - y_rep_output_loss: 1.7948 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 1.5849 - y_start_output_loss: 1.7067e-04 - y_end_output_loss: 1.2580e-04 - y_rep_output_loss: 1.5846 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 1.4206 - y_start_output_loss: 1.6092e-04 - y_end_output_loss: 1.1719e-04 - y_rep_output_loss: 1.4203 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 1.2936 - y_start_output_loss: 1.5257e-04 - y_end_output_loss: 1.0992e-04 - y_rep_output_loss: 1.2934 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 1.0000\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 1.1956 - y_start_output_loss: 1.4524e-04 - y_end_output_loss: 1.0369e-04 - y_rep_output_loss: 1.1953 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 1.1194 - y_start_output_loss: 1.3883e-04 - y_end_output_loss: 9.8353e-05 - y_rep_output_loss: 1.1191 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 1.0593 - y_start_output_loss: 1.3320e-04 - y_end_output_loss: 9.3703e-05 - y_rep_output_loss: 1.0591 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 1.0113 - y_start_output_loss: 1.2828e-04 - y_end_output_loss: 8.9620e-05 - y_rep_output_loss: 1.0111 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.9725 - y_start_output_loss: 1.2393e-04 - y_end_output_loss: 8.6013e-05 - y_rep_output_loss: 0.9722 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.8750\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.9407 - y_start_output_loss: 1.2002e-04 - y_end_output_loss: 8.2914e-05 - y_rep_output_loss: 0.9405 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.9144 - y_start_output_loss: 1.1648e-04 - y_end_output_loss: 8.0231e-05 - y_rep_output_loss: 0.9142 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.8926 - y_start_output_loss: 1.1338e-04 - y_end_output_loss: 7.7757e-05 - y_rep_output_loss: 0.8924 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.8738 - y_start_output_loss: 1.1057e-04 - y_end_output_loss: 7.5582e-05 - y_rep_output_loss: 0.8736 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.8573 - y_start_output_loss: 1.0804e-04 - y_end_output_loss: 7.3644e-05 - y_rep_output_loss: 0.8571 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8426 - y_start_output_loss: 1.0575e-04 - y_end_output_loss: 7.1945e-05 - y_rep_output_loss: 0.8424 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.8286 - y_start_output_loss: 1.0369e-04 - y_end_output_loss: 7.0396e-05 - y_rep_output_loss: 0.8284 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.8154 - y_start_output_loss: 1.0181e-04 - y_end_output_loss: 6.8965e-05 - y_rep_output_loss: 0.8153 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.8028 - y_start_output_loss: 1.0002e-04 - y_end_output_loss: 6.7683e-05 - y_rep_output_loss: 0.8026 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7905 - y_start_output_loss: 9.8413e-05 - y_end_output_loss: 6.6581e-05 - y_rep_output_loss: 0.7903 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.7781 - y_start_output_loss: 9.6922e-05 - y_end_output_loss: 6.5418e-05 - y_rep_output_loss: 0.7780 - y_start_output_acc: 1.0000 - y_end_output_acc: 1.0000 - y_rep_output_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "#### define & train model\n",
    "\n",
    "model = Model(inputs = [main_input, orig_input, repl_input], outputs = [y_start_output, y_end_output, y_rep_output])\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit([X, y_orig, y_rep], [y_start, y_end, y_rep_cat], epochs = epochs, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "main_input (InputLayer)         (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "repl_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "orig_input (InputLayer)         (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   main_input[0][0]                 \n",
      "                                                                 repl_input[0][0]                 \n",
      "                                                                 orig_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Bidirectional)         [(None, 128), (None, 186880      embedding_layer[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           encoder[0][1]                    \n",
      "                                                                 encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           encoder[0][2]                    \n",
      "                                                                 encoder[0][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (Bidirectional)            (None, 128)          186880      embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  [(None, 4, 128), (No 219648      embedding_layer[1][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "y_start_output (Dense)          (None, 10)           1290        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "y_end_output (Dense)            (None, 10)           1290        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "y_rep_output (TimeDistributed)  (None, 4, 400003)    51600387    decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 172,197,275\n",
      "Trainable params: 52,196,375\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f483fc1ac50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['y_start_output_acc'], label='y_start accuracy')\n",
    "plt.plot(history.history['y_end_output_acc'], label='y_end accuracy')\n",
    "plt.plot(history.history['y_rep_output_acc'], label='y_rep accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f483fb96710>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='overall train loss')\n",
    "plt.plot(history.history['y_start_output_loss'], label='y_start loss')\n",
    "plt.plot(history.history['y_end_output_loss'], label='y_end loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/light-on-math-ml-attention-with-keras-dc8dbc1fad39\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
    "            if verbose:\n",
    "                print('wa.s>',W_a_dot_s.shape)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>',U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "\n",
    "        def create_inital_state(inputs, hidden_size):\n",
    "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
    "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
    "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
    "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
    "            return fake_state\n",
    "\n",
    "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
    "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_nmt(hidden_size, batch_size, en_timesteps, en_vsize, fr_timesteps, fr_vsize):\n",
    "    \"\"\" Defining a NMT model \"\"\"\n",
    "\n",
    "    # Define an input sequence and process it.\n",
    "    if batch_size:\n",
    "        encoder_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize), name='encoder_inputs')\n",
    "        decoder_inputs = Input(batch_shape=(batch_size, fr_timesteps - 1, fr_vsize), name='decoder_inputs')\n",
    "    else:\n",
    "        encoder_inputs = Input(shape=(en_timesteps, en_vsize), name='encoder_inputs')\n",
    "        decoder_inputs = Input(shape=(fr_timesteps - 1, fr_vsize), name='decoder_inputs')\n",
    "\n",
    "    # Encoder GRU\n",
    "    encoder_gru = Bidirectional(GRU(hidden_size, return_sequences=True, return_state=True, name='encoder_gru'), name='bidirectional_encoder')\n",
    "    encoder_out, encoder_fwd_state, encoder_back_state = encoder_gru(encoder_inputs)\n",
    "\n",
    "    # Set up the decoder GRU, using `encoder_states` as initial state.\n",
    "    decoder_gru = Bidirectional(GRU(hidden_size, return_sequences=True, return_state=True, name='decoder_gru'), name='bidirectional_decoder')\n",
    "    decoder_out, decoder_fwd_state, decoder_back_state = decoder_gru(decoder_inputs, initial_state=[encoder_fwd_state, encoder_back_state])\n",
    "\n",
    "    # Attention layer\n",
    "    attn_layer = AttentionLayer(name='attention_layer')\n",
    "    attn_out, attn_states = attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "    # Concat attention input and decoder GRU output\n",
    "    decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_out, attn_out])\n",
    "\n",
    "    # Dense layer\n",
    "    dense = Dense(fr_vsize, activation='softmax', name='softmax_layer')\n",
    "    dense_time = TimeDistributed(dense, name='time_distributed_layer')\n",
    "    decoder_pred = dense_time(decoder_concat_input)\n",
    "\n",
    "    # Full model\n",
    "    full_model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_pred)\n",
    "    full_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    full_model.summary()\n",
    "\n",
    "    \"\"\" Inference model \"\"\"\n",
    "    batch_size = 1\n",
    "\n",
    "    \"\"\" Encoder (Inference) model \"\"\"\n",
    "    encoder_inf_inputs = Input(batch_shape=(batch_size, en_timesteps, en_vsize), name='encoder_inf_inputs')\n",
    "    encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state = encoder_gru(encoder_inf_inputs)\n",
    "    encoder_model = Model(inputs=encoder_inf_inputs, outputs=[encoder_inf_out, encoder_inf_fwd_state, encoder_inf_back_state])\n",
    "\n",
    "    \"\"\" Decoder (Inference) model \"\"\"\n",
    "    decoder_inf_inputs = Input(batch_shape=(batch_size, 1, fr_vsize), name='decoder_word_inputs')\n",
    "    encoder_inf_states = Input(batch_shape=(batch_size, en_timesteps, 2*hidden_size), name='encoder_inf_states')\n",
    "    decoder_init_fwd_state = Input(batch_shape=(batch_size, hidden_size), name='decoder_fwd_init')\n",
    "    decoder_init_back_state = Input(batch_shape=(batch_size, hidden_size), name='decoder_back_init')\n",
    "\n",
    "    decoder_inf_out, decoder_inf_fwd_state, decoder_inf_back_state = decoder_gru(decoder_inf_inputs, initial_state=[decoder_init_fwd_state, decoder_init_back_state])\n",
    "    attn_inf_out, attn_inf_states = attn_layer([encoder_inf_states, decoder_inf_out])\n",
    "    decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_inf_out, attn_inf_out])\n",
    "    decoder_inf_pred = TimeDistributed(dense)(decoder_inf_concat)\n",
    "    decoder_model = Model(inputs=[encoder_inf_states, decoder_init_fwd_state, decoder_init_back_state, decoder_inf_inputs],\n",
    "                          outputs=[decoder_inf_pred, attn_inf_states, decoder_inf_fwd_state, decoder_inf_back_state])\n",
    "\n",
    "    return full_model, encoder_model, decoder_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
