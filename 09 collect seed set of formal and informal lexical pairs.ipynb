{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from glob import glob\n",
    "import gensim\n",
    "import xml.etree.ElementTree as ET\n",
    "from ast import literal_eval\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put existing acrolinx gzt and files into pd df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('data/acrolinx_gzt/lf.json') as lfjson:\n",
    "    lf = json.load(lfjson)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('data/acrolinx_gzt/conv-words.json') as cvjson:\n",
    "    form_with_sugg = json.load(cvjson)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "unclean_gzt = []\n",
    "\n",
    "with open('data/acrolinx_gzt/archaicWords.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countFormalPhrases.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countLatinExpressions.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gzt = {}\n",
    "\n",
    "# things i noticed and don't want\n",
    "exceptions = ['use either', '(']\n",
    "\n",
    "for item in unclean_gzt:\n",
    "    if item[0] == '@' or item[0] == '#':\n",
    "        continue\n",
    "    item = item.strip()\n",
    "    if len(item) < 1:\n",
    "        continue\n",
    "    trigger = False\n",
    "    for term in exceptions:\n",
    "        if term in item:\n",
    "            trigger = True\n",
    "    if trigger:\n",
    "        continue\n",
    "    item = re.sub('\\[', '', item)\n",
    "    item = re.sub('\\]', '', item)\n",
    "    item = re.sub('\\n', '', item)\n",
    "    item = re.sub(';', '', item)\n",
    "    if '-->' in item:\n",
    "        pair = [part.strip() for part in item.split('-->')]\n",
    "        if ',' in pair[0]:\n",
    "            form_words = [part.strip() for part in pair[0].split(',')]\n",
    "            for word in form_words:\n",
    "                gzt[word] = [part.strip() for part in pair[1].split(',')]\n",
    "        else:\n",
    "            gzt[pair[0]] = [part.strip() for part in pair[1].split(',')]\n",
    "    else:\n",
    "        gzt[item] = np.nan\n",
    "        \n",
    "# There are 597 items."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "formal = []\n",
    "informal = []\n",
    "\n",
    "for word in gzt:\n",
    "    formal.append(word)\n",
    "    informal.append(gzt[word])\n",
    "\n",
    "words = pd.DataFrame()\n",
    "words['formal'] = formal\n",
    "words['suggestions'] = informal\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words.to_pickle('data/acrolinx_gzt/clean_words.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add microsoft words to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/microsoft/words.pkl', 'rb') as f:\n",
    "    mic_words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doe',\n",
       " 'on the other hand',\n",
       " 'ensuring',\n",
       " 'supported',\n",
       " 'architecture',\n",
       " 'grant',\n",
       " 'liaison',\n",
       " 'unrestricted',\n",
       " 'publish',\n",
       " 'xxxxx',\n",
       " 'enumerated',\n",
       " 'warrants',\n",
       " 'mobility',\n",
       " 'operation',\n",
       " 'excluding',\n",
       " 'confirm',\n",
       " 'multi-hop',\n",
       " 'decreased',\n",
       " 'substantial',\n",
       " 'in the event of',\n",
       " 'input',\n",
       " 'vice-versa',\n",
       " 'isolated',\n",
       " 'maximum',\n",
       " 'limitation',\n",
       " 'on a daily basis',\n",
       " 'entails',\n",
       " 'authorizing',\n",
       " 'enrichment',\n",
       " 'review',\n",
       " 'requested',\n",
       " 'strategize',\n",
       " 'override',\n",
       " 'anticipate',\n",
       " 'temperature',\n",
       " 'inquires',\n",
       " 'attain',\n",
       " 'reflect',\n",
       " 'partitioning',\n",
       " 'reside',\n",
       " 'expose',\n",
       " 'replicas',\n",
       " 'distribution',\n",
       " 'location',\n",
       " 'decreasing',\n",
       " 'binding',\n",
       " 'ascertaining',\n",
       " 'lest',\n",
       " 'recovery',\n",
       " 'provides guidance for',\n",
       " 'inception',\n",
       " 'datasets',\n",
       " 'prompt',\n",
       " 'in the case of',\n",
       " 'verification',\n",
       " 'releases',\n",
       " 'reports',\n",
       " 'item',\n",
       " 'contains',\n",
       " 'zones',\n",
       " 'constitutes',\n",
       " 'condition',\n",
       " 'in addition',\n",
       " 'transit',\n",
       " 'eg',\n",
       " 'possess',\n",
       " 'factors',\n",
       " 'percentage',\n",
       " 'aggregate',\n",
       " 'terminated',\n",
       " 'configurations',\n",
       " 'expedites',\n",
       " 'modified',\n",
       " 'in accordance with',\n",
       " 'discovering',\n",
       " 'requirements',\n",
       " 'endorses',\n",
       " 'were not',\n",
       " 'department',\n",
       " 'framework',\n",
       " 'definition',\n",
       " 'we are',\n",
       " 'ascertain',\n",
       " 'precondition',\n",
       " 'climate',\n",
       " 'diagnostic',\n",
       " 'amongst',\n",
       " 'adjustment',\n",
       " 'substitute',\n",
       " 'computes',\n",
       " 'exhibits',\n",
       " 'result',\n",
       " 'should not',\n",
       " 'retention',\n",
       " 'cornerstone',\n",
       " 'migrated',\n",
       " 'nonce',\n",
       " 'evidenced',\n",
       " 'omitting',\n",
       " 'purchase',\n",
       " 'protections',\n",
       " 'regulations',\n",
       " 'specifying',\n",
       " 'are writing to',\n",
       " 'request',\n",
       " 'if and when',\n",
       " 'equivalent',\n",
       " 'equally as',\n",
       " 'pertaining to',\n",
       " 'adjustments',\n",
       " 'on behalf of',\n",
       " 'maps',\n",
       " 'sources',\n",
       " 'reflected',\n",
       " 'delaying',\n",
       " 'notification',\n",
       " 'approval',\n",
       " 'delegated',\n",
       " 'simulated',\n",
       " 'export',\n",
       " 'phases',\n",
       " 'panel',\n",
       " 'alleviates',\n",
       " 'procuring',\n",
       " 'daunting',\n",
       " 'with regard to',\n",
       " 'they are',\n",
       " 'application',\n",
       " 'accompanied',\n",
       " 'obtaining',\n",
       " 'in all likelihood',\n",
       " 'decrease',\n",
       " 'utilization',\n",
       " 'declarations',\n",
       " 'regulation',\n",
       " 'exclusion',\n",
       " 'entity',\n",
       " 'property',\n",
       " 'components',\n",
       " 'establish',\n",
       " 'provider',\n",
       " 'was able to',\n",
       " 'optimum',\n",
       " 'increment',\n",
       " 'restriction',\n",
       " 'attaining',\n",
       " 'consolidated',\n",
       " 'distributions',\n",
       " 'equipment',\n",
       " 'extraction',\n",
       " 'logs',\n",
       " 'increasing',\n",
       " 'readiness',\n",
       " 'et al',\n",
       " 'remains',\n",
       " 'structure',\n",
       " 'hierarchical',\n",
       " 'minimum',\n",
       " 'whom',\n",
       " 'in between',\n",
       " 'certifying',\n",
       " 'linking',\n",
       " 'criteria',\n",
       " 'displayed',\n",
       " 'license',\n",
       " 'locations',\n",
       " 'communication',\n",
       " 'distinguishing',\n",
       " 'modifications',\n",
       " 'permits',\n",
       " 'an absence of',\n",
       " 'remainder',\n",
       " 'pipeline',\n",
       " 'conditional',\n",
       " 'updating',\n",
       " 'restrictions',\n",
       " 'assets',\n",
       " 'locally',\n",
       " 'alternative',\n",
       " 'residing',\n",
       " 'replacement',\n",
       " 'improvements',\n",
       " 'certificate',\n",
       " 'selection',\n",
       " 'protected',\n",
       " 'it  is',\n",
       " 'define',\n",
       " 'it appears',\n",
       " 'authorize',\n",
       " 'analyze',\n",
       " 'do not',\n",
       " 'obtained',\n",
       " 'was not',\n",
       " 'attempting',\n",
       " 'related',\n",
       " 'triggered',\n",
       " 'container',\n",
       " 'specifically',\n",
       " 'eg.',\n",
       " 'limitations',\n",
       " 'permitted',\n",
       " 'subsequently',\n",
       " 'acknowledged',\n",
       " 'assigned',\n",
       " 'comprise',\n",
       " 'provide guidance for',\n",
       " 'terminate',\n",
       " 'trigger',\n",
       " 'releasing',\n",
       " 'despite the fact that',\n",
       " 'maintains',\n",
       " 'currently',\n",
       " 'provisioning',\n",
       " 'abundance',\n",
       " 'capabilities',\n",
       " 'compliance',\n",
       " 'modify',\n",
       " 'database',\n",
       " 'enumerating',\n",
       " 'enables',\n",
       " 'programmatic',\n",
       " 'in relation to',\n",
       " 'range',\n",
       " 'investigate',\n",
       " 'state-of-the-art',\n",
       " 'due to',\n",
       " 'with reference to',\n",
       " 'agents',\n",
       " 'specified',\n",
       " 'et al.',\n",
       " 'exhibiting',\n",
       " 'connectivity',\n",
       " 'magnitude',\n",
       " 'does not',\n",
       " 'sample',\n",
       " 'encountering',\n",
       " 'exception',\n",
       " 'rendering',\n",
       " 'mr.',\n",
       " 'enumerate',\n",
       " 'precludes',\n",
       " 'viable',\n",
       " 'redundancy',\n",
       " 'detection',\n",
       " 'integrity',\n",
       " 'outputs',\n",
       " 'on request',\n",
       " 'etc',\n",
       " 'relocate',\n",
       " 'synopsis',\n",
       " 'breakdown',\n",
       " 'failed',\n",
       " 'expirations',\n",
       " 'subject to',\n",
       " 'procure',\n",
       " 'resides',\n",
       " 'above-mentioned',\n",
       " 'elected',\n",
       " 'entitlements',\n",
       " 'complying with',\n",
       " 'because of the fact that',\n",
       " 'designate',\n",
       " 'finalizing',\n",
       " 'consistent',\n",
       " 'whilst',\n",
       " 'attribute',\n",
       " 'analysis',\n",
       " 'expand',\n",
       " 'extensions',\n",
       " 'samples',\n",
       " 'enabling',\n",
       " 'tabular',\n",
       " 'as a result of',\n",
       " 'secondary',\n",
       " 'inaccurate',\n",
       " 'assign',\n",
       " 'assigning',\n",
       " 'services',\n",
       " 'in favor of',\n",
       " 'phase',\n",
       " 'close proximity',\n",
       " 'invoking',\n",
       " 'been able to',\n",
       " 'notifications',\n",
       " 'terminates',\n",
       " 'she will',\n",
       " 'compliant',\n",
       " 'for the purpose of',\n",
       " 'as prescribed by',\n",
       " 'provided that',\n",
       " 'regions',\n",
       " 'delineates',\n",
       " 'in terms of',\n",
       " 'newly',\n",
       " 'in excess of',\n",
       " 'convene',\n",
       " 'in the amount of',\n",
       " 'attempt',\n",
       " 'designated',\n",
       " 'invokes',\n",
       " 'alleviated',\n",
       " 'in the near future',\n",
       " 'expiration',\n",
       " 'explode',\n",
       " 'did not',\n",
       " 'operations',\n",
       " 'null',\n",
       " 'provide',\n",
       " 'exceeding',\n",
       " 'consolidates',\n",
       " 'one-time',\n",
       " 'operator',\n",
       " 'enumerates',\n",
       " 'fie',\n",
       " 'entities',\n",
       " 'alternatively',\n",
       " 'permitting',\n",
       " 'pools',\n",
       " 'products',\n",
       " 'thereby',\n",
       " 'encounters',\n",
       " 'is readable',\n",
       " 'begging',\n",
       " 'warranted',\n",
       " 'i.e.,',\n",
       " 'monitor',\n",
       " 'will not',\n",
       " 'policy',\n",
       " 'external',\n",
       " 'aforementioned',\n",
       " 'i have',\n",
       " 'you  will',\n",
       " 'delay',\n",
       " 'anomaly',\n",
       " 'limits',\n",
       " 'alleviate',\n",
       " 'applications',\n",
       " 'discovery',\n",
       " 'attains',\n",
       " 'proceed',\n",
       " 'at your earliest convenience',\n",
       " 'they will',\n",
       " 'exploded',\n",
       " 'authorization',\n",
       " 'asserted',\n",
       " 'deems',\n",
       " 'records',\n",
       " 'there is',\n",
       " 'unregistered',\n",
       " 'exemplifies',\n",
       " 'partitioned',\n",
       " 'prioritizes',\n",
       " 'removed',\n",
       " 'subset',\n",
       " 'render',\n",
       " 'supports',\n",
       " 'exposing',\n",
       " 'i.e.',\n",
       " 'is able to',\n",
       " 'certifies',\n",
       " 'categories',\n",
       " 'substituting',\n",
       " 'acknowledge',\n",
       " 'substituted',\n",
       " 'shall not',\n",
       " 'dual',\n",
       " 'due to the fact that',\n",
       " 'enforce',\n",
       " 'during the period',\n",
       " 'for a period of',\n",
       " 'access',\n",
       " 'types',\n",
       " 'high-level',\n",
       " 'yon',\n",
       " 'provision',\n",
       " 'federated',\n",
       " 'entail',\n",
       " 'exhibit',\n",
       " 'have the ability',\n",
       " 'profile',\n",
       " 'remediation',\n",
       " 'had the ability',\n",
       " 'as a means of',\n",
       " 'routing',\n",
       " 'deny',\n",
       " 'e.g.',\n",
       " 'remained',\n",
       " 'confirmation',\n",
       " 'credential',\n",
       " 'unverified',\n",
       " 'oversight',\n",
       " 'transactions',\n",
       " 'techniques',\n",
       " 'exposed',\n",
       " 'exemplify',\n",
       " 'fields',\n",
       " 'concurrent',\n",
       " 'caveat',\n",
       " 'ameliorate',\n",
       " 'scope',\n",
       " 'proxy',\n",
       " 'requesting',\n",
       " 'provisioned',\n",
       " 'terminating',\n",
       " 'depict',\n",
       " 'dataset',\n",
       " 'omitted',\n",
       " 'multiple',\n",
       " 'endeavor',\n",
       " 'provided',\n",
       " 'should you wish',\n",
       " 'cease',\n",
       " 'at the present time',\n",
       " 'be readable',\n",
       " 'function',\n",
       " 'region',\n",
       " 'guidance',\n",
       " 'authorizations',\n",
       " 'endpoints',\n",
       " 'domain',\n",
       " 'remain',\n",
       " 'has the option to',\n",
       " 'component',\n",
       " 'flow',\n",
       " 'thus',\n",
       " 'classification',\n",
       " 'accordingly',\n",
       " 'replication',\n",
       " 'facilitates',\n",
       " 'globally',\n",
       " 'provisions',\n",
       " 'prioritize',\n",
       " 'roles',\n",
       " 'desire',\n",
       " 'capacity',\n",
       " 'manifest',\n",
       " 'intent',\n",
       " 'operating',\n",
       " 'inside of',\n",
       " 'assessment',\n",
       " 'multi',\n",
       " 'it is',\n",
       " 'utilize',\n",
       " 'foremost',\n",
       " 'facilitated',\n",
       " 'is\\xa0not',\n",
       " 'proficiency',\n",
       " 'protection',\n",
       " 'applicability',\n",
       " 'we apologize',\n",
       " 'updatable',\n",
       " 'in the interim',\n",
       " 'in-situ',\n",
       " 'decreases',\n",
       " 'restrict',\n",
       " 'ie',\n",
       " 'actions',\n",
       " 'contain',\n",
       " 'in regard to',\n",
       " 'exceptions',\n",
       " 'attempts',\n",
       " 'duration',\n",
       " 'defines',\n",
       " 'you have',\n",
       " 'as well as',\n",
       " 'as soon as possible',\n",
       " 'at this point in time',\n",
       " 'status',\n",
       " 'providers',\n",
       " 'incident',\n",
       " 'configuration',\n",
       " 'ceases',\n",
       " \"'re writing to\",\n",
       " 'discontinues',\n",
       " 'whether or not',\n",
       " 'attempted',\n",
       " 'reflecting',\n",
       " 'retain',\n",
       " 'ad hoc',\n",
       " 'in the process of',\n",
       " 'enrollment',\n",
       " 'functional',\n",
       " 'prior to',\n",
       " 'registered',\n",
       " 'outside of',\n",
       " 'therefore',\n",
       " 'expedited',\n",
       " 'draft',\n",
       " 'tracing',\n",
       " 'composite',\n",
       " 'diagnostics',\n",
       " 'initialized',\n",
       " 'cannot',\n",
       " 'ensure',\n",
       " 'retained',\n",
       " 'consent',\n",
       " 'certificates',\n",
       " 'reference',\n",
       " 'reserved',\n",
       " 'deficiencies',\n",
       " 'regenerate',\n",
       " 'fails',\n",
       " 'secured',\n",
       " 'corresponding',\n",
       " 'additional',\n",
       " 'represented',\n",
       " 'interval',\n",
       " 'having the ability',\n",
       " 'identified',\n",
       " 'encounter',\n",
       " 'comprises',\n",
       " 'increase',\n",
       " 'prerequisite',\n",
       " 'thereof',\n",
       " 'depicts',\n",
       " 'inspect',\n",
       " 'continuous',\n",
       " 'in a timely manner',\n",
       " 'sensitivity',\n",
       " 'parent',\n",
       " 'logistic',\n",
       " 'staging',\n",
       " 'revision',\n",
       " 'transformations',\n",
       " 'anticipates',\n",
       " 'as yet',\n",
       " 'facilitate',\n",
       " 'first and foremost',\n",
       " 'exceeded',\n",
       " 'repatriation',\n",
       " 'identifier',\n",
       " 'desires',\n",
       " 'adaptive',\n",
       " 'depicted',\n",
       " 'prerequisites',\n",
       " 'numerous',\n",
       " 'unique',\n",
       " 'exceed',\n",
       " 'resided',\n",
       " 'endorsed',\n",
       " 'utilizing',\n",
       " 'units',\n",
       " 'delayed',\n",
       " 'mobile',\n",
       " 'exhibited',\n",
       " 'you  are',\n",
       " 'foregoing',\n",
       " 'it is requested',\n",
       " 'completed',\n",
       " 'reported',\n",
       " 'attest',\n",
       " 'expanded',\n",
       " 'variable',\n",
       " 'listing',\n",
       " 'vulnerability',\n",
       " 'requests',\n",
       " 'acquisition',\n",
       " 'previously',\n",
       " 'relocating',\n",
       " 'possessing',\n",
       " 'valid',\n",
       " 'retaining',\n",
       " 'irrespective',\n",
       " 'consolidate',\n",
       " 'dependency',\n",
       " 'discovers',\n",
       " 'findings',\n",
       " 'provides',\n",
       " 'systems',\n",
       " 'functions',\n",
       " 'codes',\n",
       " 'objectives',\n",
       " 'purchasing',\n",
       " 'adoption',\n",
       " 'extend',\n",
       " 'with the exception of',\n",
       " 'method',\n",
       " 'audited',\n",
       " 'complete',\n",
       " 'certify',\n",
       " 'comprising',\n",
       " 'section',\n",
       " 'display',\n",
       " 'approve',\n",
       " 'compute',\n",
       " 'omits',\n",
       " 'specification',\n",
       " 'ensures',\n",
       " 'assess',\n",
       " 'deemed',\n",
       " 'degraded',\n",
       " 'aggregation',\n",
       " 'bulk',\n",
       " 'procedure',\n",
       " 'estimated',\n",
       " 'delineated',\n",
       " 'purchases',\n",
       " 'he has',\n",
       " 'alternate',\n",
       " 'controls',\n",
       " 'invoked',\n",
       " 'registration',\n",
       " 'in an effort to',\n",
       " 'array',\n",
       " 'initiating',\n",
       " 'purchased',\n",
       " 'i am',\n",
       " 'elicited',\n",
       " 'discontinue',\n",
       " 'beverage',\n",
       " 'policies',\n",
       " 'event',\n",
       " 'containers',\n",
       " 'encode',\n",
       " 'associate',\n",
       " 'properties',\n",
       " 'as of',\n",
       " 'forbids',\n",
       " 'anticipating',\n",
       " 'operators',\n",
       " 'has not',\n",
       " 'tests',\n",
       " 'authorizes',\n",
       " 'discontinuing',\n",
       " 'is writing to',\n",
       " 'advanced',\n",
       " 'universally',\n",
       " 'successfully',\n",
       " 'perform',\n",
       " 'redundant',\n",
       " 'equitable',\n",
       " 'hereby',\n",
       " 'pin number',\n",
       " 'it is essential',\n",
       " 'reflects',\n",
       " 'acknowledges',\n",
       " 'residence',\n",
       " 'administration',\n",
       " 'hybrid',\n",
       " 'remaining',\n",
       " 'attesting',\n",
       " 'flexibility',\n",
       " 'disclosing',\n",
       " 'have the option to',\n",
       " 'sequential',\n",
       " 'regarding',\n",
       " 'in order to',\n",
       " 'govern',\n",
       " 'certified',\n",
       " 'derived',\n",
       " 'internal',\n",
       " 'detailed',\n",
       " 'departs',\n",
       " 'are readable',\n",
       " 'forwarding',\n",
       " 'hubs',\n",
       " 'delays',\n",
       " 'automatic',\n",
       " 'forbidden',\n",
       " 'inputs',\n",
       " 'import',\n",
       " 'compatibility',\n",
       " 'capable of',\n",
       " 'activated',\n",
       " 'established',\n",
       " 'generate',\n",
       " 'large quantities of',\n",
       " 'procured',\n",
       " 'implicit',\n",
       " 'had not',\n",
       " 'anticipated',\n",
       " 'delineate',\n",
       " 'pursuant to',\n",
       " 'hence',\n",
       " 'warrant',\n",
       " 'you will',\n",
       " 'are not',\n",
       " 'finalized',\n",
       " 'verifies',\n",
       " 'profiles',\n",
       " 'primary',\n",
       " 'activity',\n",
       " 'placement',\n",
       " 'reliable',\n",
       " 'allocated',\n",
       " 'acknowledgement',\n",
       " 'capability',\n",
       " 'on the basis of',\n",
       " 'anomalous',\n",
       " 'with respect to',\n",
       " 'credentials',\n",
       " 'alleviating',\n",
       " 'successfully complete',\n",
       " 'precluded',\n",
       " 'summary',\n",
       " 'invoke',\n",
       " 'specify',\n",
       " 'in some instances',\n",
       " 'refer back',\n",
       " 'elicit',\n",
       " 'modifies',\n",
       " 'requiring',\n",
       " 'unauthorized',\n",
       " 'retains',\n",
       " 'by virtue of',\n",
       " 'endpoint',\n",
       " 'recipients',\n",
       " 'mrs.',\n",
       " 'output',\n",
       " 'omit',\n",
       " 'in lieu of',\n",
       " 'acknowledging',\n",
       " 'devices',\n",
       " 'eventual',\n",
       " 'discontinued',\n",
       " 'whereas',\n",
       " 'constitute',\n",
       " 'television',\n",
       " 'gateway',\n",
       " 'finalize',\n",
       " 'etc.',\n",
       " 'whatsoever',\n",
       " 'required',\n",
       " 'designates',\n",
       " 'migration',\n",
       " 'nevertheless',\n",
       " 'rule',\n",
       " 'representing',\n",
       " 'servicing',\n",
       " 'by means of',\n",
       " 'permit',\n",
       " 'we will',\n",
       " 'initiate',\n",
       " 'acknowledgment',\n",
       " 'regardless',\n",
       " 'as of yet',\n",
       " 'domains',\n",
       " 'administrative',\n",
       " 'deactivate',\n",
       " 'he will',\n",
       " 'zone',\n",
       " 'portal',\n",
       " 'indicators',\n",
       " 'stages',\n",
       " 'revocation',\n",
       " 'obligates',\n",
       " 'administrator',\n",
       " 'adjacent to',\n",
       " 'validation',\n",
       " 'mitigation',\n",
       " 'being able to',\n",
       " 'comprised',\n",
       " 'expired',\n",
       " 'released',\n",
       " 'you are requested',\n",
       " 'please note that',\n",
       " 'testing',\n",
       " 'accrue',\n",
       " 'impacted',\n",
       " 'mandatory',\n",
       " 'interpretation',\n",
       " 'afore',\n",
       " 'top-level',\n",
       " 'complies with',\n",
       " 'commences',\n",
       " 'behavioral',\n",
       " 'atomic',\n",
       " 'stored',\n",
       " 'pending',\n",
       " 'usage',\n",
       " 'we have',\n",
       " 'allocate',\n",
       " 'during the time that',\n",
       " 'exposes',\n",
       " 'transaction',\n",
       " 'automation',\n",
       " 'preclude',\n",
       " 'consensus',\n",
       " 'inexpensive',\n",
       " 'volume',\n",
       " 'licenses',\n",
       " 'represents',\n",
       " 'specifications',\n",
       " 'distinguish',\n",
       " 'encountered',\n",
       " 'prioritizing',\n",
       " 'recommended',\n",
       " 'characteristic',\n",
       " 'they have',\n",
       " 'parameter',\n",
       " 'expended',\n",
       " 'permanent',\n",
       " 'initiative',\n",
       " 'element',\n",
       " 'analyzer',\n",
       " 'responses',\n",
       " 'allocating',\n",
       " 'deletion',\n",
       " 'have not',\n",
       " 'stipulated',\n",
       " 'none',\n",
       " 'verify',\n",
       " 'make an effort',\n",
       " 'stability',\n",
       " 'procedural',\n",
       " 'consolidating',\n",
       " 'platforms',\n",
       " 'appropriate',\n",
       " 'hereafter',\n",
       " 'per se',\n",
       " 'bind',\n",
       " 'deployment',\n",
       " 'documentation',\n",
       " 'accompanies',\n",
       " 'agent',\n",
       " 'necessitates',\n",
       " 'desired',\n",
       " 'relevant',\n",
       " 'distinguishes',\n",
       " 'determine',\n",
       " 'exceeds',\n",
       " 'response',\n",
       " 'mapping',\n",
       " 'limit',\n",
       " 'repositories',\n",
       " 'initiates',\n",
       " 'ingestion',\n",
       " 'in view of',\n",
       " 'include',\n",
       " 'integration',\n",
       " 'herein',\n",
       " 'anew',\n",
       " 'distinguished',\n",
       " 'reviewing',\n",
       " 'identify with',\n",
       " 'efficiency',\n",
       " \"'re able to\",\n",
       " 'target',\n",
       " 'subsequent',\n",
       " 'constituted',\n",
       " 'considerations',\n",
       " 'thereafter',\n",
       " 'monitoring',\n",
       " 'device',\n",
       " 'conceptual',\n",
       " 'serial',\n",
       " 'comply with',\n",
       " 'restore',\n",
       " 'direct',\n",
       " 'initial',\n",
       " 'affected',\n",
       " 'accompanying',\n",
       " 'a variety of',\n",
       " 'obtain',\n",
       " 'delivery',\n",
       " 'would not',\n",
       " 'active',\n",
       " 'global',\n",
       " 'to summarize',\n",
       " 'deactivated',\n",
       " 'substitutes',\n",
       " 'encompass',\n",
       " 'accrued',\n",
       " 'registrations',\n",
       " 'infrastructure',\n",
       " 'processing',\n",
       " 'expediting',\n",
       " 'initiated',\n",
       " 'requirement',\n",
       " 'transferred',\n",
       " 'conditions',\n",
       " 'she is',\n",
       " 'is authorized to',\n",
       " 'investigation',\n",
       " 'identical',\n",
       " 'resource',\n",
       " 'represent',\n",
       " 'magnitudes',\n",
       " 'dynamic',\n",
       " 'imported',\n",
       " 'nb',\n",
       " 'manifests',\n",
       " 'inactive',\n",
       " 'are able to',\n",
       " 'appreciable',\n",
       " 'in regards to',\n",
       " 'branches',\n",
       " 'endorse',\n",
       " 'validate',\n",
       " 'accelerated',\n",
       " 'register',\n",
       " 'operational',\n",
       " 'apparent',\n",
       " 'state',\n",
       " 'accurate',\n",
       " 'she has',\n",
       " 'evaluation',\n",
       " 'he is',\n",
       " 'transfers',\n",
       " 'is not',\n",
       " 'commence',\n",
       " 'vehicles',\n",
       " 'nominate',\n",
       " 'ceased',\n",
       " 'regional',\n",
       " 'necessitating',\n",
       " 'repository',\n",
       " 'were able to',\n",
       " 'therein',\n",
       " 'facilitating',\n",
       " 'performed',\n",
       " 'accessibility',\n",
       " 'be advised',\n",
       " 'enabled',\n",
       " 'synchronization',\n",
       " 'total',\n",
       " 'central',\n",
       " 'warehousing',\n",
       " 'ternary',\n",
       " 'objective',\n",
       " 'instances',\n",
       " 'scheduling',\n",
       " 'maintain',\n",
       " 'triggers',\n",
       " 'providing',\n",
       " 'obtains',\n",
       " 'maintenance',\n",
       " 'fore',\n",
       " 'selected',\n",
       " 'is responsible for',\n",
       " 'relocated',\n",
       " 'and/or',\n",
       " 'incompatible',\n",
       " 'extension',\n",
       " 'processes',\n",
       " 'evaluate',\n",
       " 'accrues',\n",
       " 'extract',\n",
       " 'allocates',\n",
       " 'entitlement',\n",
       " 'allocation',\n",
       " 'articulated',\n",
       " 'circuit',\n",
       " 'moreover',\n",
       " 'requesters',\n",
       " 'degradation',\n",
       " 'execution',\n",
       " 'parameters',\n",
       " 'possesses',\n",
       " 'existing',\n",
       " 'expedite',\n",
       " 'manifested',\n",
       " 'endeavors',\n",
       " 'definitely',\n",
       " 'tiering',\n",
       " 'specifies',\n",
       " 'relative to',\n",
       " 'identities',\n",
       " 'hub',\n",
       " 'disclosed',\n",
       " 'discovered',\n",
       " 'performing',\n",
       " 'has the ability',\n",
       " 'registry',\n",
       " 'discover',\n",
       " 'initiator',\n",
       " 'designating',\n",
       " 'embodies',\n",
       " 'methods',\n",
       " 'performs',\n",
       " 'large-scale',\n",
       " 'vice versa',\n",
       " 'accompany',\n",
       " 'i will',\n",
       " 'select',\n",
       " 'obligated',\n",
       " 'authorized',\n",
       " 'predictive',\n",
       " 'audit',\n",
       " 'forbid',\n",
       " 'rendered',\n",
       " 'routes',\n",
       " 'activation',\n",
       " 'prioritized',\n",
       " 'storage',\n",
       " 'stipulate',\n",
       " 'could not',\n",
       " 'invalid',\n",
       " 'contained',\n",
       " 'you are',\n",
       " 'containing',\n",
       " 'release',\n",
       " 'ensured',\n",
       " 'spatial',\n",
       " 'attributes',\n",
       " 'elect',\n",
       " 'certainty',\n",
       " 'applicable',\n",
       " 'be able to',\n",
       " 'accruing',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_words = list(set([str(x).strip().lower() for x in list(mic_words)]))\n",
    "mic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sugg = [np.nan] * len(mic_words)\n",
    "sugg += list(words_df['suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_words += list(words_df['formal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mic_df = pd.DataFrame()\n",
    "mic_df['words'] = mic_words\n",
    "mic_df['sugg'] = sugg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>sugg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>compute</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>ensuring</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>integrity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>requesters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>e.g.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>permitted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>invokes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>request</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>devices</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>apparent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words sugg\n",
       "644      compute  NaN\n",
       "1499    ensuring  NaN\n",
       "898    integrity  NaN\n",
       "194   requesters  NaN\n",
       "1483        e.g.  NaN\n",
       "90     permitted  NaN\n",
       "649      invokes  NaN\n",
       "1254     request  NaN\n",
       "693      devices  NaN\n",
       "913     apparent  NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_df.to_pickle('data/lexical_repl/all_words_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next: extrapolate to the other words using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_pickle('data/lexical_repl/all_words_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('/home/rebekah/Documents/Word Embeddings/GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opposed', 0.5896098613739014),\n",
       " ('opposes', 0.5139723420143127),\n",
       " ('vehemently_opposed', 0.5054149031639099),\n",
       " ('concur', 0.4950396716594696),\n",
       " ('vehemently_oppose', 0.4931677281856537),\n",
       " ('disagree', 0.4864474833011627),\n",
       " ('adamantly_opposed', 0.48512935638427734),\n",
       " ('agree', 0.47763556241989136),\n",
       " ('unalterably_opposed', 0.462196409702301),\n",
       " ('favor', 0.4584296643733978)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The basic way.\n",
    "word = 'oppose'\n",
    "w2v.most_similar(positive=[word, 'caveat'], negative=['warning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_word_lists(wl, embed, one_word_only = False):\n",
    "    if len(wl) == 1:\n",
    "        if wl[0] in embed:\n",
    "            return embed[wl[0]]\n",
    "    elif len(wl) > 1 and one_word_only == False:\n",
    "        vecs = [0.0] * len(embed['word'])\n",
    "        for w in wl:\n",
    "            if w in embed:\n",
    "                vecs = list(map(sum, zip(vecs, embed[w])))\n",
    "        if vecs != [0.0] * len(embed['word']):\n",
    "            return vecs\n",
    "    return np.nan\n",
    "\n",
    "def make_data(df, embed, X, y, one_word_only = False):\n",
    "    X_ph = np.nan * len(df)\n",
    "    y_ph = np.nan * len(df)\n",
    "    df[X] = X_ph\n",
    "    df[X] = df[X].astype(object)\n",
    "    df[y] = y_ph\n",
    "    df[y] = df[y].astype(object)\n",
    "    \n",
    "    for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "        formal_words = nltk.word_tokenize(row['words'])\n",
    "        df.at[idx, X] = process_word_lists(formal_words, embed, one_word_only) \n",
    "        informal_words = []\n",
    "        if type(row['sugg']) != float:\n",
    "            for word in row['sugg']:\n",
    "                word = nltk.word_tokenize(word)\n",
    "                word = process_word_lists(word, embed, one_word_only)\n",
    "                informal_words.append(word)\n",
    "        if len(informal_words) > 0:\n",
    "            df.at[idx, y] = informal_words[0]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae306b85fea46edb19c14d0d93aea8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = make_data(words_df, w2v, 'X_w2v', 'y_w2v', one_word_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>sugg</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>fore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.018798828, 0.123046875, -0.03100586, -0.125...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>distributions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.18066406, -0.15429688, -0.024414062, 0.3339...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>invoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.2734375, 0.23828125, 0.19726562, 0.078125, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>attempt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.20410156, 0.15820312, -0.05419922, -0.00970...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>cornerstone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.01977539, 0.09765625, 0.07373047, 0.203125,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>pending</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.16601562, 0.06640625, 0.29101562, -0.273437...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.024291992, 0.010803223, -0.107421875, 0.302...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>initiate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.21386719, 0.015991211, 0.096191406, 0.1259...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>acknowledge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.16601562, -0.13183594, -0.15625, 0.1367187...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>decreased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.2578125, -0.140625, -0.23925781, 0.0893554...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words sugg                                              X_w2v  \\\n",
       "1242           fore  NaN  [0.018798828, 0.123046875, -0.03100586, -0.125...   \n",
       "1584  distributions  NaN  [0.18066406, -0.15429688, -0.024414062, 0.3339...   \n",
       "1529         invoke  NaN  [0.2734375, 0.23828125, 0.19726562, 0.078125, ...   \n",
       "769         attempt  NaN  [0.20410156, 0.15820312, -0.05419922, -0.00970...   \n",
       "936     cornerstone  NaN  [0.01977539, 0.09765625, 0.07373047, 0.203125,...   \n",
       "1214        pending  NaN  [0.16601562, 0.06640625, 0.29101562, -0.273437...   \n",
       "559            item  NaN  [0.024291992, 0.010803223, -0.107421875, 0.302...   \n",
       "1465       initiate  NaN  [-0.21386719, 0.015991211, 0.096191406, 0.1259...   \n",
       "2046    acknowledge  NaN  [-0.16601562, -0.13183594, -0.15625, 0.1367187...   \n",
       "91        decreased  NaN  [-0.2578125, -0.140625, -0.23925781, 0.0893554...   \n",
       "\n",
       "     y_w2v  \n",
       "1242   NaN  \n",
       "1584   NaN  \n",
       "1529   NaN  \n",
       "769    NaN  \n",
       "936    NaN  \n",
       "1214   NaN  \n",
       "559    NaN  \n",
       "1465   NaN  \n",
       "2046   NaN  \n",
       "91     NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.dropna(subset=['X_w2v']).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = words_df.dropna() # only the words that have suggestions and vectors for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in train.iterrows():\n",
    "    assert len(row['X_w2v']) == 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(train['X_w2v']))\n",
    "y = np.array(list(train['y_w2v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999982279"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    pred = lr.predict([word]).reshape(-1, 1)\n",
    "    pred = pred.reshape(300,)\n",
    "    return w2v.similar_by_vector(pred, topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea2d9c32b284b269dba95152a0da82e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict for all other words\n",
    "\n",
    "w2v_pred = []\n",
    "\n",
    "for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "    if type(row['X_w2v']) == float:\n",
    "        w2v_pred.append(None)\n",
    "        #formal = nltk.word_tokenize(row['words'])\n",
    "        #vec = process_word_lists(formal, w2v, one_word_only = True)\n",
    "        #if type(vec) == float:\n",
    "        #    w2v_pred.append(np.nan)\n",
    "        #else:\n",
    "        #    w2v_pred.append(predict(vec))\n",
    "    else:\n",
    "        w2v_pred.append(predict(row['X_w2v']))\n",
    "\n",
    "words_df['pred_w2v'] = w2v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(df, num = 10):\n",
    "    current = 0\n",
    "    for idx, row in df.sample(frac=1).iterrows():\n",
    "        if current > num:\n",
    "            break\n",
    "        train = type(row['y_w2v']) != float\n",
    "        if train:\n",
    "            continue\n",
    "        print('Original Word:\\t' + row['words'])\n",
    "        #print('Training Data?:\\t' + str(train))\n",
    "        if type(row['sugg']) != float:\n",
    "            print('Given Answer:\\t' + str(row['sugg']))\n",
    "        else:\n",
    "            print()\n",
    "        if type(row['pred_w2v']) != float:\n",
    "            ans = ''\n",
    "            for item in row['pred_w2v']:\n",
    "                ans += item[0] + '\\t' + str('%s' % float('%.3g' % item[1])) + '\\n\\t\\t'\n",
    "            print('Pred Answers:\\t' + ans)\n",
    "        current += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word:\tyon\n",
      "\n",
      "Pred Answers:\tthink\t0.511\n",
      "\t\tknow\t0.51\n",
      "\t\tchoose\t0.479\n",
      "\t\tguess\t0.469\n",
      "\t\tsuppose\t0.462\n",
      "\t\tMARK_LATHAM_OPPOSITION_LEADER\t0.459\n",
      "\t\tdo\t0.458\n",
      "\t\tBEGALA\t0.453\n",
      "\t\tMr._NAVARRETTE\t0.451\n",
      "\t\tRENDELL_Well\t0.451\n",
      "\t\t\n",
      "Original Word:\ttelevision\n",
      "Given Answer:\t['T.V.']\n",
      "Pred Answers:\tmany\t0.563\n",
      "\t\tnowadays\t0.465\n",
      "\t\tlaypersons_alike\t0.446\n",
      "\t\toften\t0.437\n",
      "\t\tsimplifiers\t0.424\n",
      "\t\tsimplistic_notions\t0.423\n",
      "\t\tloathe\t0.422\n",
      "\t\tTh_ere\t0.419\n",
      "\t\tculturally_ingrained\t0.416\n",
      "\t\thesays\t0.414\n",
      "\t\t\n",
      "Original Word:\tcomponents\n",
      "\n",
      "Pred Answers:\tJin_Qi\t0.324\n",
      "\t\tprebuilt_templates\t0.317\n",
      "\t\talso\t0.311\n",
      "\t\tability\t0.309\n",
      "\t\tease\t0.304\n",
      "\t\tStrikers_Charged\t0.299\n",
      "\t\tLUCRF\t0.292\n",
      "\t\telectromechanical_steering\t0.292\n",
      "\t\tsturdiness\t0.286\n",
      "\t\trappel_tower\t0.285\n",
      "\t\t\n",
      "Original Word:\tresource\n",
      "\n",
      "Pred Answers:\tmeet\t0.382\n",
      "\t\tease\t0.357\n",
      "\t\tuse\t0.354\n",
      "\t\tutilize\t0.352\n",
      "\t\tpurchase\t0.345\n",
      "\t\toutplace\t0.341\n",
      "\t\tselect\t0.339\n",
      "\t\tNSLI_Y\t0.333\n",
      "\t\tworkwith\t0.327\n",
      "\t\treasonable\t0.326\n",
      "\t\t\n",
      "Original Word:\tenumerate\n",
      "\n",
      "Pred Answers:\tcount\t1.0\n",
      "\t\tcounts\t0.689\n",
      "\t\tcounted\t0.594\n",
      "\t\tcounting\t0.533\n",
      "\t\ttally\t0.526\n",
      "\t\tself_effacement_literary\t0.512\n",
      "\t\tthrowing_hittable_pitches\t0.491\n",
      "\t\tAsdrubal_Cabrera_bunted\t0.479\n",
      "\t\tCount\t0.467\n",
      "\t\ttotals\t0.457\n",
      "\t\t\n",
      "Original Word:\tacknowledge\n",
      "\n",
      "Pred Answers:\tsay\t0.594\n",
      "\t\tbelieve\t0.498\n",
      "\t\tthink\t0.47\n",
      "\t\targue\t0.468\n",
      "\t\twarn\t0.462\n",
      "\t\tknow\t0.43\n",
      "\t\ttell\t0.402\n",
      "\t\tremain_unconvinced\t0.4\n",
      "\t\tsee\t0.396\n",
      "\t\tsuggest\t0.392\n",
      "\t\t\n",
      "Original Word:\tspecified\n",
      "\n",
      "Pred Answers:\tregardless\t0.504\n",
      "\t\tirrespective\t0.444\n",
      "\t\twhichever\t0.44\n",
      "\t\tvast_majority\t0.438\n",
      "\t\tchoose\t0.432\n",
      "\t\tleast\t0.422\n",
      "\t\tone\t0.411\n",
      "\t\tgreatest\t0.405\n",
      "\t\tsame\t0.405\n",
      "\t\tmultiple\t0.399\n",
      "\t\t\n",
      "Original Word:\tdiscovering\n",
      "\n",
      "Pred Answers:\tdo\t0.415\n",
      "\t\tunderstand\t0.407\n",
      "\t\tanymore\t0.392\n",
      "\t\torient\t0.39\n",
      "\t\ttell\t0.387\n",
      "\t\tknow\t0.381\n",
      "\t\tThatÕs\t0.376\n",
      "\t\treally\t0.375\n",
      "\t\tjust\t0.372\n",
      "\t\tmeet\t0.372\n",
      "\t\t\n",
      "Original Word:\toperational\n",
      "\n",
      "Pred Answers:\tuse\t0.45\n",
      "\t\tdeploy\t0.391\n",
      "\t\t_Creating\t0.37\n",
      "\t\tLumeta_empowers_large\t0.367\n",
      "\t\toperate\t0.36\n",
      "\t\temploy\t0.359\n",
      "\t\tutilize\t0.352\n",
      "\t\tprioritize\t0.349\n",
      "\t\tallow\t0.346\n",
      "\t\taffect\t0.345\n",
      "\t\t\n",
      "Original Word:\texception\n",
      "\n",
      "Pred Answers:\twarning\t0.535\n",
      "\t\twarnings\t0.43\n",
      "\t\talert\t0.404\n",
      "\t\talso\t0.383\n",
      "\t\talerting\t0.35\n",
      "\t\thowever\t0.337\n",
      "\t\tKeri_Embry\t0.337\n",
      "\t\tPuddles_formed\t0.333\n",
      "\t\tprompting\t0.329\n",
      "\t\tadvising\t0.324\n",
      "\t\t\n",
      "Original Word:\tprocure\n",
      "\n",
      "Pred Answers:\tbuy\t0.489\n",
      "\t\tprocure\t0.475\n",
      "\t\tsell\t0.471\n",
      "\t\tget\t0.447\n",
      "\t\tobtain\t0.441\n",
      "\t\tuse\t0.428\n",
      "\t\tpurchase\t0.416\n",
      "\t\talso\t0.4\n",
      "\t\tinstall_microgeneration\t0.397\n",
      "\t\tdistribute\t0.393\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "display(words_df.dropna(subset=['pred_w2v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_pickle('data/lexical_repl/all_words_filled.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4965a2bfe0484c86bebb37589b20097b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/lexical_repl/doccano_to_check.txt', 'w') as f:\n",
    "    for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "        if row['pred_w2v'] != None:\n",
    "            ans = ''\n",
    "            for item in row['pred_w2v']:\n",
    "                ans += item[0] + '\\t'\n",
    "            f.write(row['words'].upper() + '\\t' + ans + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n"
     ]
    }
   ],
   "source": [
    "with open('data/lexical_repl/doccano_to_check.txt', 'r') as f:\n",
    "    tests = f.readlines()\n",
    "print(len(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuples = []\n",
    "\n",
    "for item in tests:\n",
    "    split = item.split('\\t')[:-1]\n",
    "    test_tuples.append((split[0], split[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "996\n"
     ]
    }
   ],
   "source": [
    "words = [tup[0] for tup in test_tuples]\n",
    "print(len(words))\n",
    "words = list(set(words))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16600ed27781449d859f1fab59fadc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_sets = defaultdict(list)\n",
    "\n",
    "for item in tqdm(words):\n",
    "    for pair in test_tuples:\n",
    "        if pair[0] == item:\n",
    "            for possible in pair[1]:\n",
    "                new_sets[item].append(possible)\n",
    "                \n",
    "for term in new_sets:\n",
    "    new_sets[term] = list(set([x.lower() for x in new_sets[term]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_be_checked = pd.DataFrame.from_dict(new_sets, \n",
    "                                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_checked.to_csv('data/microsoft/to_be_checked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
