{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import gensim\n",
    "import xml.etree.ElementTree as ET\n",
    "from ast import literal_eval\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put existing gzt and files into pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/acrolinx_gzt/lf.json') as lfjson:\n",
    "    lf = json.load(lfjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/acrolinx_gzt/conv-words.json') as cvjson:\n",
    "    form_with_sugg = json.load(cvjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_gzt = []\n",
    "\n",
    "with open('data/acrolinx_gzt/archaicWords.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countFormalPhrases.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countLatinExpressions.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzt = {}\n",
    "\n",
    "# things i noticed and don't want\n",
    "exceptions = ['use either', '(']\n",
    "\n",
    "for item in unclean_gzt:\n",
    "    if item[0] == '@' or item[0] == '#':\n",
    "        continue\n",
    "    item = item.strip()\n",
    "    if len(item) < 1:\n",
    "        continue\n",
    "    trigger = False\n",
    "    for term in exceptions:\n",
    "        if term in item:\n",
    "            trigger = True\n",
    "    if trigger:\n",
    "        continue\n",
    "    item = re.sub('\\[', '', item)\n",
    "    item = re.sub('\\]', '', item)\n",
    "    item = re.sub('\\n', '', item)\n",
    "    item = re.sub(';', '', item)\n",
    "    if '-->' in item:\n",
    "        pair = [part.strip() for part in item.split('-->')]\n",
    "        if ',' in pair[0]:\n",
    "            form_words = [part.strip() for part in pair[0].split(',')]\n",
    "            for word in form_words:\n",
    "                gzt[word] = [part.strip() for part in pair[1].split(',')]\n",
    "        else:\n",
    "            gzt[pair[0]] = [part.strip() for part in pair[1].split(',')]\n",
    "    else:\n",
    "        gzt[item] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gzt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set forth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abeyance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in abeyance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afore</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afore mentioned</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            formal suggestions\n",
       "0        set forth         NaN\n",
       "1         abeyance         NaN\n",
       "2      in abeyance         NaN\n",
       "3            afore         NaN\n",
       "4  afore mentioned         NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal = []\n",
    "informal = []\n",
    "\n",
    "for word in gzt:\n",
    "    formal.append(word)\n",
    "    informal.append(gzt[word])\n",
    "\n",
    "words = pd.DataFrame()\n",
    "words['formal'] = formal\n",
    "words['suggestions'] = informal\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.to_pickle('data/acrolinx_gzt/clean_words.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next: extrapolate to the other words using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_pickle('data/acrolinx_gzt/clean_words.pkl') # only words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>necessitate</td>\n",
       "      <td>[cause, need]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>It’s in regards to</td>\n",
       "      <td>[It’s about]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>preowned</td>\n",
       "      <td>[used]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>in some instances</td>\n",
       "      <td>[sometimes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>desire</td>\n",
       "      <td>[want, wish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>than was formerly the case</td>\n",
       "      <td>[now]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>subsequent to</td>\n",
       "      <td>[later, next, after, then]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>it is requested</td>\n",
       "      <td>[please, we request, I request]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>remain</td>\n",
       "      <td>[stay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>by means of</td>\n",
       "      <td>[by, with]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         formal                      suggestions\n",
       "262                 necessitate                    [cause, need]\n",
       "137          It’s in regards to                     [It’s about]\n",
       "500                    preowned                           [used]\n",
       "432           in some instances                      [sometimes]\n",
       "210                      desire                     [want, wish]\n",
       "528  than was formerly the case                            [now]\n",
       "523               subsequent to       [later, next, after, then]\n",
       "462             it is requested  [please, we request, I request]\n",
       "291                      remain                           [stay]\n",
       "358                 by means of                       [by, with]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.dropna().sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_pickle('data/acrolinx_gzt/initial_words.pkl') # with vectors, determined here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('/home/rebekah/Documents/Word Embeddings/GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countenance', 0.3350488245487213),\n",
       " ('revivified', 0.32268810272216797),\n",
       " ('unstinted', 0.32051318883895874)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'oppose'\n",
    "w2v.most_similar(positive=[word, 'peruse', 'penurious', 'amidst', 'endeavor'], negative=['read', 'poor', 'among', 'try'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opposed', 0.5896098613739014),\n",
       " ('opposes', 0.5139723420143127),\n",
       " ('vehemently_opposed', 0.5054149031639099),\n",
       " ('concur', 0.4950396716594696),\n",
       " ('vehemently_oppose', 0.4931677281856537),\n",
       " ('disagree', 0.4864474833011627),\n",
       " ('adamantly_opposed', 0.48512935638427734),\n",
       " ('agree', 0.47763556241989136),\n",
       " ('unalterably_opposed', 0.462196409702301),\n",
       " ('favor', 0.4584296643733978)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'oppose'\n",
    "w2v.most_similar(positive=[word, 'caveat'], negative=['warning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_word_lists(wl, embed, one_word_only = False):\n",
    "    if len(wl) == 1:\n",
    "        if wl[0] in embed:\n",
    "            return embed[wl[0]]\n",
    "    elif len(wl) > 1 and one_word_only == False:\n",
    "        vecs = [0.0] * len(embed['word'])\n",
    "        for w in wl:\n",
    "            if w in embed:\n",
    "                vecs = list(map(sum, zip(vecs, embed[w])))\n",
    "        if vecs != [0.0] * len(embed['word']):\n",
    "            return vecs\n",
    "    return np.nan\n",
    "\n",
    "def make_data(df, embed, X, y, one_word_only = False):\n",
    "    X_ph = np.nan * len(df)\n",
    "    y_ph = np.nan * len(df)\n",
    "    df[X] = X_ph\n",
    "    df[X] = df[X].astype(object)\n",
    "    df[y] = y_ph\n",
    "    df[y] = df[y].astype(object)\n",
    "    \n",
    "    for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "        formal_words = nltk.word_tokenize(row['formal'])\n",
    "        df.at[idx, X] = process_word_lists(formal_words, embed, one_word_only) \n",
    "        informal_words = []\n",
    "        if type(row['suggestions']) != float:\n",
    "            for word in row['suggestions']:\n",
    "                word = nltk.word_tokenize(word)\n",
    "                word = process_word_lists(word, embed, one_word_only)\n",
    "                informal_words.append(word)\n",
    "        if len(informal_words) > 0:\n",
    "            df.at[idx, y] = informal_words[0]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc96ec03d4f04af4ba52d0c7f03f1589"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = make_data(words_df, w2v, 'X_w2v', 'y_w2v', one_word_only = True)\n",
    "#words_df.to_pickle('data/acrolinx_gzt/initial_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>whosoever</td>\n",
       "      <td>[whoever, whomever]</td>\n",
       "      <td>[-0.21972656, -0.19921875, 0.030517578, 0.3574...</td>\n",
       "      <td>[0.045166016, -0.20703125, 0.083984375, 0.0354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>commence</td>\n",
       "      <td>[begin, start]</td>\n",
       "      <td>[-0.27734375, 0.025756836, 0.115234375, 0.1455...</td>\n",
       "      <td>[0.055664062, 0.12695312, 0.16308594, 0.150390...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>depart</td>\n",
       "      <td>[leave, go]</td>\n",
       "      <td>[0.032226562, 0.140625, -0.053466797, 0.007019...</td>\n",
       "      <td>[0.18554688, 0.008178711, 0.032958984, 0.17675...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>retain</td>\n",
       "      <td>[keep]</td>\n",
       "      <td>[0.13769531, -0.064453125, -0.24121094, -0.056...</td>\n",
       "      <td>[0.060546875, -0.012939453, -0.10888672, 0.143...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>cease</td>\n",
       "      <td>[stop]</td>\n",
       "      <td>[-0.2109375, -0.20019531, 0.296875, 0.17089844...</td>\n",
       "      <td>[-0.057861328, 0.013183594, 0.115234375, 0.069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>reside</td>\n",
       "      <td>[live, house]</td>\n",
       "      <td>[-0.091796875, -0.05419922, -0.092285156, -0.0...</td>\n",
       "      <td>[0.016967773, 0.017333984, -0.041748047, 0.126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>inexpensive</td>\n",
       "      <td>[cheap]</td>\n",
       "      <td>[0.0546875, -0.13671875, -0.14746094, 0.227539...</td>\n",
       "      <td>[0.06738281, -0.08105469, -0.103027344, 0.2539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>subsequently</td>\n",
       "      <td>[next, later]</td>\n",
       "      <td>[-0.0079956055, -0.114746094, 0.107910156, -0....</td>\n",
       "      <td>[0.18261719, -0.044921875, 0.13867188, 0.01165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>abominate</td>\n",
       "      <td>[hate]</td>\n",
       "      <td>[0.028930664, 0.037109375, 0.13378906, 0.11083...</td>\n",
       "      <td>[0.1328125, 0.080078125, 0.28710938, 0.0986328...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>accrue</td>\n",
       "      <td>[add, gain]</td>\n",
       "      <td>[0.12402344, 0.07714844, -0.17773438, 0.324218...</td>\n",
       "      <td>[-0.008728027, 0.1015625, -0.056884766, 0.1416...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>accurate</td>\n",
       "      <td>[right]</td>\n",
       "      <td>[0.004211426, -0.35351562, 0.0035552979, -0.20...</td>\n",
       "      <td>[0.14550781, -0.018920898, 0.096191406, 0.1289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>acquiesce</td>\n",
       "      <td>[agree]</td>\n",
       "      <td>[-0.043701172, -0.056152344, -0.03491211, 0.21...</td>\n",
       "      <td>[-0.03857422, 0.026245117, 0.19042969, 0.12109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>adjustment</td>\n",
       "      <td>[change, alteration]</td>\n",
       "      <td>[-0.24414062, 0.106933594, -0.32226562, 0.3125...</td>\n",
       "      <td>[-0.060058594, -0.09326172, -0.072265625, 0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>alleviate</td>\n",
       "      <td>[ease, reduce]</td>\n",
       "      <td>[-0.18359375, 0.111328125, -0.25195312, -0.166...</td>\n",
       "      <td>[0.17480469, 0.27929688, -0.29492188, -0.18457...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>allocate</td>\n",
       "      <td>[divide]</td>\n",
       "      <td>[-0.029174805, -0.16503906, 0.05883789, 0.1079...</td>\n",
       "      <td>[0.12695312, 0.103027344, 0.10888672, -0.04150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>ameliorate</td>\n",
       "      <td>[improve, help]</td>\n",
       "      <td>[-0.28515625, 0.22363281, -0.18359375, 0.04907...</td>\n",
       "      <td>[-0.33984375, 0.25390625, -0.021240234, -0.163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>anticipate</td>\n",
       "      <td>[expect]</td>\n",
       "      <td>[-0.056640625, 0.10888672, 0.00592041, 0.13769...</td>\n",
       "      <td>[0.05102539, 0.19921875, -0.002090454, 0.18847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>apprehend</td>\n",
       "      <td>[arrest]</td>\n",
       "      <td>[0.051513672, 0.20996094, 0.140625, -0.1367187...</td>\n",
       "      <td>[0.029907227, -0.0625, -0.011108398, -0.316406...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>attain</td>\n",
       "      <td>[meet]</td>\n",
       "      <td>[-0.059570312, 0.03881836, -0.296875, 0.112792...</td>\n",
       "      <td>[-0.36914062, 0.171875, 0.08105469, 0.01965332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>attempt</td>\n",
       "      <td>[try]</td>\n",
       "      <td>[0.20410156, 0.15820312, -0.05419922, -0.00970...</td>\n",
       "      <td>[0.24023438, 0.20117188, 0.16210938, 0.2089843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>authorize</td>\n",
       "      <td>[allow, let]</td>\n",
       "      <td>[-0.107421875, -0.018066406, 0.08642578, -0.02...</td>\n",
       "      <td>[-0.13769531, -0.0012130737, 0.1640625, 0.0742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>beg</td>\n",
       "      <td>[ask]</td>\n",
       "      <td>[0.24804688, 0.016967773, 0.12109375, 0.421875...</td>\n",
       "      <td>[-0.028076172, 0.05859375, 0.18945312, 0.09765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>capability</td>\n",
       "      <td>[ability]</td>\n",
       "      <td>[0.015319824, 0.10205078, 0.1640625, 0.0272216...</td>\n",
       "      <td>[0.23828125, 0.125, -0.056640625, 0.050048828,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>comprise</td>\n",
       "      <td>[form]</td>\n",
       "      <td>[-0.15625, -0.22265625, 0.34375, -0.08642578, ...</td>\n",
       "      <td>[0.083496094, -0.007293701, -0.026489258, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>conceal</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[0.1484375, 0.07421875, -0.28710938, -0.201171...</td>\n",
       "      <td>[0.18847656, 0.05517578, -0.21484375, -0.09814...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>consolidate</td>\n",
       "      <td>[join, merge]</td>\n",
       "      <td>[-0.28320312, 0.020385742, -0.17871094, 0.0927...</td>\n",
       "      <td>[-0.056396484, 0.050048828, 0.10986328, 0.2265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>contain</td>\n",
       "      <td>[has]</td>\n",
       "      <td>[-0.0020751953, -0.10644531, 0.14941406, 0.057...</td>\n",
       "      <td>[-0.044921875, -0.030395508, 0.0023498535, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>convene</td>\n",
       "      <td>[meet]</td>\n",
       "      <td>[0.026611328, 0.265625, 0.12060547, 0.10791015...</td>\n",
       "      <td>[-0.36914062, 0.171875, 0.08105469, 0.01965332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>deem</td>\n",
       "      <td>[believe, think]</td>\n",
       "      <td>[-0.32421875, -0.048095703, 0.140625, 0.205078...</td>\n",
       "      <td>[-0.1640625, 0.010803223, 0.033203125, 0.08007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>designate</td>\n",
       "      <td>[choose, name]</td>\n",
       "      <td>[-0.048339844, -0.041992188, 0.115722656, 0.22...</td>\n",
       "      <td>[0.08496094, 0.125, -0.030029297, 0.30078125, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>caveat</td>\n",
       "      <td>[warning]</td>\n",
       "      <td>[0.15234375, -0.03515625, 0.059814453, 0.125, ...</td>\n",
       "      <td>[-0.11376953, -0.15136719, 0.16992188, -0.0500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>cogitate</td>\n",
       "      <td>[think]</td>\n",
       "      <td>[0.016723633, 0.19238281, 0.08544922, 0.349609...</td>\n",
       "      <td>[-0.046875, 0.06689453, 0.009338379, 0.2636718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>comestibles</td>\n",
       "      <td>[food]</td>\n",
       "      <td>[-0.02758789, -0.036865234, -0.0043945312, 0.5...</td>\n",
       "      <td>[-0.18164062, 0.16503906, -0.16601562, 0.35742...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>definitely</td>\n",
       "      <td>[really, very]</td>\n",
       "      <td>[0.06738281, 0.064453125, -0.09375, 0.21777344...</td>\n",
       "      <td>[0.096191406, -0.028686523, -0.10839844, 0.145...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>emoluments</td>\n",
       "      <td>[fee, salary]</td>\n",
       "      <td>[0.24414062, -0.103027344, 0.125, 0.74609375, ...</td>\n",
       "      <td>[0.25976562, 0.09423828, 0.2109375, -0.0329589...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>equitable</td>\n",
       "      <td>[fair]</td>\n",
       "      <td>[-0.25, -0.030517578, -0.21777344, 0.21679688,...</td>\n",
       "      <td>[-0.16113281, -0.037109375, -0.055419922, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>equivalent</td>\n",
       "      <td>[equal]</td>\n",
       "      <td>[0.16503906, -0.33789062, 0.25195312, 0.125, -...</td>\n",
       "      <td>[-0.053955078, -0.18457031, 0.12792969, 0.1201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>evidenced</td>\n",
       "      <td>[showed]</td>\n",
       "      <td>[-0.24707031, 0.24023438, -0.24902344, -0.0429...</td>\n",
       "      <td>[-0.08886719, 0.10498047, -0.07421875, -0.1269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>excluding</td>\n",
       "      <td>[except]</td>\n",
       "      <td>[-0.059570312, 0.16503906, 0.095703125, 0.2187...</td>\n",
       "      <td>[-0.01928711, -0.16992188, 0.15917969, 0.18847...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>expeditious</td>\n",
       "      <td>[fast, quick]</td>\n",
       "      <td>[-0.21484375, 0.35742188, -0.056640625, 0.1127...</td>\n",
       "      <td>[0.14453125, -0.012390137, 0.119140625, 0.0415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>identical</td>\n",
       "      <td>[same]</td>\n",
       "      <td>[0.08154297, -0.039794922, 0.125, 0.043701172,...</td>\n",
       "      <td>[0.17089844, -0.012084961, 0.036132812, 0.1728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>impacted</td>\n",
       "      <td>[affected, changed]</td>\n",
       "      <td>[-0.26953125, 0.10986328, 0.0079956055, 0.1494...</td>\n",
       "      <td>[-0.0625, 0.0014724731, 0.12597656, 0.10205078...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>maximum</td>\n",
       "      <td>[greatest, largest, most]</td>\n",
       "      <td>[0.048339844, -0.375, 0.15820312, -0.100097656...</td>\n",
       "      <td>[0.078125, -0.04736328, 0.27734375, 0.21777344...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>minimum</td>\n",
       "      <td>[least, smallest]</td>\n",
       "      <td>[-0.17675781, -0.296875, 0.030517578, 0.143554...</td>\n",
       "      <td>[0.080566406, -0.14160156, 0.12792969, 0.29687...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>moreover</td>\n",
       "      <td>[also]</td>\n",
       "      <td>[0.061523438, 0.036376953, -0.056884766, 0.190...</td>\n",
       "      <td>[0.053466797, 0.012023926, -0.006500244, 0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>multiple</td>\n",
       "      <td>[many]</td>\n",
       "      <td>[0.022705078, -0.11279297, -0.24804688, 0.0957...</td>\n",
       "      <td>[0.19335938, -0.004333496, -0.032226562, 0.139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>numerous</td>\n",
       "      <td>[many]</td>\n",
       "      <td>[-0.025146484, 0.067871094, -0.29882812, -0.06...</td>\n",
       "      <td>[0.19335938, -0.004333496, -0.032226562, 0.139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>optimum</td>\n",
       "      <td>[best, greatest, most]</td>\n",
       "      <td>[-0.13378906, -0.064453125, -0.036376953, -0.0...</td>\n",
       "      <td>[-0.12695312, 0.021972656, 0.28710938, 0.15332...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>particulars</td>\n",
       "      <td>[details]</td>\n",
       "      <td>[0.19238281, 0.12011719, 0.053222656, -0.16015...</td>\n",
       "      <td>[0.06347656, -0.067871094, 0.07714844, -0.2197...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>penurious</td>\n",
       "      <td>[poor]</td>\n",
       "      <td>[0.1796875, 0.37109375, 0.0045166016, 0.194335...</td>\n",
       "      <td>[0.21484375, 0.26367188, -0.040771484, 0.11132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>perchance</td>\n",
       "      <td>[perhaps]</td>\n",
       "      <td>[-0.037353516, 0.052001953, 0.05908203, 0.2373...</td>\n",
       "      <td>[0.16894531, 0.018310547, 0.15136719, 0.310546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>practicable</td>\n",
       "      <td>[practical]</td>\n",
       "      <td>[-0.40429688, 0.12890625, 0.22070312, 0.147460...</td>\n",
       "      <td>[-0.03125, -0.19921875, -0.067871094, 0.040283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>preowned</td>\n",
       "      <td>[used]</td>\n",
       "      <td>[0.20019531, 0.103027344, -0.24902344, 0.04980...</td>\n",
       "      <td>[0.20214844, 0.11376953, 0.24121094, 0.1079101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>regarding</td>\n",
       "      <td>[about, of, on]</td>\n",
       "      <td>[-0.15820312, -0.038085938, 0.118652344, -0.23...</td>\n",
       "      <td>[0.20214844, -0.08105469, 0.18359375, -0.13671...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>regardless</td>\n",
       "      <td>[regardless]</td>\n",
       "      <td>[0.00015354156, -0.24316406, 0.013977051, 0.01...</td>\n",
       "      <td>[0.00015354156, -0.24316406, 0.013977051, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>subsequent</td>\n",
       "      <td>[later, next, after, then]</td>\n",
       "      <td>[0.057128906, -0.08935547, 0.08691406, 0.07324...</td>\n",
       "      <td>[0.18847656, -0.17382812, 0.15332031, 0.055664...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>substantial</td>\n",
       "      <td>[large, much]</td>\n",
       "      <td>[0.029418945, -0.011352539, -0.24023438, 0.208...</td>\n",
       "      <td>[0.044921875, 0.1484375, -0.12695312, 0.169921...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>viable</td>\n",
       "      <td>[practical, workable]</td>\n",
       "      <td>[-0.15722656, -0.03125, -0.103515625, -0.02111...</td>\n",
       "      <td>[-0.03125, -0.19921875, -0.067871094, 0.040283...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>whomsoever</td>\n",
       "      <td>[whoever, whomever]</td>\n",
       "      <td>[-0.21875, -0.10205078, -0.016967773, 0.492187...</td>\n",
       "      <td>[0.045166016, -0.20703125, 0.083984375, 0.0354...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>witnessed</td>\n",
       "      <td>[saw]</td>\n",
       "      <td>[0.002090454, 0.18066406, 0.06201172, -0.04858...</td>\n",
       "      <td>[0.09423828, 0.20117188, 0.092285156, 0.023071...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           formal                 suggestions  \\\n",
       "103     whosoever         [whoever, whomever]   \n",
       "112      commence              [begin, start]   \n",
       "119        depart                 [leave, go]   \n",
       "120        retain                      [keep]   \n",
       "121         cease                      [stop]   \n",
       "123        reside               [live, house]   \n",
       "128   inexpensive                     [cheap]   \n",
       "129  subsequently               [next, later]   \n",
       "162     abominate                      [hate]   \n",
       "164        accrue                 [add, gain]   \n",
       "165      accurate                     [right]   \n",
       "167     acquiesce                     [agree]   \n",
       "169    adjustment        [change, alteration]   \n",
       "171     alleviate              [ease, reduce]   \n",
       "172      allocate                    [divide]   \n",
       "173    ameliorate             [improve, help]   \n",
       "174    anticipate                    [expect]   \n",
       "177     apprehend                    [arrest]   \n",
       "180        attain                      [meet]   \n",
       "181       attempt                       [try]   \n",
       "184     authorize                [allow, let]   \n",
       "192           beg                       [ask]   \n",
       "193    capability                   [ability]   \n",
       "197      comprise                      [form]   \n",
       "198       conceal                      [hide]   \n",
       "200   consolidate               [join, merge]   \n",
       "202       contain                       [has]   \n",
       "203       convene                      [meet]   \n",
       "205          deem            [believe, think]   \n",
       "209     designate              [choose, name]   \n",
       "..            ...                         ...   \n",
       "362        caveat                   [warning]   \n",
       "364      cogitate                     [think]   \n",
       "366   comestibles                      [food]   \n",
       "377    definitely              [really, very]   \n",
       "391    emoluments               [fee, salary]   \n",
       "394     equitable                      [fair]   \n",
       "395    equivalent                     [equal]   \n",
       "396     evidenced                    [showed]   \n",
       "398     excluding                    [except]   \n",
       "399   expeditious               [fast, quick]   \n",
       "411     identical                      [same]   \n",
       "413      impacted         [affected, changed]   \n",
       "466       maximum   [greatest, largest, most]   \n",
       "468       minimum           [least, smallest]   \n",
       "469      moreover                      [also]   \n",
       "470      multiple                      [many]   \n",
       "474      numerous                      [many]   \n",
       "484       optimum      [best, greatest, most]   \n",
       "488   particulars                   [details]   \n",
       "490     penurious                      [poor]   \n",
       "492     perchance                   [perhaps]   \n",
       "499   practicable                 [practical]   \n",
       "500      preowned                      [used]   \n",
       "512     regarding             [about, of, on]   \n",
       "513    regardless                [regardless]   \n",
       "522    subsequent  [later, next, after, then]   \n",
       "524   substantial               [large, much]   \n",
       "541        viable       [practical, workable]   \n",
       "547    whomsoever         [whoever, whomever]   \n",
       "554     witnessed                       [saw]   \n",
       "\n",
       "                                                 X_w2v  \\\n",
       "103  [-0.21972656, -0.19921875, 0.030517578, 0.3574...   \n",
       "112  [-0.27734375, 0.025756836, 0.115234375, 0.1455...   \n",
       "119  [0.032226562, 0.140625, -0.053466797, 0.007019...   \n",
       "120  [0.13769531, -0.064453125, -0.24121094, -0.056...   \n",
       "121  [-0.2109375, -0.20019531, 0.296875, 0.17089844...   \n",
       "123  [-0.091796875, -0.05419922, -0.092285156, -0.0...   \n",
       "128  [0.0546875, -0.13671875, -0.14746094, 0.227539...   \n",
       "129  [-0.0079956055, -0.114746094, 0.107910156, -0....   \n",
       "162  [0.028930664, 0.037109375, 0.13378906, 0.11083...   \n",
       "164  [0.12402344, 0.07714844, -0.17773438, 0.324218...   \n",
       "165  [0.004211426, -0.35351562, 0.0035552979, -0.20...   \n",
       "167  [-0.043701172, -0.056152344, -0.03491211, 0.21...   \n",
       "169  [-0.24414062, 0.106933594, -0.32226562, 0.3125...   \n",
       "171  [-0.18359375, 0.111328125, -0.25195312, -0.166...   \n",
       "172  [-0.029174805, -0.16503906, 0.05883789, 0.1079...   \n",
       "173  [-0.28515625, 0.22363281, -0.18359375, 0.04907...   \n",
       "174  [-0.056640625, 0.10888672, 0.00592041, 0.13769...   \n",
       "177  [0.051513672, 0.20996094, 0.140625, -0.1367187...   \n",
       "180  [-0.059570312, 0.03881836, -0.296875, 0.112792...   \n",
       "181  [0.20410156, 0.15820312, -0.05419922, -0.00970...   \n",
       "184  [-0.107421875, -0.018066406, 0.08642578, -0.02...   \n",
       "192  [0.24804688, 0.016967773, 0.12109375, 0.421875...   \n",
       "193  [0.015319824, 0.10205078, 0.1640625, 0.0272216...   \n",
       "197  [-0.15625, -0.22265625, 0.34375, -0.08642578, ...   \n",
       "198  [0.1484375, 0.07421875, -0.28710938, -0.201171...   \n",
       "200  [-0.28320312, 0.020385742, -0.17871094, 0.0927...   \n",
       "202  [-0.0020751953, -0.10644531, 0.14941406, 0.057...   \n",
       "203  [0.026611328, 0.265625, 0.12060547, 0.10791015...   \n",
       "205  [-0.32421875, -0.048095703, 0.140625, 0.205078...   \n",
       "209  [-0.048339844, -0.041992188, 0.115722656, 0.22...   \n",
       "..                                                 ...   \n",
       "362  [0.15234375, -0.03515625, 0.059814453, 0.125, ...   \n",
       "364  [0.016723633, 0.19238281, 0.08544922, 0.349609...   \n",
       "366  [-0.02758789, -0.036865234, -0.0043945312, 0.5...   \n",
       "377  [0.06738281, 0.064453125, -0.09375, 0.21777344...   \n",
       "391  [0.24414062, -0.103027344, 0.125, 0.74609375, ...   \n",
       "394  [-0.25, -0.030517578, -0.21777344, 0.21679688,...   \n",
       "395  [0.16503906, -0.33789062, 0.25195312, 0.125, -...   \n",
       "396  [-0.24707031, 0.24023438, -0.24902344, -0.0429...   \n",
       "398  [-0.059570312, 0.16503906, 0.095703125, 0.2187...   \n",
       "399  [-0.21484375, 0.35742188, -0.056640625, 0.1127...   \n",
       "411  [0.08154297, -0.039794922, 0.125, 0.043701172,...   \n",
       "413  [-0.26953125, 0.10986328, 0.0079956055, 0.1494...   \n",
       "466  [0.048339844, -0.375, 0.15820312, -0.100097656...   \n",
       "468  [-0.17675781, -0.296875, 0.030517578, 0.143554...   \n",
       "469  [0.061523438, 0.036376953, -0.056884766, 0.190...   \n",
       "470  [0.022705078, -0.11279297, -0.24804688, 0.0957...   \n",
       "474  [-0.025146484, 0.067871094, -0.29882812, -0.06...   \n",
       "484  [-0.13378906, -0.064453125, -0.036376953, -0.0...   \n",
       "488  [0.19238281, 0.12011719, 0.053222656, -0.16015...   \n",
       "490  [0.1796875, 0.37109375, 0.0045166016, 0.194335...   \n",
       "492  [-0.037353516, 0.052001953, 0.05908203, 0.2373...   \n",
       "499  [-0.40429688, 0.12890625, 0.22070312, 0.147460...   \n",
       "500  [0.20019531, 0.103027344, -0.24902344, 0.04980...   \n",
       "512  [-0.15820312, -0.038085938, 0.118652344, -0.23...   \n",
       "513  [0.00015354156, -0.24316406, 0.013977051, 0.01...   \n",
       "522  [0.057128906, -0.08935547, 0.08691406, 0.07324...   \n",
       "524  [0.029418945, -0.011352539, -0.24023438, 0.208...   \n",
       "541  [-0.15722656, -0.03125, -0.103515625, -0.02111...   \n",
       "547  [-0.21875, -0.10205078, -0.016967773, 0.492187...   \n",
       "554  [0.002090454, 0.18066406, 0.06201172, -0.04858...   \n",
       "\n",
       "                                                 y_w2v  \n",
       "103  [0.045166016, -0.20703125, 0.083984375, 0.0354...  \n",
       "112  [0.055664062, 0.12695312, 0.16308594, 0.150390...  \n",
       "119  [0.18554688, 0.008178711, 0.032958984, 0.17675...  \n",
       "120  [0.060546875, -0.012939453, -0.10888672, 0.143...  \n",
       "121  [-0.057861328, 0.013183594, 0.115234375, 0.069...  \n",
       "123  [0.016967773, 0.017333984, -0.041748047, 0.126...  \n",
       "128  [0.06738281, -0.08105469, -0.103027344, 0.2539...  \n",
       "129  [0.18261719, -0.044921875, 0.13867188, 0.01165...  \n",
       "162  [0.1328125, 0.080078125, 0.28710938, 0.0986328...  \n",
       "164  [-0.008728027, 0.1015625, -0.056884766, 0.1416...  \n",
       "165  [0.14550781, -0.018920898, 0.096191406, 0.1289...  \n",
       "167  [-0.03857422, 0.026245117, 0.19042969, 0.12109...  \n",
       "169  [-0.060058594, -0.09326172, -0.072265625, 0.19...  \n",
       "171  [0.17480469, 0.27929688, -0.29492188, -0.18457...  \n",
       "172  [0.12695312, 0.103027344, 0.10888672, -0.04150...  \n",
       "173  [-0.33984375, 0.25390625, -0.021240234, -0.163...  \n",
       "174  [0.05102539, 0.19921875, -0.002090454, 0.18847...  \n",
       "177  [0.029907227, -0.0625, -0.011108398, -0.316406...  \n",
       "180  [-0.36914062, 0.171875, 0.08105469, 0.01965332...  \n",
       "181  [0.24023438, 0.20117188, 0.16210938, 0.2089843...  \n",
       "184  [-0.13769531, -0.0012130737, 0.1640625, 0.0742...  \n",
       "192  [-0.028076172, 0.05859375, 0.18945312, 0.09765...  \n",
       "193  [0.23828125, 0.125, -0.056640625, 0.050048828,...  \n",
       "197  [0.083496094, -0.007293701, -0.026489258, -0.0...  \n",
       "198  [0.18847656, 0.05517578, -0.21484375, -0.09814...  \n",
       "200  [-0.056396484, 0.050048828, 0.10986328, 0.2265...  \n",
       "202  [-0.044921875, -0.030395508, 0.0023498535, -0....  \n",
       "203  [-0.36914062, 0.171875, 0.08105469, 0.01965332...  \n",
       "205  [-0.1640625, 0.010803223, 0.033203125, 0.08007...  \n",
       "209  [0.08496094, 0.125, -0.030029297, 0.30078125, ...  \n",
       "..                                                 ...  \n",
       "362  [-0.11376953, -0.15136719, 0.16992188, -0.0500...  \n",
       "364  [-0.046875, 0.06689453, 0.009338379, 0.2636718...  \n",
       "366  [-0.18164062, 0.16503906, -0.16601562, 0.35742...  \n",
       "377  [0.096191406, -0.028686523, -0.10839844, 0.145...  \n",
       "391  [0.25976562, 0.09423828, 0.2109375, -0.0329589...  \n",
       "394  [-0.16113281, -0.037109375, -0.055419922, 0.12...  \n",
       "395  [-0.053955078, -0.18457031, 0.12792969, 0.1201...  \n",
       "396  [-0.08886719, 0.10498047, -0.07421875, -0.1269...  \n",
       "398  [-0.01928711, -0.16992188, 0.15917969, 0.18847...  \n",
       "399  [0.14453125, -0.012390137, 0.119140625, 0.0415...  \n",
       "411  [0.17089844, -0.012084961, 0.036132812, 0.1728...  \n",
       "413  [-0.0625, 0.0014724731, 0.12597656, 0.10205078...  \n",
       "466  [0.078125, -0.04736328, 0.27734375, 0.21777344...  \n",
       "468  [0.080566406, -0.14160156, 0.12792969, 0.29687...  \n",
       "469  [0.053466797, 0.012023926, -0.006500244, 0.008...  \n",
       "470  [0.19335938, -0.004333496, -0.032226562, 0.139...  \n",
       "474  [0.19335938, -0.004333496, -0.032226562, 0.139...  \n",
       "484  [-0.12695312, 0.021972656, 0.28710938, 0.15332...  \n",
       "488  [0.06347656, -0.067871094, 0.07714844, -0.2197...  \n",
       "490  [0.21484375, 0.26367188, -0.040771484, 0.11132...  \n",
       "492  [0.16894531, 0.018310547, 0.15136719, 0.310546...  \n",
       "499  [-0.03125, -0.19921875, -0.067871094, 0.040283...  \n",
       "500  [0.20214844, 0.11376953, 0.24121094, 0.1079101...  \n",
       "512  [0.20214844, -0.08105469, 0.18359375, -0.13671...  \n",
       "513  [0.00015354156, -0.24316406, 0.013977051, 0.01...  \n",
       "522  [0.18847656, -0.17382812, 0.15332031, 0.055664...  \n",
       "524  [0.044921875, 0.1484375, -0.12695312, 0.169921...  \n",
       "541  [-0.03125, -0.19921875, -0.067871094, 0.040283...  \n",
       "547  [0.045166016, -0.20703125, 0.083984375, 0.0354...  \n",
       "554  [0.09423828, 0.20117188, 0.092285156, 0.023071...  \n",
       "\n",
       "[115 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = words_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in train.iterrows():\n",
    "    assert len(row['X_w2v']) == 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(train['X_w2v']))\n",
    "y = np.array(list(train['y_w2v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999982279"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>sirrah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Kind regards,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>doth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.33007812, 0.100097656, -0.016723633, 0.3535...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>It concerns</td>\n",
       "      <td>[It’s about]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Mrs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.23242188, -0.1875, -0.28125, -0.06542969, -...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>identical</td>\n",
       "      <td>[same]</td>\n",
       "      <td>[0.08154297, -0.039794922, 0.125, 0.043701172,...</td>\n",
       "      <td>[0.17089844, -0.012084961, 0.036132812, 0.1728...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>henceforward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0546875, -0.032714844, 0.17382812, 0.053466...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>enounce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>whencesoever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>anon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.16015625, 0.027954102, -0.40234375, 0.34570...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            formal   suggestions  \\\n",
       "62          sirrah           NaN   \n",
       "140  Kind regards,           NaN   \n",
       "17            doth           NaN   \n",
       "138    It concerns  [It’s about]   \n",
       "144            Mrs           NaN   \n",
       "411      identical        [same]   \n",
       "35    henceforward           NaN   \n",
       "225        enounce           NaN   \n",
       "86    whencesoever           NaN   \n",
       "10            anon           NaN   \n",
       "\n",
       "                                                 X_w2v  \\\n",
       "62                                                 NaN   \n",
       "140                                                NaN   \n",
       "17   [0.33007812, 0.100097656, -0.016723633, 0.3535...   \n",
       "138                                                NaN   \n",
       "144  [0.23242188, -0.1875, -0.28125, -0.06542969, -...   \n",
       "411  [0.08154297, -0.039794922, 0.125, 0.043701172,...   \n",
       "35   [0.0546875, -0.032714844, 0.17382812, 0.053466...   \n",
       "225                                                NaN   \n",
       "86                                                 NaN   \n",
       "10   [0.16015625, 0.027954102, -0.40234375, 0.34570...   \n",
       "\n",
       "                                                 y_w2v  \n",
       "62                                                 NaN  \n",
       "140                                                NaN  \n",
       "17                                                 NaN  \n",
       "138                                                NaN  \n",
       "144                                                NaN  \n",
       "411  [0.17089844, -0.012084961, 0.036132812, 0.1728...  \n",
       "35                                                 NaN  \n",
       "225                                                NaN  \n",
       "86                                                 NaN  \n",
       "10                                                 NaN  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    pred = lr.predict([word]).reshape(-1, 1)\n",
    "    pred = pred.reshape(300,)\n",
    "    return w2v.similar_by_vector(pred, topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7f1d9c06524df1b4a390165db4f62e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_pred = []\n",
    "for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "    if type(row['X_w2v']) == float:\n",
    "        formal = nltk.word_tokenize(row['formal'])\n",
    "        vec = process_word_lists(formal, w2v)\n",
    "        if type(vec) == float:\n",
    "            w2v_pred.append(np.nan)\n",
    "        else:\n",
    "            w2v_pred.append(predict(vec))\n",
    "    else:\n",
    "        w2v_pred.append(predict(row['X_w2v']))\n",
    "words_df['pred_w2v'] = w2v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "      <th>pred_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set forth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(facililty, 0.28416314721107483), (same, 0.28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abeyance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.115234375, 0.059814453, 0.18066406, 0.0791...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(gonig, 0.4544585347175598), (Oooops, 0.44092...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in abeyance</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(next, 0.4528557062149048), (just, 0.43177771...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.20898438, 0.042236328, 0.0022277832, -0.03...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(hate, 0.5216549634933472), (think, 0.5096905...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afore mentioned</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(hate, 0.4496977925300598), (thought, 0.43439...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            formal suggestions  \\\n",
       "0        set forth         NaN   \n",
       "1         abeyance         NaN   \n",
       "2      in abeyance         NaN   \n",
       "3            afore         NaN   \n",
       "4  afore mentioned         NaN   \n",
       "\n",
       "                                               X_w2v y_w2v  \\\n",
       "0                                                NaN   NaN   \n",
       "1  [-0.115234375, 0.059814453, 0.18066406, 0.0791...   NaN   \n",
       "2                                                NaN   NaN   \n",
       "3  [-0.20898438, 0.042236328, 0.0022277832, -0.03...   NaN   \n",
       "4                                                NaN   NaN   \n",
       "\n",
       "                                            pred_w2v  \n",
       "0  [(facililty, 0.28416314721107483), (same, 0.28...  \n",
       "1  [(gonig, 0.4544585347175598), (Oooops, 0.44092...  \n",
       "2  [(next, 0.4528557062149048), (just, 0.43177771...  \n",
       "3  [(hate, 0.5216549634933472), (think, 0.5096905...  \n",
       "4  [(hate, 0.4496977925300598), (thought, 0.43439...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df['pred_w2v'] = w2v_pred\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        print('Original Word:\\t' + row['formal'])\n",
    "        train = type(row['y_w2v']) != float\n",
    "        print('Training Data?:\\t' + str(train))\n",
    "        if type(row['suggestions']) != float:\n",
    "            print('Given Answer:\\t' + str(row['suggestions']))\n",
    "        else:\n",
    "            print()\n",
    "        if type(row['pred_w2v']) != float:\n",
    "            ans = ''\n",
    "            for item in row['pred_w2v']:\n",
    "                ans += item[0] + '\\t' + str('%s' % float('%.3g' % item[1])) + '\\n\\t\\t'\n",
    "            print('Pred Answers:\\t' + ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "      <th>pred_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>whosoever</td>\n",
       "      <td>[whoever, whomever]</td>\n",
       "      <td>[-0.21972656, -0.19921875, 0.030517578, 0.3574...</td>\n",
       "      <td>[0.045166016, -0.20703125, 0.083984375, 0.0354...</td>\n",
       "      <td>[(whoever, 1.0), (whomever, 0.7898032069206238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>commence</td>\n",
       "      <td>[begin, start]</td>\n",
       "      <td>[-0.27734375, 0.025756836, 0.115234375, 0.1455...</td>\n",
       "      <td>[0.055664062, 0.12695312, 0.16308594, 0.150390...</td>\n",
       "      <td>[(begin, 1.0), (begins, 0.7261765003204346), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>ascertain</td>\n",
       "      <td>[find out, learn]</td>\n",
       "      <td>[-0.22460938, -0.05493164, -0.23242188, -0.159...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(understand, 0.4546816945075989), (know, 0.44...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>depart</td>\n",
       "      <td>[leave, go]</td>\n",
       "      <td>[0.032226562, 0.140625, -0.053466797, 0.007019...</td>\n",
       "      <td>[0.18554688, 0.008178711, 0.032958984, 0.17675...</td>\n",
       "      <td>[(leave, 1.0), (leaving, 0.6598549485206604), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>retain</td>\n",
       "      <td>[keep]</td>\n",
       "      <td>[0.13769531, -0.064453125, -0.24121094, -0.056...</td>\n",
       "      <td>[0.060546875, -0.012939453, -0.10888672, 0.143...</td>\n",
       "      <td>[(keep, 0.9999999403953552), (kept, 0.77060246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>cease</td>\n",
       "      <td>[stop]</td>\n",
       "      <td>[-0.2109375, -0.20019531, 0.296875, 0.17089844...</td>\n",
       "      <td>[-0.057861328, 0.013183594, 0.115234375, 0.069...</td>\n",
       "      <td>[(stop, 1.0), (stopped, 0.6834868788719177), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>reside</td>\n",
       "      <td>[live, house]</td>\n",
       "      <td>[-0.091796875, -0.05419922, -0.092285156, -0.0...</td>\n",
       "      <td>[0.016967773, 0.017333984, -0.041748047, 0.126...</td>\n",
       "      <td>[(live, 0.9999999403953552), (living, 0.577273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>inexpensive</td>\n",
       "      <td>[cheap]</td>\n",
       "      <td>[0.0546875, -0.13671875, -0.14746094, 0.227539...</td>\n",
       "      <td>[0.06738281, -0.08105469, -0.103027344, 0.2539...</td>\n",
       "      <td>[(cheap, 1.0), (Cheap, 0.7455264329910278), (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>subsequently</td>\n",
       "      <td>[next, later]</td>\n",
       "      <td>[-0.0079956055, -0.114746094, 0.107910156, -0....</td>\n",
       "      <td>[0.18261719, -0.044921875, 0.13867188, 0.01165...</td>\n",
       "      <td>[(next, 0.9999999403953552), (Next, 0.62757861...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>abominate</td>\n",
       "      <td>[hate]</td>\n",
       "      <td>[0.028930664, 0.037109375, 0.13378906, 0.11083...</td>\n",
       "      <td>[0.1328125, 0.080078125, 0.28710938, 0.0986328...</td>\n",
       "      <td>[(hate, 1.0), (despise, 0.6712517142295837), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>accompany</td>\n",
       "      <td>[go with]</td>\n",
       "      <td>[-0.07519531, 0.020996094, -0.0031433105, -0.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(later, 0.5166234374046326), (shortly_afterwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>accrue</td>\n",
       "      <td>[add, gain]</td>\n",
       "      <td>[0.12402344, 0.07714844, -0.17773438, 0.324218...</td>\n",
       "      <td>[-0.008728027, 0.1015625, -0.056884766, 0.1416...</td>\n",
       "      <td>[(add, 0.9999999403953552), (Adding, 0.5781972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>accurate</td>\n",
       "      <td>[right]</td>\n",
       "      <td>[0.004211426, -0.35351562, 0.0035552979, -0.20...</td>\n",
       "      <td>[0.14550781, -0.018920898, 0.096191406, 0.1289...</td>\n",
       "      <td>[(right, 1.0), (Right, 0.5703939199447632), (w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>acquiesce</td>\n",
       "      <td>[agree]</td>\n",
       "      <td>[-0.043701172, -0.056152344, -0.03491211, 0.21...</td>\n",
       "      <td>[-0.03857422, 0.026245117, 0.19042969, 0.12109...</td>\n",
       "      <td>[(agree, 1.0), (disagree, 0.7711759209632874),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>adjustment</td>\n",
       "      <td>[change, alteration]</td>\n",
       "      <td>[-0.24414062, 0.106933594, -0.32226562, 0.3125...</td>\n",
       "      <td>[-0.060058594, -0.09326172, -0.072265625, 0.19...</td>\n",
       "      <td>[(change, 1.0), (changes, 0.7581716775894165),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>alleviate</td>\n",
       "      <td>[ease, reduce]</td>\n",
       "      <td>[-0.18359375, 0.111328125, -0.25195312, -0.166...</td>\n",
       "      <td>[0.17480469, 0.27929688, -0.29492188, -0.18457...</td>\n",
       "      <td>[(ease, 1.0), (alleviate, 0.6578652858734131),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>allocate</td>\n",
       "      <td>[divide]</td>\n",
       "      <td>[-0.029174805, -0.16503906, 0.05883789, 0.1079...</td>\n",
       "      <td>[0.12695312, 0.103027344, 0.10888672, -0.04150...</td>\n",
       "      <td>[(divide, 1.0), (divides, 0.7381653785705566),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>ameliorate</td>\n",
       "      <td>[improve, help]</td>\n",
       "      <td>[-0.28515625, 0.22363281, -0.18359375, 0.04907...</td>\n",
       "      <td>[-0.33984375, 0.25390625, -0.021240234, -0.163...</td>\n",
       "      <td>[(improve, 1.0), (improving, 0.763739407062530...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>anticipate</td>\n",
       "      <td>[expect]</td>\n",
       "      <td>[-0.056640625, 0.10888672, 0.00592041, 0.13769...</td>\n",
       "      <td>[0.05102539, 0.19921875, -0.002090454, 0.18847...</td>\n",
       "      <td>[(expect, 1.0), (expecting, 0.6965944766998291...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>apologize</td>\n",
       "      <td>[say sorry]</td>\n",
       "      <td>[-0.1875, -0.056640625, 0.29101562, -0.1474609...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(hate, 0.6118065118789673), (think, 0.5536184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>apprehend</td>\n",
       "      <td>[arrest]</td>\n",
       "      <td>[0.051513672, 0.20996094, 0.140625, -0.1367187...</td>\n",
       "      <td>[0.029907227, -0.0625, -0.011108398, -0.316406...</td>\n",
       "      <td>[(arrest, 1.0), (arrests, 0.698840856552124), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>attain</td>\n",
       "      <td>[meet]</td>\n",
       "      <td>[-0.059570312, 0.03881836, -0.296875, 0.112792...</td>\n",
       "      <td>[-0.36914062, 0.171875, 0.08105469, 0.01965332...</td>\n",
       "      <td>[(meet, 1.0), (meets, 0.6858962774276733), (me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>attempt</td>\n",
       "      <td>[try]</td>\n",
       "      <td>[0.20410156, 0.15820312, -0.05419922, -0.00970...</td>\n",
       "      <td>[0.24023438, 0.20117188, 0.16210938, 0.2089843...</td>\n",
       "      <td>[(try, 1.0), (trying, 0.7056990265846252), (tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>authorize</td>\n",
       "      <td>[allow, let]</td>\n",
       "      <td>[-0.107421875, -0.018066406, 0.08642578, -0.02...</td>\n",
       "      <td>[-0.13769531, -0.0012130737, 0.1640625, 0.0742...</td>\n",
       "      <td>[(allow, 0.9999999403953552), (enable, 0.74900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>beg</td>\n",
       "      <td>[ask]</td>\n",
       "      <td>[0.24804688, 0.016967773, 0.12109375, 0.421875...</td>\n",
       "      <td>[-0.028076172, 0.05859375, 0.18945312, 0.09765...</td>\n",
       "      <td>[(ask, 1.0), (asking, 0.7390810251235962), (as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>capability</td>\n",
       "      <td>[ability]</td>\n",
       "      <td>[0.015319824, 0.10205078, 0.1640625, 0.0272216...</td>\n",
       "      <td>[0.23828125, 0.125, -0.056640625, 0.050048828,...</td>\n",
       "      <td>[(ability, 1.0), (inability, 0.636398434638977...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>comprise</td>\n",
       "      <td>[form]</td>\n",
       "      <td>[-0.15625, -0.22265625, 0.34375, -0.08642578, ...</td>\n",
       "      <td>[0.083496094, -0.007293701, -0.026489258, -0.0...</td>\n",
       "      <td>[(form, 1.0), (forms, 0.6484163999557495), (sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>conceal</td>\n",
       "      <td>[hide]</td>\n",
       "      <td>[0.1484375, 0.07421875, -0.28710938, -0.201171...</td>\n",
       "      <td>[0.18847656, 0.05517578, -0.21484375, -0.09814...</td>\n",
       "      <td>[(hide, 1.0), (conceal, 0.7830645442008972), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>consolidate</td>\n",
       "      <td>[join, merge]</td>\n",
       "      <td>[-0.28320312, 0.020385742, -0.17871094, 0.0927...</td>\n",
       "      <td>[-0.056396484, 0.050048828, 0.10986328, 0.2265...</td>\n",
       "      <td>[(join, 1.0), (joining, 0.7053104639053345), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>contain</td>\n",
       "      <td>[has]</td>\n",
       "      <td>[-0.0020751953, -0.10644531, 0.14941406, 0.057...</td>\n",
       "      <td>[-0.044921875, -0.030395508, 0.0023498535, -0....</td>\n",
       "      <td>[(has, 1.0), (had, 0.6411882638931274), (Has, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>definitely</td>\n",
       "      <td>[really, very]</td>\n",
       "      <td>[0.06738281, 0.064453125, -0.09375, 0.21777344...</td>\n",
       "      <td>[0.096191406, -0.028686523, -0.10839844, 0.145...</td>\n",
       "      <td>[(really, 1.0), (obviously, 0.745040237903595)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>emoluments</td>\n",
       "      <td>[fee, salary]</td>\n",
       "      <td>[0.24414062, -0.103027344, 0.125, 0.74609375, ...</td>\n",
       "      <td>[0.25976562, 0.09423828, 0.2109375, -0.0329589...</td>\n",
       "      <td>[(fee, 1.0), (fees, 0.8403059244155884), (Fees...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>equitable</td>\n",
       "      <td>[fair]</td>\n",
       "      <td>[-0.25, -0.030517578, -0.21777344, 0.21679688,...</td>\n",
       "      <td>[-0.16113281, -0.037109375, -0.055419922, 0.12...</td>\n",
       "      <td>[(fair, 1.0), (Fair, 0.5540855526924133), (Kur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>equivalent</td>\n",
       "      <td>[equal]</td>\n",
       "      <td>[0.16503906, -0.33789062, 0.25195312, 0.125, -...</td>\n",
       "      <td>[-0.053955078, -0.18457031, 0.12792969, 0.1201...</td>\n",
       "      <td>[(equal, 1.0), (Equal, 0.597323477268219), (eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>evidenced</td>\n",
       "      <td>[showed]</td>\n",
       "      <td>[-0.24707031, 0.24023438, -0.24902344, -0.0429...</td>\n",
       "      <td>[-0.08886719, 0.10498047, -0.07421875, -0.1269...</td>\n",
       "      <td>[(showed, 1.0), (showing, 0.7537652850151062),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>excluding</td>\n",
       "      <td>[except]</td>\n",
       "      <td>[-0.059570312, 0.16503906, 0.095703125, 0.2187...</td>\n",
       "      <td>[-0.01928711, -0.16992188, 0.15917969, 0.18847...</td>\n",
       "      <td>[(except, 1.0000001192092896), (Except, 0.6435...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>expeditious</td>\n",
       "      <td>[fast, quick]</td>\n",
       "      <td>[-0.21484375, 0.35742188, -0.056640625, 0.1127...</td>\n",
       "      <td>[0.14453125, -0.012390137, 0.119140625, 0.0415...</td>\n",
       "      <td>[(fast, 1.0000001192092896), (quick, 0.5701605...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>identical</td>\n",
       "      <td>[same]</td>\n",
       "      <td>[0.08154297, -0.039794922, 0.125, 0.043701172,...</td>\n",
       "      <td>[0.17089844, -0.012084961, 0.036132812, 0.1728...</td>\n",
       "      <td>[(same, 1.0), (Same, 0.579692542552948), (simi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>impacted</td>\n",
       "      <td>[affected, changed]</td>\n",
       "      <td>[-0.26953125, 0.10986328, 0.0079956055, 0.1494...</td>\n",
       "      <td>[-0.0625, 0.0014724731, 0.12597656, 0.10205078...</td>\n",
       "      <td>[(affected, 1.0), (impacted, 0.813484549522399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>maximum</td>\n",
       "      <td>[greatest, largest, most]</td>\n",
       "      <td>[0.048339844, -0.375, 0.15820312, -0.100097656...</td>\n",
       "      <td>[0.078125, -0.04736328, 0.27734375, 0.21777344...</td>\n",
       "      <td>[(greatest, 1.0), (biggest, 0.7188718318939209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>minimum</td>\n",
       "      <td>[least, smallest]</td>\n",
       "      <td>[-0.17675781, -0.296875, 0.030517578, 0.143554...</td>\n",
       "      <td>[0.080566406, -0.14160156, 0.12792969, 0.29687...</td>\n",
       "      <td>[(least, 1.0000001192092896), (Piedra_Blanca_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>moreover</td>\n",
       "      <td>[also]</td>\n",
       "      <td>[0.061523438, 0.036376953, -0.056884766, 0.190...</td>\n",
       "      <td>[0.053466797, 0.012023926, -0.006500244, 0.008...</td>\n",
       "      <td>[(also, 1.0), (additionally, 0.612952828407287...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>multiple</td>\n",
       "      <td>[many]</td>\n",
       "      <td>[0.022705078, -0.11279297, -0.24804688, 0.0957...</td>\n",
       "      <td>[0.19335938, -0.004333496, -0.032226562, 0.139...</td>\n",
       "      <td>[(many, 1.0), (several, 0.6742649078369141), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>notwithstanding</td>\n",
       "      <td>[in spite of, still]</td>\n",
       "      <td>[0.018798828, 0.087402344, -0.13671875, 0.1010...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(kept, 0.4539951682090759), (after, 0.4228077...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>numerous</td>\n",
       "      <td>[many]</td>\n",
       "      <td>[-0.025146484, 0.067871094, -0.29882812, -0.06...</td>\n",
       "      <td>[0.19335938, -0.004333496, -0.032226562, 0.139...</td>\n",
       "      <td>[(many, 1.0), (several, 0.6742651462554932), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>oppose</td>\n",
       "      <td>[go against]</td>\n",
       "      <td>[0.010925293, 0.030883789, 0.118652344, -0.099...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(hate, 0.8024753332138062), (Hate, 0.55397832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>optimum</td>\n",
       "      <td>[best, greatest, most]</td>\n",
       "      <td>[-0.13378906, -0.064453125, -0.036376953, -0.0...</td>\n",
       "      <td>[-0.12695312, 0.021972656, 0.28710938, 0.15332...</td>\n",
       "      <td>[(best, 1.0), (finest, 0.6383626461029053), (w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>particulars</td>\n",
       "      <td>[details]</td>\n",
       "      <td>[0.19238281, 0.12011719, 0.053222656, -0.16015...</td>\n",
       "      <td>[0.06347656, -0.067871094, 0.07714844, -0.2197...</td>\n",
       "      <td>[(details, 1.0), (specifics, 0.730320215225219...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>penurious</td>\n",
       "      <td>[poor]</td>\n",
       "      <td>[0.1796875, 0.37109375, 0.0045166016, 0.194335...</td>\n",
       "      <td>[0.21484375, 0.26367188, -0.040771484, 0.11132...</td>\n",
       "      <td>[(poor, 1.0), (poorer, 0.646229088306427), (ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>perchance</td>\n",
       "      <td>[perhaps]</td>\n",
       "      <td>[-0.037353516, 0.052001953, 0.05908203, 0.2373...</td>\n",
       "      <td>[0.16894531, 0.018310547, 0.15136719, 0.310546...</td>\n",
       "      <td>[(perhaps, 1.0000001192092896), (Possibly, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>practicable</td>\n",
       "      <td>[practical]</td>\n",
       "      <td>[-0.40429688, 0.12890625, 0.22070312, 0.147460...</td>\n",
       "      <td>[-0.03125, -0.19921875, -0.067871094, 0.040283...</td>\n",
       "      <td>[(practical, 1.0), (Practical, 0.6598489284515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>preowned</td>\n",
       "      <td>[used]</td>\n",
       "      <td>[0.20019531, 0.103027344, -0.24902344, 0.04980...</td>\n",
       "      <td>[0.20214844, 0.11376953, 0.24121094, 0.1079101...</td>\n",
       "      <td>[(used, 0.9999999403953552), (utilized, 0.6846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>regarding</td>\n",
       "      <td>[about, of, on]</td>\n",
       "      <td>[-0.15820312, -0.038085938, 0.118652344, -0.23...</td>\n",
       "      <td>[0.20214844, -0.08105469, 0.18359375, -0.13671...</td>\n",
       "      <td>[(about, 1.0), (abut, 0.6566214561462402), (ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>regardless</td>\n",
       "      <td>[regardless]</td>\n",
       "      <td>[0.00015354156, -0.24316406, 0.013977051, 0.01...</td>\n",
       "      <td>[0.00015354156, -0.24316406, 0.013977051, 0.01...</td>\n",
       "      <td>[(regardless, 0.9999999403953552), (irrespecti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>subsequent</td>\n",
       "      <td>[later, next, after, then]</td>\n",
       "      <td>[0.057128906, -0.08935547, 0.08691406, 0.07324...</td>\n",
       "      <td>[0.18847656, -0.17382812, 0.15332031, 0.055664...</td>\n",
       "      <td>[(later, 1.0000001192092896), (after, 0.639662...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>substantial</td>\n",
       "      <td>[large, much]</td>\n",
       "      <td>[0.029418945, -0.011352539, -0.24023438, 0.208...</td>\n",
       "      <td>[0.044921875, 0.1484375, -0.12695312, 0.169921...</td>\n",
       "      <td>[(large, 1.0), (sizeable, 0.7341437339782715),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>television</td>\n",
       "      <td>[T.V.]</td>\n",
       "      <td>[0.012451172, 0.0048217773, 0.03491211, 0.0820...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(many, 0.5625544190406799), (nowadays, 0.4648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>viable</td>\n",
       "      <td>[practical, workable]</td>\n",
       "      <td>[-0.15722656, -0.03125, -0.103515625, -0.02111...</td>\n",
       "      <td>[-0.03125, -0.19921875, -0.067871094, 0.040283...</td>\n",
       "      <td>[(practical, 1.0), (Practical, 0.6598489284515...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>whomsoever</td>\n",
       "      <td>[whoever, whomever]</td>\n",
       "      <td>[-0.21875, -0.10205078, -0.016967773, 0.492187...</td>\n",
       "      <td>[0.045166016, -0.20703125, 0.083984375, 0.0354...</td>\n",
       "      <td>[(whoever, 1.0), (whomever, 0.789803147315979)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>witnessed</td>\n",
       "      <td>[saw]</td>\n",
       "      <td>[0.002090454, 0.18066406, 0.06201172, -0.04858...</td>\n",
       "      <td>[0.09423828, 0.20117188, 0.092285156, 0.023071...</td>\n",
       "      <td>[(saw, 1.0), (noticed, 0.5968519449234009), (w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              formal                 suggestions  \\\n",
       "103        whosoever         [whoever, whomever]   \n",
       "112         commence              [begin, start]   \n",
       "115        ascertain           [find out, learn]   \n",
       "119           depart                 [leave, go]   \n",
       "120           retain                      [keep]   \n",
       "121            cease                      [stop]   \n",
       "123           reside               [live, house]   \n",
       "128      inexpensive                     [cheap]   \n",
       "129     subsequently               [next, later]   \n",
       "162        abominate                      [hate]   \n",
       "163        accompany                   [go with]   \n",
       "164           accrue                 [add, gain]   \n",
       "165         accurate                     [right]   \n",
       "167        acquiesce                     [agree]   \n",
       "169       adjustment        [change, alteration]   \n",
       "171        alleviate              [ease, reduce]   \n",
       "172         allocate                    [divide]   \n",
       "173       ameliorate             [improve, help]   \n",
       "174       anticipate                    [expect]   \n",
       "176        apologize                 [say sorry]   \n",
       "177        apprehend                    [arrest]   \n",
       "180           attain                      [meet]   \n",
       "181          attempt                       [try]   \n",
       "184        authorize                [allow, let]   \n",
       "192              beg                       [ask]   \n",
       "193       capability                   [ability]   \n",
       "197         comprise                      [form]   \n",
       "198          conceal                      [hide]   \n",
       "200      consolidate               [join, merge]   \n",
       "202          contain                       [has]   \n",
       "..               ...                         ...   \n",
       "377       definitely              [really, very]   \n",
       "391       emoluments               [fee, salary]   \n",
       "394        equitable                      [fair]   \n",
       "395       equivalent                     [equal]   \n",
       "396        evidenced                    [showed]   \n",
       "398        excluding                    [except]   \n",
       "399      expeditious               [fast, quick]   \n",
       "411        identical                      [same]   \n",
       "413         impacted         [affected, changed]   \n",
       "466          maximum   [greatest, largest, most]   \n",
       "468          minimum           [least, smallest]   \n",
       "469         moreover                      [also]   \n",
       "470         multiple                      [many]   \n",
       "473  notwithstanding        [in spite of, still]   \n",
       "474         numerous                      [many]   \n",
       "483           oppose                [go against]   \n",
       "484          optimum      [best, greatest, most]   \n",
       "488      particulars                   [details]   \n",
       "490        penurious                      [poor]   \n",
       "492        perchance                   [perhaps]   \n",
       "499      practicable                 [practical]   \n",
       "500         preowned                      [used]   \n",
       "512        regarding             [about, of, on]   \n",
       "513       regardless                [regardless]   \n",
       "522       subsequent  [later, next, after, then]   \n",
       "524      substantial               [large, much]   \n",
       "527       television                      [T.V.]   \n",
       "541           viable       [practical, workable]   \n",
       "547       whomsoever         [whoever, whomever]   \n",
       "554        witnessed                       [saw]   \n",
       "\n",
       "                                                 X_w2v  \\\n",
       "103  [-0.21972656, -0.19921875, 0.030517578, 0.3574...   \n",
       "112  [-0.27734375, 0.025756836, 0.115234375, 0.1455...   \n",
       "115  [-0.22460938, -0.05493164, -0.23242188, -0.159...   \n",
       "119  [0.032226562, 0.140625, -0.053466797, 0.007019...   \n",
       "120  [0.13769531, -0.064453125, -0.24121094, -0.056...   \n",
       "121  [-0.2109375, -0.20019531, 0.296875, 0.17089844...   \n",
       "123  [-0.091796875, -0.05419922, -0.092285156, -0.0...   \n",
       "128  [0.0546875, -0.13671875, -0.14746094, 0.227539...   \n",
       "129  [-0.0079956055, -0.114746094, 0.107910156, -0....   \n",
       "162  [0.028930664, 0.037109375, 0.13378906, 0.11083...   \n",
       "163  [-0.07519531, 0.020996094, -0.0031433105, -0.0...   \n",
       "164  [0.12402344, 0.07714844, -0.17773438, 0.324218...   \n",
       "165  [0.004211426, -0.35351562, 0.0035552979, -0.20...   \n",
       "167  [-0.043701172, -0.056152344, -0.03491211, 0.21...   \n",
       "169  [-0.24414062, 0.106933594, -0.32226562, 0.3125...   \n",
       "171  [-0.18359375, 0.111328125, -0.25195312, -0.166...   \n",
       "172  [-0.029174805, -0.16503906, 0.05883789, 0.1079...   \n",
       "173  [-0.28515625, 0.22363281, -0.18359375, 0.04907...   \n",
       "174  [-0.056640625, 0.10888672, 0.00592041, 0.13769...   \n",
       "176  [-0.1875, -0.056640625, 0.29101562, -0.1474609...   \n",
       "177  [0.051513672, 0.20996094, 0.140625, -0.1367187...   \n",
       "180  [-0.059570312, 0.03881836, -0.296875, 0.112792...   \n",
       "181  [0.20410156, 0.15820312, -0.05419922, -0.00970...   \n",
       "184  [-0.107421875, -0.018066406, 0.08642578, -0.02...   \n",
       "192  [0.24804688, 0.016967773, 0.12109375, 0.421875...   \n",
       "193  [0.015319824, 0.10205078, 0.1640625, 0.0272216...   \n",
       "197  [-0.15625, -0.22265625, 0.34375, -0.08642578, ...   \n",
       "198  [0.1484375, 0.07421875, -0.28710938, -0.201171...   \n",
       "200  [-0.28320312, 0.020385742, -0.17871094, 0.0927...   \n",
       "202  [-0.0020751953, -0.10644531, 0.14941406, 0.057...   \n",
       "..                                                 ...   \n",
       "377  [0.06738281, 0.064453125, -0.09375, 0.21777344...   \n",
       "391  [0.24414062, -0.103027344, 0.125, 0.74609375, ...   \n",
       "394  [-0.25, -0.030517578, -0.21777344, 0.21679688,...   \n",
       "395  [0.16503906, -0.33789062, 0.25195312, 0.125, -...   \n",
       "396  [-0.24707031, 0.24023438, -0.24902344, -0.0429...   \n",
       "398  [-0.059570312, 0.16503906, 0.095703125, 0.2187...   \n",
       "399  [-0.21484375, 0.35742188, -0.056640625, 0.1127...   \n",
       "411  [0.08154297, -0.039794922, 0.125, 0.043701172,...   \n",
       "413  [-0.26953125, 0.10986328, 0.0079956055, 0.1494...   \n",
       "466  [0.048339844, -0.375, 0.15820312, -0.100097656...   \n",
       "468  [-0.17675781, -0.296875, 0.030517578, 0.143554...   \n",
       "469  [0.061523438, 0.036376953, -0.056884766, 0.190...   \n",
       "470  [0.022705078, -0.11279297, -0.24804688, 0.0957...   \n",
       "473  [0.018798828, 0.087402344, -0.13671875, 0.1010...   \n",
       "474  [-0.025146484, 0.067871094, -0.29882812, -0.06...   \n",
       "483  [0.010925293, 0.030883789, 0.118652344, -0.099...   \n",
       "484  [-0.13378906, -0.064453125, -0.036376953, -0.0...   \n",
       "488  [0.19238281, 0.12011719, 0.053222656, -0.16015...   \n",
       "490  [0.1796875, 0.37109375, 0.0045166016, 0.194335...   \n",
       "492  [-0.037353516, 0.052001953, 0.05908203, 0.2373...   \n",
       "499  [-0.40429688, 0.12890625, 0.22070312, 0.147460...   \n",
       "500  [0.20019531, 0.103027344, -0.24902344, 0.04980...   \n",
       "512  [-0.15820312, -0.038085938, 0.118652344, -0.23...   \n",
       "513  [0.00015354156, -0.24316406, 0.013977051, 0.01...   \n",
       "522  [0.057128906, -0.08935547, 0.08691406, 0.07324...   \n",
       "524  [0.029418945, -0.011352539, -0.24023438, 0.208...   \n",
       "527  [0.012451172, 0.0048217773, 0.03491211, 0.0820...   \n",
       "541  [-0.15722656, -0.03125, -0.103515625, -0.02111...   \n",
       "547  [-0.21875, -0.10205078, -0.016967773, 0.492187...   \n",
       "554  [0.002090454, 0.18066406, 0.06201172, -0.04858...   \n",
       "\n",
       "                                                 y_w2v  \\\n",
       "103  [0.045166016, -0.20703125, 0.083984375, 0.0354...   \n",
       "112  [0.055664062, 0.12695312, 0.16308594, 0.150390...   \n",
       "115                                                NaN   \n",
       "119  [0.18554688, 0.008178711, 0.032958984, 0.17675...   \n",
       "120  [0.060546875, -0.012939453, -0.10888672, 0.143...   \n",
       "121  [-0.057861328, 0.013183594, 0.115234375, 0.069...   \n",
       "123  [0.016967773, 0.017333984, -0.041748047, 0.126...   \n",
       "128  [0.06738281, -0.08105469, -0.103027344, 0.2539...   \n",
       "129  [0.18261719, -0.044921875, 0.13867188, 0.01165...   \n",
       "162  [0.1328125, 0.080078125, 0.28710938, 0.0986328...   \n",
       "163                                                NaN   \n",
       "164  [-0.008728027, 0.1015625, -0.056884766, 0.1416...   \n",
       "165  [0.14550781, -0.018920898, 0.096191406, 0.1289...   \n",
       "167  [-0.03857422, 0.026245117, 0.19042969, 0.12109...   \n",
       "169  [-0.060058594, -0.09326172, -0.072265625, 0.19...   \n",
       "171  [0.17480469, 0.27929688, -0.29492188, -0.18457...   \n",
       "172  [0.12695312, 0.103027344, 0.10888672, -0.04150...   \n",
       "173  [-0.33984375, 0.25390625, -0.021240234, -0.163...   \n",
       "174  [0.05102539, 0.19921875, -0.002090454, 0.18847...   \n",
       "176                                                NaN   \n",
       "177  [0.029907227, -0.0625, -0.011108398, -0.316406...   \n",
       "180  [-0.36914062, 0.171875, 0.08105469, 0.01965332...   \n",
       "181  [0.24023438, 0.20117188, 0.16210938, 0.2089843...   \n",
       "184  [-0.13769531, -0.0012130737, 0.1640625, 0.0742...   \n",
       "192  [-0.028076172, 0.05859375, 0.18945312, 0.09765...   \n",
       "193  [0.23828125, 0.125, -0.056640625, 0.050048828,...   \n",
       "197  [0.083496094, -0.007293701, -0.026489258, -0.0...   \n",
       "198  [0.18847656, 0.05517578, -0.21484375, -0.09814...   \n",
       "200  [-0.056396484, 0.050048828, 0.10986328, 0.2265...   \n",
       "202  [-0.044921875, -0.030395508, 0.0023498535, -0....   \n",
       "..                                                 ...   \n",
       "377  [0.096191406, -0.028686523, -0.10839844, 0.145...   \n",
       "391  [0.25976562, 0.09423828, 0.2109375, -0.0329589...   \n",
       "394  [-0.16113281, -0.037109375, -0.055419922, 0.12...   \n",
       "395  [-0.053955078, -0.18457031, 0.12792969, 0.1201...   \n",
       "396  [-0.08886719, 0.10498047, -0.07421875, -0.1269...   \n",
       "398  [-0.01928711, -0.16992188, 0.15917969, 0.18847...   \n",
       "399  [0.14453125, -0.012390137, 0.119140625, 0.0415...   \n",
       "411  [0.17089844, -0.012084961, 0.036132812, 0.1728...   \n",
       "413  [-0.0625, 0.0014724731, 0.12597656, 0.10205078...   \n",
       "466  [0.078125, -0.04736328, 0.27734375, 0.21777344...   \n",
       "468  [0.080566406, -0.14160156, 0.12792969, 0.29687...   \n",
       "469  [0.053466797, 0.012023926, -0.006500244, 0.008...   \n",
       "470  [0.19335938, -0.004333496, -0.032226562, 0.139...   \n",
       "473                                                NaN   \n",
       "474  [0.19335938, -0.004333496, -0.032226562, 0.139...   \n",
       "483                                                NaN   \n",
       "484  [-0.12695312, 0.021972656, 0.28710938, 0.15332...   \n",
       "488  [0.06347656, -0.067871094, 0.07714844, -0.2197...   \n",
       "490  [0.21484375, 0.26367188, -0.040771484, 0.11132...   \n",
       "492  [0.16894531, 0.018310547, 0.15136719, 0.310546...   \n",
       "499  [-0.03125, -0.19921875, -0.067871094, 0.040283...   \n",
       "500  [0.20214844, 0.11376953, 0.24121094, 0.1079101...   \n",
       "512  [0.20214844, -0.08105469, 0.18359375, -0.13671...   \n",
       "513  [0.00015354156, -0.24316406, 0.013977051, 0.01...   \n",
       "522  [0.18847656, -0.17382812, 0.15332031, 0.055664...   \n",
       "524  [0.044921875, 0.1484375, -0.12695312, 0.169921...   \n",
       "527                                                NaN   \n",
       "541  [-0.03125, -0.19921875, -0.067871094, 0.040283...   \n",
       "547  [0.045166016, -0.20703125, 0.083984375, 0.0354...   \n",
       "554  [0.09423828, 0.20117188, 0.092285156, 0.023071...   \n",
       "\n",
       "                                              pred_w2v  \n",
       "103  [(whoever, 1.0), (whomever, 0.7898032069206238...  \n",
       "112  [(begin, 1.0), (begins, 0.7261765003204346), (...  \n",
       "115  [(understand, 0.4546816945075989), (know, 0.44...  \n",
       "119  [(leave, 1.0), (leaving, 0.6598549485206604), ...  \n",
       "120  [(keep, 0.9999999403953552), (kept, 0.77060246...  \n",
       "121  [(stop, 1.0), (stopped, 0.6834868788719177), (...  \n",
       "123  [(live, 0.9999999403953552), (living, 0.577273...  \n",
       "128  [(cheap, 1.0), (Cheap, 0.7455264329910278), (i...  \n",
       "129  [(next, 0.9999999403953552), (Next, 0.62757861...  \n",
       "162  [(hate, 1.0), (despise, 0.6712517142295837), (...  \n",
       "163  [(later, 0.5166234374046326), (shortly_afterwa...  \n",
       "164  [(add, 0.9999999403953552), (Adding, 0.5781972...  \n",
       "165  [(right, 1.0), (Right, 0.5703939199447632), (w...  \n",
       "167  [(agree, 1.0), (disagree, 0.7711759209632874),...  \n",
       "169  [(change, 1.0), (changes, 0.7581716775894165),...  \n",
       "171  [(ease, 1.0), (alleviate, 0.6578652858734131),...  \n",
       "172  [(divide, 1.0), (divides, 0.7381653785705566),...  \n",
       "173  [(improve, 1.0), (improving, 0.763739407062530...  \n",
       "174  [(expect, 1.0), (expecting, 0.6965944766998291...  \n",
       "176  [(hate, 0.6118065118789673), (think, 0.5536184...  \n",
       "177  [(arrest, 1.0), (arrests, 0.698840856552124), ...  \n",
       "180  [(meet, 1.0), (meets, 0.6858962774276733), (me...  \n",
       "181  [(try, 1.0), (trying, 0.7056990265846252), (tr...  \n",
       "184  [(allow, 0.9999999403953552), (enable, 0.74900...  \n",
       "192  [(ask, 1.0), (asking, 0.7390810251235962), (as...  \n",
       "193  [(ability, 1.0), (inability, 0.636398434638977...  \n",
       "197  [(form, 1.0), (forms, 0.6484163999557495), (sh...  \n",
       "198  [(hide, 1.0), (conceal, 0.7830645442008972), (...  \n",
       "200  [(join, 1.0), (joining, 0.7053104639053345), (...  \n",
       "202  [(has, 1.0), (had, 0.6411882638931274), (Has, ...  \n",
       "..                                                 ...  \n",
       "377  [(really, 1.0), (obviously, 0.745040237903595)...  \n",
       "391  [(fee, 1.0), (fees, 0.8403059244155884), (Fees...  \n",
       "394  [(fair, 1.0), (Fair, 0.5540855526924133), (Kur...  \n",
       "395  [(equal, 1.0), (Equal, 0.597323477268219), (eq...  \n",
       "396  [(showed, 1.0), (showing, 0.7537652850151062),...  \n",
       "398  [(except, 1.0000001192092896), (Except, 0.6435...  \n",
       "399  [(fast, 1.0000001192092896), (quick, 0.5701605...  \n",
       "411  [(same, 1.0), (Same, 0.579692542552948), (simi...  \n",
       "413  [(affected, 1.0), (impacted, 0.813484549522399...  \n",
       "466  [(greatest, 1.0), (biggest, 0.7188718318939209...  \n",
       "468  [(least, 1.0000001192092896), (Piedra_Blanca_e...  \n",
       "469  [(also, 1.0), (additionally, 0.612952828407287...  \n",
       "470  [(many, 1.0), (several, 0.6742649078369141), (...  \n",
       "473  [(kept, 0.4539951682090759), (after, 0.4228077...  \n",
       "474  [(many, 1.0), (several, 0.6742651462554932), (...  \n",
       "483  [(hate, 0.8024753332138062), (Hate, 0.55397832...  \n",
       "484  [(best, 1.0), (finest, 0.6383626461029053), (w...  \n",
       "488  [(details, 1.0), (specifics, 0.730320215225219...  \n",
       "490  [(poor, 1.0), (poorer, 0.646229088306427), (ab...  \n",
       "492  [(perhaps, 1.0000001192092896), (Possibly, 0.6...  \n",
       "499  [(practical, 1.0), (Practical, 0.6598489284515...  \n",
       "500  [(used, 0.9999999403953552), (utilized, 0.6846...  \n",
       "512  [(about, 1.0), (abut, 0.6566214561462402), (ab...  \n",
       "513  [(regardless, 0.9999999403953552), (irrespecti...  \n",
       "522  [(later, 1.0000001192092896), (after, 0.639662...  \n",
       "524  [(large, 1.0), (sizeable, 0.7341437339782715),...  \n",
       "527  [(many, 0.5625544190406799), (nowadays, 0.4648...  \n",
       "541  [(practical, 1.0), (Practical, 0.6598489284515...  \n",
       "547  [(whoever, 1.0), (whomever, 0.789803147315979)...  \n",
       "554  [(saw, 1.0), (noticed, 0.5968519449234009), (w...  \n",
       "\n",
       "[132 rows x 5 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.dropna(subset=['suggestions', 'X_w2v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word:\twhosoever\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['whoever', 'whomever']\n",
      "Pred Answers:\twhoever\t1.0\n",
      "\t\twhomever\t0.79\n",
      "\t\tWhoever\t0.764\n",
      "\t\tWhomever\t0.66\n",
      "\t\tsomebody\t0.627\n",
      "\t\twhatever\t0.62\n",
      "\t\tsomebody_else\t0.607\n",
      "\t\tsomeone\t0.583\n",
      "\t\tnobody\t0.583\n",
      "\t\teverybody\t0.575\n",
      "\t\t\n",
      "Original Word:\tcommence\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['begin', 'start']\n",
      "Pred Answers:\tbegin\t1.0\n",
      "\t\tbegins\t0.726\n",
      "\t\tcommence\t0.724\n",
      "\t\tstart\t0.685\n",
      "\t\tcommences\t0.63\n",
      "\t\tbegan\t0.614\n",
      "\t\tbegun\t0.608\n",
      "\t\tresume\t0.597\n",
      "\t\tbeginning\t0.581\n",
      "\t\trecommence\t0.559\n",
      "\t\t\n",
      "Original Word:\tdepart\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['leave', 'go']\n",
      "Pred Answers:\tleave\t1.0\n",
      "\t\tleaving\t0.66\n",
      "\t\tstay\t0.579\n",
      "\t\tdepart\t0.556\n",
      "\t\tLeaving\t0.549\n",
      "\t\tleft\t0.525\n",
      "\t\tleaves\t0.513\n",
      "\t\treturn\t0.507\n",
      "\t\tvacate\t0.494\n",
      "\t\tquit\t0.484\n",
      "\t\t\n",
      "Original Word:\tretain\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['keep']\n",
      "Pred Answers:\tkeep\t1.0\n",
      "\t\tkept\t0.771\n",
      "\t\tkeeping\t0.754\n",
      "\t\tkeeps\t0.728\n",
      "\t\tstay\t0.676\n",
      "\t\tKeeping\t0.657\n",
      "\t\tKeep\t0.633\n",
      "\t\tmaintain\t0.576\n",
      "\t\tKept\t0.52\n",
      "\t\tremain\t0.518\n",
      "\t\t\n",
      "Original Word:\tcease\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['stop']\n",
      "Pred Answers:\tstop\t1.0\n",
      "\t\tstopped\t0.683\n",
      "\t\tstopping\t0.63\n",
      "\t\tstops\t0.617\n",
      "\t\tStop\t0.612\n",
      "\t\thalt\t0.608\n",
      "\t\tprevent\t0.538\n",
      "\t\tStopping\t0.506\n",
      "\t\tcease\t0.503\n",
      "\t\tdissuade\t0.49\n",
      "\t\t\n",
      "Original Word:\treside\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['live', 'house']\n",
      "Pred Answers:\tlive\t1.0\n",
      "\t\tliving\t0.577\n",
      "\t\tLive\t0.532\n",
      "\t\treside\t0.506\n",
      "\t\tGoFightLive.tv\t0.5\n",
      "\t\tlived\t0.498\n",
      "\t\tscore_preview_recaps\t0.484\n",
      "\t\tcherish_el_Gamal\t0.473\n",
      "\t\twww.spss.com_invest\t0.466\n",
      "\t\tOptionetics_Inc\t0.458\n",
      "\t\t\n",
      "Original Word:\tinexpensive\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['cheap']\n",
      "Pred Answers:\tcheap\t1.0\n",
      "\t\tCheap\t0.746\n",
      "\t\tinexpensive\t0.701\n",
      "\t\tcheep\t0.651\n",
      "\t\tcheaper\t0.638\n",
      "\t\trelatively_inexpensive\t0.625\n",
      "\t\treasonably_priced\t0.607\n",
      "\t\tcheapest\t0.567\n",
      "\t\tInexpensive\t0.561\n",
      "\t\tcheaply\t0.557\n",
      "\t\t\n",
      "Original Word:\tsubsequently\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['next', 'later']\n",
      "Pred Answers:\tnext\t1.0\n",
      "\t\tNext\t0.628\n",
      "\t\tlast\t0.548\n",
      "\t\tsometime\t0.538\n",
      "\t\tlater\t0.525\n",
      "\t\ttomorrow\t0.506\n",
      "\t\tfinal\t0.503\n",
      "\t\tthenext\t0.503\n",
      "\t\t'll\t0.496\n",
      "\t\tupcoming\t0.493\n",
      "\t\t\n",
      "Original Word:\tabominate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['hate']\n",
      "Pred Answers:\thate\t1.0\n",
      "\t\tdespise\t0.671\n",
      "\t\tHate\t0.64\n",
      "\t\tdetest\t0.618\n",
      "\t\thatred\t0.616\n",
      "\t\thating\t0.61\n",
      "\t\thates\t0.609\n",
      "\t\tHATE\t0.602\n",
      "\t\tdislike\t0.601\n",
      "\t\tlove\t0.6\n",
      "\t\t\n",
      "Original Word:\taccrue\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['add', 'gain']\n",
      "Pred Answers:\tadd\t1.0\n",
      "\t\tAdding\t0.578\n",
      "\t\tAdd\t0.568\n",
      "\t\tadds\t0.566\n",
      "\t\tbring\t0.56\n",
      "\t\taugment\t0.525\n",
      "\t\tcreate\t0.521\n",
      "\t\tincorporate\t0.504\n",
      "\t\texpand\t0.499\n",
      "\t\tcombine\t0.494\n",
      "\t\t\n",
      "Original Word:\taccurate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['right']\n",
      "Pred Answers:\tright\t1.0\n",
      "\t\tRight\t0.57\n",
      "\t\twrong\t0.553\n",
      "\t\t##.Help_us\t0.55\n",
      "\t\tGoodwill_Catanese\t0.516\n",
      "\t\tleft\t0.492\n",
      "\t\tfielder_Joe_Borchard\t0.489\n",
      "\t\tNOTE_Xactly_Incent\t0.489\n",
      "\t\tfielder_Ambiorix_Concepcion\t0.484\n",
      "\t\tnow\t0.479\n",
      "\t\t\n",
      "Original Word:\tacquiesce\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['agree']\n",
      "Pred Answers:\tagree\t1.0\n",
      "\t\tdisagree\t0.771\n",
      "\t\tconcur\t0.713\n",
      "\t\tagrees\t0.593\n",
      "\t\tdisagreed\t0.571\n",
      "\t\tAgree\t0.564\n",
      "\t\tdisagreeing\t0.553\n",
      "\t\trespectfully_disagree\t0.546\n",
      "\t\tagreed\t0.545\n",
      "\t\tinsist\t0.527\n",
      "\t\t\n",
      "Original Word:\tadjustment\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['change', 'alteration']\n",
      "Pred Answers:\tchange\t1.0\n",
      "\t\tchanges\t0.758\n",
      "\t\tchanging\t0.716\n",
      "\t\tchanged\t0.688\n",
      "\t\talter\t0.672\n",
      "\t\tshift\t0.612\n",
      "\t\tChanging\t0.61\n",
      "\t\tChange\t0.574\n",
      "\t\tseismic_shift\t0.563\n",
      "\t\tChanges\t0.554\n",
      "\t\t\n",
      "Original Word:\talleviate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['ease', 'reduce']\n",
      "Pred Answers:\tease\t1.0\n",
      "\t\talleviate\t0.658\n",
      "\t\teasing\t0.627\n",
      "\t\trelieve\t0.62\n",
      "\t\teases\t0.598\n",
      "\t\tEasing\t0.591\n",
      "\t\teased\t0.579\n",
      "\t\tEase\t0.561\n",
      "\t\tlessen\t0.554\n",
      "\t\talleviating\t0.552\n",
      "\t\t\n",
      "Original Word:\tallocate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['divide']\n",
      "Pred Answers:\tdivide\t1.0\n",
      "\t\tdivides\t0.738\n",
      "\t\tdividing\t0.675\n",
      "\t\tdivided\t0.635\n",
      "\t\tchasm\t0.596\n",
      "\t\trift\t0.584\n",
      "\t\trifts\t0.567\n",
      "\t\twidening_gulf\t0.559\n",
      "\t\twidening_chasm\t0.559\n",
      "\t\tdifferences\t0.559\n",
      "\t\t\n",
      "Original Word:\tameliorate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['improve', 'help']\n",
      "Pred Answers:\timprove\t1.0\n",
      "\t\timproving\t0.764\n",
      "\t\tenhance\t0.755\n",
      "\t\timproved\t0.716\n",
      "\t\tstrengthen\t0.681\n",
      "\t\ttoimprove\t0.637\n",
      "\t\timproves\t0.636\n",
      "\t\tImproving\t0.607\n",
      "\t\timporve\t0.6\n",
      "\t\tImprove\t0.594\n",
      "\t\t\n",
      "Original Word:\tanticipate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['expect']\n",
      "Pred Answers:\texpect\t1.0\n",
      "\t\texpecting\t0.697\n",
      "\t\tanticipate\t0.677\n",
      "\t\tExpect\t0.617\n",
      "\t\tforesee\t0.604\n",
      "\t\twant\t0.585\n",
      "\t\texpected\t0.582\n",
      "\t\texpects\t0.58\n",
      "\t\tintend\t0.575\n",
      "\t\tpredicted\t0.572\n",
      "\t\t\n",
      "Original Word:\tapprehend\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['arrest']\n",
      "Pred Answers:\tarrest\t1.0\n",
      "\t\tarrests\t0.699\n",
      "\t\tarrested\t0.669\n",
      "\t\tarrrest\t0.637\n",
      "\t\trearrest\t0.604\n",
      "\t\tarresting\t0.602\n",
      "\t\tapprehended\t0.596\n",
      "\t\tdetained\t0.591\n",
      "\t\tarrest_warrant\t0.59\n",
      "\t\trearrested\t0.565\n",
      "\t\t\n",
      "Original Word:\tattain\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['meet']\n",
      "Pred Answers:\tmeet\t1.0\n",
      "\t\tmeets\t0.686\n",
      "\t\tmet\t0.655\n",
      "\t\ttomeet\t0.579\n",
      "\t\tfulfill\t0.567\n",
      "\t\tsatisfy\t0.551\n",
      "\t\tmeeting\t0.517\n",
      "\t\tMeet\t0.506\n",
      "\t\ts_spinoff_Freescale\t0.502\n",
      "\t\tdiscuss\t0.497\n",
      "\t\t\n",
      "Original Word:\tattempt\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['try']\n",
      "Pred Answers:\ttry\t1.0\n",
      "\t\ttrying\t0.706\n",
      "\t\ttried\t0.665\n",
      "\t\ttries\t0.632\n",
      "\t\twant\t0.61\n",
      "\t\thoping\t0.585\n",
      "\t\tTrying\t0.584\n",
      "\t\tattempt\t0.582\n",
      "\t\tregroup_refocus\t0.579\n",
      "\t\tattempting\t0.56\n",
      "\t\t\n",
      "Original Word:\tauthorize\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['allow', 'let']\n",
      "Pred Answers:\tallow\t1.0\n",
      "\t\tenable\t0.749\n",
      "\t\tallowing\t0.7\n",
      "\t\tallows\t0.694\n",
      "\t\tallowed\t0.642\n",
      "\t\trequire\t0.616\n",
      "\t\tenabling\t0.595\n",
      "\t\tenabled\t0.585\n",
      "\t\tenables\t0.566\n",
      "\t\tlet\t0.557\n",
      "\t\t\n",
      "Original Word:\tbeg\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['ask']\n",
      "Pred Answers:\task\t1.0\n",
      "\t\tasking\t0.739\n",
      "\t\tasked\t0.71\n",
      "\t\tasks\t0.673\n",
      "\t\ttell\t0.628\n",
      "\t\tAsk\t0.592\n",
      "\t\tknow\t0.575\n",
      "\t\tquestons\t0.561\n",
      "\t\tSCHIEFFER_Let\t0.558\n",
      "\t\tAsking\t0.558\n",
      "\t\t\n",
      "Original Word:\tcapability\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['ability']\n",
      "Pred Answers:\tability\t1.0\n",
      "\t\tinability\t0.636\n",
      "\t\tabilityto\t0.635\n",
      "\t\tabilities\t0.621\n",
      "\t\tabilty\t0.599\n",
      "\t\twillingness\t0.595\n",
      "\t\tuncanny_ability\t0.587\n",
      "\t\ttheability\t0.585\n",
      "\t\tAbility\t0.535\n",
      "\t\table\t0.533\n",
      "\t\t\n",
      "Original Word:\tcomprise\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['form']\n",
      "Pred Answers:\tform\t1.0\n",
      "\t\tforms\t0.648\n",
      "\t\tshape\t0.419\n",
      "\t\tforming\t0.399\n",
      "\t\tLead_Celador\t0.388\n",
      "\t\tcompleting_Retraction_Request\t0.387\n",
      "\t\tGianfranco_Zola_Hammers\t0.381\n",
      "\t\tmetatarsal_fractures\t0.373\n",
      "\t\tfronts_collide_Pasch\t0.369\n",
      "\t\tXavi_Hernandez_Gerard_Pique\t0.368\n",
      "\t\t\n",
      "Original Word:\tconceal\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['hide']\n",
      "Pred Answers:\thide\t1.0\n",
      "\t\tconceal\t0.783\n",
      "\t\thiding\t0.704\n",
      "\t\thid\t0.662\n",
      "\t\thidden\t0.622\n",
      "\t\thides\t0.617\n",
      "\t\tdisguise\t0.599\n",
      "\t\tHiding\t0.595\n",
      "\t\tconcealed\t0.584\n",
      "\t\tconcealing\t0.525\n",
      "\t\t\n",
      "Original Word:\tconsolidate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['join', 'merge']\n",
      "Pred Answers:\tjoin\t1.0\n",
      "\t\tjoining\t0.705\n",
      "\t\tjoined\t0.678\n",
      "\t\trejoin\t0.667\n",
      "\t\tparticipate\t0.627\n",
      "\t\tjoins\t0.623\n",
      "\t\tJoining\t0.594\n",
      "\t\tJoin\t0.54\n",
      "\t\tinvite\t0.536\n",
      "\t\tenlist\t0.534\n",
      "\t\t\n",
      "Original Word:\tcontain\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['has']\n",
      "Pred Answers:\thas\t1.0\n",
      "\t\thad\t0.641\n",
      "\t\tHas\t0.612\n",
      "\t\trecently\t0.608\n",
      "\t\tbeen\t0.601\n",
      "\t\thave\t0.559\n",
      "\t\thasn_`_t\t0.533\n",
      "\t\thasbeen\t0.529\n",
      "\t\talready\t0.515\n",
      "\t\t've\t0.509\n",
      "\t\t\n",
      "Original Word:\tconvene\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['meet']\n",
      "Pred Answers:\tmeet\t1.0\n",
      "\t\tmeets\t0.686\n",
      "\t\tmet\t0.655\n",
      "\t\ttomeet\t0.579\n",
      "\t\tfulfill\t0.567\n",
      "\t\tsatisfy\t0.551\n",
      "\t\tmeeting\t0.517\n",
      "\t\tMeet\t0.506\n",
      "\t\ts_spinoff_Freescale\t0.502\n",
      "\t\tdiscuss\t0.497\n",
      "\t\t\n",
      "Original Word:\tdeem\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['believe', 'think']\n",
      "Pred Answers:\tbelieve\t1.0\n",
      "\t\tsay\t0.719\n",
      "\t\tthink\t0.663\n",
      "\t\targue\t0.638\n",
      "\t\tpresume\t0.628\n",
      "\t\tconvinced\t0.617\n",
      "\t\tbelieving\t0.597\n",
      "\t\tbeleive\t0.596\n",
      "\t\tbelive\t0.592\n",
      "\t\tsurmise\t0.591\n",
      "\t\t\n",
      "Original Word:\tdesignate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['choose', 'name']\n",
      "Pred Answers:\tchoose\t1.0\n",
      "\t\tchoosing\t0.732\n",
      "\t\tselect\t0.698\n",
      "\t\tchoice\t0.66\n",
      "\t\tdecide\t0.61\n",
      "\t\tChoosing\t0.604\n",
      "\t\tchooses\t0.603\n",
      "\t\tchose\t0.592\n",
      "\t\tChoose\t0.591\n",
      "\t\tchosen\t0.585\n",
      "\t\t\n",
      "Original Word:\tdesire\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['want', 'wish']\n",
      "Pred Answers:\twant\t1.0\n",
      "\t\tdo\t0.739\n",
      "\t\twanted\t0.7\n",
      "\t\tneed\t0.688\n",
      "\t\tcan\t0.667\n",
      "\t\twanting\t0.657\n",
      "\t\tprefer\t0.639\n",
      "\t\twanna\t0.636\n",
      "\t\twants\t0.636\n",
      "\t\twantto\t0.635\n",
      "\t\t\n",
      "Original Word:\tdisclose\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['show']\n",
      "Pred Answers:\tshow\t1.0\n",
      "\t\tshows\t0.719\n",
      "\t\tshowing\t0.574\n",
      "\t\tShow\t0.565\n",
      "\t\tshowed\t0.543\n",
      "\t\tshown\t0.497\n",
      "\t\tdemonstrate\t0.477\n",
      "\t\tShows\t0.468\n",
      "\t\tTHE_SINGING_BEE\t0.463\n",
      "\t\tPBS_Soundstage\t0.456\n",
      "\t\t\n",
      "Original Word:\tdiscontinue\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['drop', 'stop']\n",
      "Pred Answers:\tdrop\t1.0\n",
      "\t\tdecline\t0.687\n",
      "\t\tdrops\t0.673\n",
      "\t\tdropped\t0.646\n",
      "\t\tdropping\t0.638\n",
      "\t\trise\t0.626\n",
      "\t\tdip\t0.623\n",
      "\t\tplunge\t0.608\n",
      "\t\tplummet\t0.603\n",
      "\t\tspike\t0.598\n",
      "\t\t\n",
      "Original Word:\telect\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['chose', 'pick']\n",
      "Pred Answers:\tchose\t1.0\n",
      "\t\topted\t0.752\n",
      "\t\tchosen\t0.741\n",
      "\t\tdecided\t0.705\n",
      "\t\tchoosing\t0.681\n",
      "\t\tchooses\t0.607\n",
      "\t\tchoose\t0.592\n",
      "\t\twanted\t0.583\n",
      "\t\tselected\t0.557\n",
      "\t\tfelt_compelled\t0.548\n",
      "\t\t\n",
      "Original Word:\telucidate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['explain']\n",
      "Pred Answers:\texplain\t1.0\n",
      "\t\tunderstand\t0.704\n",
      "\t\texplaining\t0.691\n",
      "\t\tclarify\t0.633\n",
      "\t\telucidate\t0.632\n",
      "\t\tcomprehend\t0.611\n",
      "\t\tfathom\t0.591\n",
      "\t\tdescribe\t0.577\n",
      "\t\texplanation\t0.574\n",
      "\t\tdecipher\t0.567\n",
      "\t\t\n",
      "Original Word:\tencounter\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['meet']\n",
      "Pred Answers:\tmeet\t1.0\n",
      "\t\tmeets\t0.686\n",
      "\t\tmet\t0.655\n",
      "\t\ttomeet\t0.579\n",
      "\t\tfulfill\t0.567\n",
      "\t\tsatisfy\t0.551\n",
      "\t\tmeeting\t0.517\n",
      "\t\tMeet\t0.506\n",
      "\t\ts_spinoff_Freescale\t0.502\n",
      "\t\tdiscuss\t0.497\n",
      "\t\t\n",
      "Original Word:\tendeavor\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['try']\n",
      "Pred Answers:\ttry\t1.0\n",
      "\t\ttrying\t0.706\n",
      "\t\ttried\t0.665\n",
      "\t\ttries\t0.632\n",
      "\t\twant\t0.61\n",
      "\t\thoping\t0.585\n",
      "\t\tTrying\t0.584\n",
      "\t\tattempt\t0.582\n",
      "\t\tregroup_refocus\t0.579\n",
      "\t\tattempting\t0.56\n",
      "\t\t\n",
      "Original Word:\tentitlement\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['right']\n",
      "Pred Answers:\tright\t1.0\n",
      "\t\tRight\t0.57\n",
      "\t\twrong\t0.553\n",
      "\t\t##.Help_us\t0.55\n",
      "\t\tGoodwill_Catanese\t0.516\n",
      "\t\tleft\t0.492\n",
      "\t\tfielder_Joe_Borchard\t0.489\n",
      "\t\tNOTE_Xactly_Incent\t0.489\n",
      "\t\tfielder_Ambiorix_Concepcion\t0.484\n",
      "\t\tnow\t0.479\n",
      "\t\t\n",
      "Original Word:\tenumerate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['count']\n",
      "Pred Answers:\tcount\t1.0\n",
      "\t\tcounts\t0.689\n",
      "\t\tcounted\t0.594\n",
      "\t\tcounting\t0.533\n",
      "\t\ttally\t0.526\n",
      "\t\tself_effacement_literary\t0.512\n",
      "\t\tthrowing_hittable_pitches\t0.491\n",
      "\t\tAsdrubal_Cabrera_bunted\t0.479\n",
      "\t\tCount\t0.467\n",
      "\t\ttotals\t0.457\n",
      "\t\t\n",
      "Original Word:\texhibit\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['show']\n",
      "Pred Answers:\tshow\t1.0\n",
      "\t\tshows\t0.719\n",
      "\t\tshowing\t0.574\n",
      "\t\tShow\t0.565\n",
      "\t\tshowed\t0.543\n",
      "\t\tshown\t0.497\n",
      "\t\tdemonstrate\t0.477\n",
      "\t\tShows\t0.468\n",
      "\t\tTHE_SINGING_BEE\t0.463\n",
      "\t\tPBS_Soundstage\t0.456\n",
      "\t\t\n",
      "Original Word:\texpedite\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['hurry']\n",
      "Pred Answers:\thurry\t1.0\n",
      "\t\thurrying\t0.538\n",
      "\t\thaste\t0.517\n",
      "\t\trush\t0.515\n",
      "\t\timpatient\t0.5\n",
      "\t\thurried\t0.49\n",
      "\t\twait\t0.487\n",
      "\t\tpronto\t0.483\n",
      "\t\tready\t0.48\n",
      "\t\tHurry\t0.478\n",
      "\t\t\n",
      "Original Word:\texpend\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['spend']\n",
      "Pred Answers:\tspend\t1.0\n",
      "\t\tspent\t0.751\n",
      "\t\tspends\t0.707\n",
      "\t\tSpend\t0.685\n",
      "\t\tdevote\t0.638\n",
      "\t\tspending\t0.61\n",
      "\t\texpend\t0.566\n",
      "\t\tdevoting\t0.525\n",
      "\t\tsplurge\t0.524\n",
      "\t\tinvest\t0.522\n",
      "\t\t\n",
      "Original Word:\texpiration\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['end']\n",
      "Pred Answers:\tend\t1.0\n",
      "\t\tending\t0.646\n",
      "\t\tends\t0.591\n",
      "\t\tbeginning\t0.53\n",
      "\t\tended\t0.515\n",
      "\t\ttheend\t0.472\n",
      "\t\tendof\t0.441\n",
      "\t\tmidpoint\t0.439\n",
      "\t\tstart\t0.438\n",
      "\t\tprolong\t0.416\n",
      "\t\t\n",
      "Original Word:\tfacilitate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['ease', 'help']\n",
      "Pred Answers:\tease\t1.0\n",
      "\t\talleviate\t0.658\n",
      "\t\teasing\t0.627\n",
      "\t\trelieve\t0.62\n",
      "\t\teases\t0.598\n",
      "\t\tEasing\t0.591\n",
      "\t\teased\t0.579\n",
      "\t\tEase\t0.561\n",
      "\t\tlessen\t0.554\n",
      "\t\talleviating\t0.552\n",
      "\t\t\n",
      "Original Word:\tfinalize\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['complete', 'finish']\n",
      "Pred Answers:\tcomplete\t1.0\n",
      "\t\tcompleted\t0.629\n",
      "\t\tcompleting\t0.589\n",
      "\t\tcompletes\t0.553\n",
      "\t\tComplete\t0.527\n",
      "\t\tfull\t0.5\n",
      "\t\tCompleting\t0.474\n",
      "\t\tcompletion\t0.454\n",
      "\t\tSuccessfully_completing\t0.446\n",
      "\t\tdetailed\t0.434\n",
      "\t\t\n",
      "Original Word:\tforfeit\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['lose', 'give up']\n",
      "Pred Answers:\tlose\t1.0\n",
      "\t\tlosing\t0.746\n",
      "\t\tlost\t0.714\n",
      "\t\tloses\t0.669\n",
      "\t\tloosing\t0.629\n",
      "\t\tLosing\t0.591\n",
      "\t\tsquander\t0.521\n",
      "\t\tregain\t0.52\n",
      "\t\tlooses\t0.519\n",
      "\t\tLose\t0.509\n",
      "\t\t\n",
      "Original Word:\tinception\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['start']\n",
      "Pred Answers:\tstart\t1.0\n",
      "\t\tbegin\t0.685\n",
      "\t\tstarted\t0.631\n",
      "\t\tstarting\t0.614\n",
      "\t\tstarts\t0.599\n",
      "\t\tbeginning\t0.546\n",
      "\t\tStart\t0.532\n",
      "\t\tfinish\t0.493\n",
      "\t\tbegan\t0.489\n",
      "\t\tcommence\t0.475\n",
      "\t\t\n",
      "Original Word:\tinitiate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['start']\n",
      "Pred Answers:\tstart\t1.0\n",
      "\t\tbegin\t0.685\n",
      "\t\tstarted\t0.631\n",
      "\t\tstarting\t0.614\n",
      "\t\tstarts\t0.599\n",
      "\t\tbeginning\t0.546\n",
      "\t\tStart\t0.532\n",
      "\t\tfinish\t0.493\n",
      "\t\tbegan\t0.489\n",
      "\t\tcommence\t0.475\n",
      "\t\t\n",
      "Original Word:\tliaison\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['discussion']\n",
      "Pred Answers:\tdiscussion\t1.0\n",
      "\t\tdiscussions\t0.748\n",
      "\t\tdebate\t0.701\n",
      "\t\tdicussion\t0.688\n",
      "\t\tDiscussion\t0.687\n",
      "\t\tconversation\t0.675\n",
      "\t\tdiscusssion\t0.63\n",
      "\t\tfrank_discussion\t0.628\n",
      "\t\theated_debate\t0.597\n",
      "\t\tdebates\t0.591\n",
      "\t\t\n",
      "Original Word:\tmagnitude\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['size']\n",
      "Pred Answers:\tsize\t1.0\n",
      "\t\tsized\t0.679\n",
      "\t\tSize\t0.622\n",
      "\t\tsizes\t0.612\n",
      "\t\t4_chars\t0.537\n",
      "\t\tHanny_Voorwerp_Keel\t0.537\n",
      "\t\theight\t0.529\n",
      "\t\twidth\t0.518\n",
      "\t\tlarger\t0.507\n",
      "\t\tsmall\t0.496\n",
      "\t\t\n",
      "Original Word:\tnecessitate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['cause', 'need']\n",
      "Pred Answers:\tcause\t1.0\n",
      "\t\tcauses\t0.784\n",
      "\t\tcaused\t0.662\n",
      "\t\tcausing\t0.638\n",
      "\t\tcontributing_factor\t0.552\n",
      "\t\tCause\t0.528\n",
      "\t\tcasued\t0.51\n",
      "\t\tCausing\t0.501\n",
      "\t\tcasue\t0.483\n",
      "\t\tculprit\t0.483\n",
      "\t\t\n",
      "Original Word:\tobjective\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['aim', 'goal']\n",
      "Pred Answers:\taim\t1.0\n",
      "\t\taiming\t0.727\n",
      "\t\tobjective\t0.717\n",
      "\t\taims\t0.68\n",
      "\t\taimed\t0.546\n",
      "\t\tintention\t0.526\n",
      "\t\tstriving\t0.514\n",
      "\t\toverriding_objective\t0.506\n",
      "\t\tavowed_aim\t0.505\n",
      "\t\tintended\t0.493\n",
      "\t\t\n",
      "Original Word:\tobtain\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['get']\n",
      "Pred Answers:\tget\t1.0\n",
      "\t\tgetting\t0.751\n",
      "\t\tgot\t0.724\n",
      "\t\tgets\t0.643\n",
      "\t\tgotten\t0.626\n",
      "\t\tGetting\t0.621\n",
      "\t\tgo\t0.59\n",
      "\t\tcome\t0.582\n",
      "\t\tgive\t0.58\n",
      "\t\tbring\t0.553\n",
      "\t\t\n",
      "Original Word:\torientate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['orient']\n",
      "Pred Answers:\torient\t1.0\n",
      "\t\torientate\t0.722\n",
      "\t\torienting\t0.691\n",
      "\t\tre_orient\t0.619\n",
      "\t\treorient\t0.61\n",
      "\t\torient_themselves\t0.61\n",
      "\t\torientate_themselves\t0.571\n",
      "\t\torients\t0.56\n",
      "\t\torientating\t0.535\n",
      "\t\tfamiliarize\t0.535\n",
      "\t\t\n",
      "Original Word:\tperform\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['do']\n",
      "Pred Answers:\tdo\t1.0\n",
      "\t\twant\t0.739\n",
      "\t\tknow\t0.724\n",
      "\t\tnot\t0.713\n",
      "\t\tspokeswoman_Ewa_Malmborg\t0.671\n",
      "\t\tdid\t0.656\n",
      "\t\tanymore\t0.651\n",
      "\t\tthink\t0.65\n",
      "\t\tdoes\t0.65\n",
      "\t\tJulian_Radbourne_editorial\t0.649\n",
      "\t\t\n",
      "Original Word:\tpermit\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['let']\n",
      "Pred Answers:\tlet\t1.0\n",
      "\t\tletting\t0.728\n",
      "\t\tLet\t0.65\n",
      "\t\tdo\t0.601\n",
      "\t\twant\t0.591\n",
      "\t\tlets\t0.581\n",
      "\t\tE_mail_heyjen@phillynews.com\t0.577\n",
      "\t\tallow\t0.557\n",
      "\t\ttry\t0.554\n",
      "\t\tdare\t0.551\n",
      "\t\t\n",
      "Original Word:\tperspire\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['sweat']\n",
      "Pred Answers:\tsweat\t1.0\n",
      "\t\tperspiration\t0.642\n",
      "\t\tMud_resin\t0.633\n",
      "\t\tsweating\t0.603\n",
      "\t\tsweated\t0.597\n",
      "\t\tsweaty\t0.552\n",
      "\t\tsweat_dripping\t0.546\n",
      "\t\tSweat\t0.515\n",
      "\t\tperspire\t0.505\n",
      "\t\tsweats\t0.5\n",
      "\t\t\n",
      "Original Word:\tperuse\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['read']\n",
      "Pred Answers:\tread\t1.0\n",
      "\t\treading\t0.699\n",
      "\t\treread\t0.691\n",
      "\t\treads\t0.663\n",
      "\t\twrite\t0.631\n",
      "\t\tReread\t0.612\n",
      "\t\thandwrite\t0.582\n",
      "\t\twritten\t0.581\n",
      "\t\tread_aloud\t0.579\n",
      "\t\thttp://www.jpost.com_servlet_Satellite\t0.559\n",
      "\t\t\n",
      "Original Word:\tportray\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['show']\n",
      "Pred Answers:\tshow\t1.0\n",
      "\t\tshows\t0.719\n",
      "\t\tshowing\t0.574\n",
      "\t\tShow\t0.565\n",
      "\t\tshowed\t0.543\n",
      "\t\tshown\t0.497\n",
      "\t\tdemonstrate\t0.477\n",
      "\t\tShows\t0.468\n",
      "\t\tTHE_SINGING_BEE\t0.463\n",
      "\t\tPBS_Soundstage\t0.456\n",
      "\t\t\n",
      "Original Word:\tpossess\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['have', 'own']\n",
      "Pred Answers:\thave\t1.0\n",
      "\t\t've\t0.677\n",
      "\t\thad\t0.66\n",
      "\t\thaven_t\t0.586\n",
      "\t\talready\t0.581\n",
      "\t\tbeen\t0.561\n",
      "\t\thas\t0.559\n",
      "\t\thavenâ_€_™\t0.557\n",
      "\t\tthey\t0.551\n",
      "\t\tHave\t0.549\n",
      "\t\t\n",
      "Original Word:\tpreclude\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['prevent']\n",
      "Pred Answers:\tprevent\t1.0\n",
      "\t\tpreventing\t0.789\n",
      "\t\tprevented\t0.702\n",
      "\t\tdeter\t0.698\n",
      "\t\tavoid\t0.684\n",
      "\t\tdiscourage\t0.675\n",
      "\t\tforestall\t0.671\n",
      "\t\tprevents\t0.646\n",
      "\t\tavert\t0.644\n",
      "\t\tPrevent\t0.619\n",
      "\t\t\n",
      "Original Word:\tprioritize\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['rank']\n",
      "Pred Answers:\trank\t1.0\n",
      "\t\tranks\t0.671\n",
      "\t\tranking\t0.627\n",
      "\t\tRank\t0.509\n",
      "\t\tranked\t0.503\n",
      "\t\techelon\t0.49\n",
      "\t\tRanking\t0.48\n",
      "\t\tRanks\t0.472\n",
      "\t\tranker\t0.467\n",
      "\t\toutranked\t0.455\n",
      "\t\t\n",
      "Original Word:\tproficiency\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['skill']\n",
      "Pred Answers:\tskill\t1.0\n",
      "\t\tskills\t0.77\n",
      "\t\tabilities\t0.656\n",
      "\t\taptitude\t0.628\n",
      "\t\tskils\t0.61\n",
      "\t\tskillset\t0.595\n",
      "\t\tSkill\t0.594\n",
      "\t\tskilled\t0.587\n",
      "\t\tquickness_explosiveness\t0.582\n",
      "\t\tfinesse\t0.582\n",
      "\t\t\n",
      "Original Word:\tpromulgate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['issue', 'publish']\n",
      "Pred Answers:\tissue\t1.0\n",
      "\t\tissues\t0.707\n",
      "\t\tthorny_issue\t0.598\n",
      "\t\tproblem\t0.565\n",
      "\t\tisssue\t0.562\n",
      "\t\ttopic\t0.553\n",
      "\t\tIssues\t0.537\n",
      "\t\ttouchy_subject\t0.514\n",
      "\t\tmatter\t0.511\n",
      "\t\tmatters\t0.496\n",
      "\t\t\n",
      "Original Word:\tpurchase\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['buy']\n",
      "Pred Answers:\tbuy\t1.0\n",
      "\t\tsell\t0.831\n",
      "\t\tpurchase\t0.764\n",
      "\t\tbuying\t0.721\n",
      "\t\tbought\t0.709\n",
      "\t\tbuys\t0.662\n",
      "\t\tBuy\t0.585\n",
      "\t\ttobuy\t0.584\n",
      "\t\tpurchased\t0.583\n",
      "\t\tBuying\t0.578\n",
      "\t\t\n",
      "Original Word:\treflect\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['say', 'show']\n",
      "Pred Answers:\tsay\t1.0\n",
      "\t\tbelieve\t0.719\n",
      "\t\targue\t0.67\n",
      "\t\tknow\t0.641\n",
      "\t\ttell\t0.616\n",
      "\t\tinsist\t0.609\n",
      "\t\tthink\t0.595\n",
      "\t\tspeculate\t0.563\n",
      "\t\tpresume\t0.56\n",
      "\t\tsuggest\t0.549\n",
      "\t\t\n",
      "Original Word:\trelease\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['free']\n",
      "Pred Answers:\tfree\t1.0\n",
      "\t\tFree\t0.672\n",
      "\t\tSix_Flags_website_http://www.sixflags.com\t0.526\n",
      "\t\tFREE\t0.508\n",
      "\t\tnominal_fee\t0.457\n",
      "\t\ttherapy_systems_NFITS\t0.453\n",
      "\t\trestricted\t0.449\n",
      "\t\tcomplimentary\t0.448\n",
      "\t\tafree\t0.441\n",
      "\t\twww.dickmorris.com\t0.433\n",
      "\t\t\n",
      "Original Word:\trelocate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['move']\n",
      "Pred Answers:\tmove\t1.0\n",
      "\t\tmoves\t0.702\n",
      "\t\tmoving\t0.621\n",
      "\t\tpush\t0.573\n",
      "\t\tmoved\t0.543\n",
      "\t\tstep\t0.519\n",
      "\t\tMoving\t0.514\n",
      "\t\trelocate\t0.506\n",
      "\t\tgo\t0.495\n",
      "\t\tswitch\t0.48\n",
      "\t\t\n",
      "Original Word:\tremain\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['stay']\n",
      "Pred Answers:\tstay\t1.0\n",
      "\t\tstaying\t0.752\n",
      "\t\tstayed\t0.697\n",
      "\t\tstays\t0.695\n",
      "\t\tkeep\t0.676\n",
      "\t\tremain\t0.656\n",
      "\t\tStaying\t0.63\n",
      "\t\tStay\t0.596\n",
      "\t\tleave\t0.579\n",
      "\t\tgo\t0.529\n",
      "\t\t\n",
      "Original Word:\tremainder\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['rest']\n",
      "Pred Answers:\trest\t1.0\n",
      "\t\tremainder\t0.588\n",
      "\t\tentire\t0.562\n",
      "\t\twhole\t0.542\n",
      "\t\tGoeres_sued\t0.446\n",
      "\t\talerts_BEFORE\t0.445\n",
      "\t\trecuperate\t0.43\n",
      "\t\tCrikey_Army\t0.426\n",
      "\t\tthe\t0.42\n",
      "\t\tjust\t0.412\n",
      "\t\t\n",
      "Original Word:\tremuneration\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['pay', 'payment']\n",
      "Pred Answers:\tpay\t1.0\n",
      "\t\tpaying\t0.752\n",
      "\t\tpaid\t0.739\n",
      "\t\tpays\t0.67\n",
      "\t\ttopay\t0.615\n",
      "\t\treimburse\t0.605\n",
      "\t\tPaying\t0.573\n",
      "\t\tpayed\t0.567\n",
      "\t\tpayment\t0.552\n",
      "\t\trepay\t0.55\n",
      "\t\t\n",
      "Original Word:\trender\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['give', 'make']\n",
      "Pred Answers:\tgive\t1.0\n",
      "\t\tgiving\t0.746\n",
      "\t\tgave\t0.741\n",
      "\t\tGive\t0.683\n",
      "\t\tgives\t0.67\n",
      "\t\tprovide\t0.656\n",
      "\t\tgiven\t0.646\n",
      "\t\tGiving\t0.597\n",
      "\t\ttake\t0.591\n",
      "\t\tget\t0.58\n",
      "\t\t\n",
      "Original Word:\tstrategize\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['plan']\n",
      "Pred Answers:\tplan\t1.0\n",
      "\t\tplans\t0.724\n",
      "\t\tproposal\t0.713\n",
      "\t\tPlan\t0.608\n",
      "\t\tblueprint\t0.599\n",
      "\t\tstrategy\t0.589\n",
      "\t\tproposals\t0.57\n",
      "\t\tplanned\t0.537\n",
      "\t\tproposed\t0.535\n",
      "\t\tplanning\t0.522\n",
      "\t\t\n",
      "Original Word:\tterminate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['end', 'stop']\n",
      "Pred Answers:\tend\t1.0\n",
      "\t\tending\t0.646\n",
      "\t\tends\t0.591\n",
      "\t\tbeginning\t0.53\n",
      "\t\tended\t0.515\n",
      "\t\ttheend\t0.472\n",
      "\t\tendof\t0.441\n",
      "\t\tmidpoint\t0.439\n",
      "\t\tstart\t0.438\n",
      "\t\tprolong\t0.416\n",
      "\t\t\n",
      "Original Word:\tundermine\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['block']\n",
      "Pred Answers:\tblock\t1.0\n",
      "\t\tblocks\t0.543\n",
      "\t\tExume_tried\t0.54\n",
      "\t\tKedvale_Avenue\t0.527\n",
      "\t\tTerroristic_threat\t0.527\n",
      "\t\tHoyne_Avenue\t0.525\n",
      "\t\tGoguac_Street\t0.524\n",
      "\t\tBriarwood_Drive\t0.521\n",
      "\t\tBoxwood_Drive\t0.52\n",
      "\t\tAvers_Avenue\t0.516\n",
      "\t\t\n",
      "Original Word:\tutilization\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['use']\n",
      "Pred Answers:\tuse\t1.0\n",
      "\t\tusing\t0.727\n",
      "\t\tutilize\t0.651\n",
      "\t\tused\t0.636\n",
      "\t\tuses\t0.613\n",
      "\t\tUse\t0.577\n",
      "\t\tusage\t0.573\n",
      "\t\tUsing\t0.548\n",
      "\t\tUtilize\t0.512\n",
      "\t\tutilizing\t0.51\n",
      "\t\t\n",
      "Original Word:\tutilize\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['use']\n",
      "Pred Answers:\tuse\t1.0\n",
      "\t\tusing\t0.727\n",
      "\t\tutilize\t0.651\n",
      "\t\tused\t0.636\n",
      "\t\tuses\t0.613\n",
      "\t\tUse\t0.577\n",
      "\t\tusage\t0.573\n",
      "\t\tUsing\t0.548\n",
      "\t\tUtilize\t0.512\n",
      "\t\tutilizing\t0.51\n",
      "\t\t\n",
      "Original Word:\tabundance\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['enough', 'plenty']\n",
      "Pred Answers:\tenough\t1.0\n",
      "\t\tsufficient\t0.604\n",
      "\t\tenought\t0.602\n",
      "\t\ttoo\t0.587\n",
      "\t\tsufficiently\t0.572\n",
      "\t\tnot\t0.566\n",
      "\t\table\t0.544\n",
      "\t\tso\t0.542\n",
      "\t\tneeded\t0.529\n",
      "\t\tcould\t0.5\n",
      "\t\t\n",
      "Original Word:\taccordingly\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['thus', 'so']\n",
      "Pred Answers:\tthus\t1.0\n",
      "\t\tthereby\t0.772\n",
      "\t\tconsequently\t0.646\n",
      "\t\tThereby\t0.628\n",
      "\t\tThus\t0.586\n",
      "\t\thence\t0.575\n",
      "\t\ttherefore\t0.562\n",
      "\t\ttherby\t0.517\n",
      "\t\tconsequentially\t0.509\n",
      "\t\tmoreover\t0.506\n",
      "\t\t\n",
      "Original Word:\tadmissible\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['allowed', 'accepted']\n",
      "Pred Answers:\tallowed\t1.0\n",
      "\t\tpermitted\t0.762\n",
      "\t\tallowing\t0.718\n",
      "\t\tallow\t0.642\n",
      "\t\table\t0.56\n",
      "\t\tAllowing\t0.534\n",
      "\t\tforced\t0.513\n",
      "\t\tAllowed\t0.501\n",
      "\t\tlet\t0.491\n",
      "\t\tenabled\t0.488\n",
      "\t\t\n",
      "Original Word:\talternatively\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['or']\n",
      "Pred Answers:\tor\t1.0\n",
      "\t\teither\t0.682\n",
      "\t\tany\t0.59\n",
      "\t\tOr\t0.565\n",
      "\t\te_mail_palitem@richmond.gannett.com\t0.552\n",
      "\t\teg\t0.526\n",
      "\t\ttpnews@tracypress.com\t0.525\n",
      "\t\theaven_forbid\t0.512\n",
      "\t\tkcates@greatfallstribune.com\t0.504\n",
      "\t\totherwise\t0.496\n",
      "\t\t\n",
      "Original Word:\tapparent\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['clear', 'plain']\n",
      "Pred Answers:\tclear\t1.0\n",
      "\t\tcrystal_clear\t0.62\n",
      "\t\tclearer\t0.602\n",
      "\t\tabundantly_clear\t0.587\n",
      "\t\tobvious\t0.576\n",
      "\t\tclearest\t0.518\n",
      "\t\tunambiguous\t0.518\n",
      "\t\tunclear\t0.51\n",
      "\t\tsure\t0.498\n",
      "\t\tevident\t0.489\n",
      "\t\t\n",
      "Original Word:\tappreciable\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['many']\n",
      "Pred Answers:\tmany\t1.0\n",
      "\t\tseveral\t0.674\n",
      "\t\tnumerous\t0.657\n",
      "\t\tsome\t0.653\n",
      "\t\tcountless\t0.642\n",
      "\t\tdozens\t0.633\n",
      "\t\tfew\t0.605\n",
      "\t\tmultitude\t0.602\n",
      "\t\thandful\t0.6\n",
      "\t\tmyriad\t0.598\n",
      "\t\t\n",
      "Original Word:\tbelated\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['late']\n",
      "Pred Answers:\tlate\t1.0\n",
      "\t\tearly\t0.812\n",
      "\t\tmid\t0.625\n",
      "\t\tLate\t0.614\n",
      "\t\tAfter_inventing_microarray\t0.491\n",
      "\t\tprimetime_daytime\t0.466\n",
      "\t\tCMEA_invests\t0.454\n",
      "\t\tEarly\t0.453\n",
      "\t\tsometime\t0.445\n",
      "\t\tafter\t0.444\n",
      "\t\t\n",
      "Original Word:\tbestow\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['give', 'award']\n",
      "Pred Answers:\tgive\t1.0\n",
      "\t\tgiving\t0.746\n",
      "\t\tgave\t0.741\n",
      "\t\tGive\t0.683\n",
      "\t\tgives\t0.67\n",
      "\t\tprovide\t0.656\n",
      "\t\tgiven\t0.646\n",
      "\t\tGiving\t0.597\n",
      "\t\ttake\t0.591\n",
      "\t\tget\t0.58\n",
      "\t\t\n",
      "Original Word:\tcaveat\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['warning']\n",
      "Pred Answers:\twarning\t1.0\n",
      "\t\twarnings\t0.818\n",
      "\t\tWarnings\t0.673\n",
      "\t\twarn\t0.666\n",
      "\t\tWarning\t0.664\n",
      "\t\tstern_warning\t0.61\n",
      "\t\talert\t0.595\n",
      "\t\talerting\t0.566\n",
      "\t\twarned\t0.564\n",
      "\t\tstark_warning\t0.558\n",
      "\t\t\n",
      "Original Word:\tcogitate\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['think']\n",
      "Pred Answers:\tthink\t1.0\n",
      "\t\tknow\t0.734\n",
      "\t\tguess\t0.72\n",
      "\t\tsuppose\t0.716\n",
      "\t\treally\t0.707\n",
      "\t\tthought\t0.687\n",
      "\t\tobviously\t0.673\n",
      "\t\tmaybe\t0.669\n",
      "\t\tprobably\t0.668\n",
      "\t\tbelieve\t0.663\n",
      "\t\t\n",
      "Original Word:\tcomestibles\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['food']\n",
      "Pred Answers:\tfood\t1.0\n",
      "\t\tfoods\t0.68\n",
      "\t\tFood\t0.654\n",
      "\t\tfoodstuffs\t0.643\n",
      "\t\tmeals\t0.617\n",
      "\t\tfood_stuffs\t0.593\n",
      "\t\tnourishing_meals\t0.585\n",
      "\t\tfoodstuff\t0.584\n",
      "\t\tstaple_foods\t0.554\n",
      "\t\tnutritious\t0.547\n",
      "\t\t\n",
      "Original Word:\tdefinitely\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['really', 'very']\n",
      "Pred Answers:\treally\t1.0\n",
      "\t\tobviously\t0.745\n",
      "\t\tdefinitely\t0.739\n",
      "\t\tthink\t0.707\n",
      "\t\tpretty\t0.696\n",
      "\t\tReally\t0.694\n",
      "\t\tkinda\t0.678\n",
      "\t\tjust\t0.675\n",
      "\t\tkind\t0.67\n",
      "\t\teverybody\t0.664\n",
      "\t\t\n",
      "Original Word:\temoluments\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['fee', 'salary']\n",
      "Pred Answers:\tfee\t1.0\n",
      "\t\tfees\t0.84\n",
      "\t\tFees\t0.68\n",
      "\t\tFee\t0.659\n",
      "\t\tnominal_fee\t0.609\n",
      "\t\tsurcharge\t0.605\n",
      "\t\tnonrefundable_fee\t0.546\n",
      "\t\tminimums_FDIC_insured\t0.517\n",
      "\t\tYearly_membership\t0.515\n",
      "\t\tdockage_fees\t0.51\n",
      "\t\t\n",
      "Original Word:\tequitable\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['fair']\n",
      "Pred Answers:\tfair\t1.0\n",
      "\t\tFair\t0.554\n",
      "\t\tKurylowicz_trial\t0.554\n",
      "\t\tP###_INX_futures\t0.535\n",
      "\t\tequitable\t0.53\n",
      "\t\tRanee_Gaynor\t0.526\n",
      "\t\tMATAGORDA_Trout\t0.512\n",
      "\t\tspokeswoman_Brienna_Schuette\t0.508\n",
      "\t\tfairness\t0.502\n",
      "\t\treasonable\t0.501\n",
      "\t\t\n",
      "Original Word:\tequivalent\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['equal']\n",
      "Pred Answers:\tequal\t1.0\n",
      "\t\tEqual\t0.597\n",
      "\t\tequals\t0.575\n",
      "\t\tunequal\t0.542\n",
      "\t\tequality\t0.534\n",
      "\t\topportunity_insulter\t0.502\n",
      "\t\tproportional\t0.494\n",
      "\t\tRookie_Roddy_Beaubois\t0.491\n",
      "\t\ttransaminase_elevations_greater\t0.491\n",
      "\t\tDiversity_Pledged_Recruiter\t0.471\n",
      "\t\t\n",
      "Original Word:\tevidenced\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['showed']\n",
      "Pred Answers:\tshowed\t1.0\n",
      "\t\tshowing\t0.754\n",
      "\t\tshown\t0.681\n",
      "\t\tshows\t0.641\n",
      "\t\tShowing\t0.566\n",
      "\t\trevealed\t0.558\n",
      "\t\tindicated\t0.549\n",
      "\t\tindicates\t0.546\n",
      "\t\tshow\t0.543\n",
      "\t\tsaw\t0.541\n",
      "\t\t\n",
      "Original Word:\texcluding\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['except']\n",
      "Pred Answers:\texcept\t1.0\n",
      "\t\tExcept\t0.644\n",
      "\t\texcepting\t0.58\n",
      "\t\tMinagawa_outlived\t0.526\n",
      "\t\tvirtually\t0.524\n",
      "\t\tVirtually\t0.514\n",
      "\t\tINCOME_STATEMENT_DATA_Dollars\t0.51\n",
      "\t\tpractically\t0.504\n",
      "\t\telse\t0.492\n",
      "\t\tfew_scrapes_Kyson\t0.489\n",
      "\t\t\n",
      "Original Word:\texpeditious\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['fast', 'quick']\n",
      "Pred Answers:\tfast\t1.0\n",
      "\t\tquick\t0.57\n",
      "\t\trapidly\t0.553\n",
      "\t\tFast\t0.549\n",
      "\t\tquickly\t0.539\n",
      "\t\tslow\t0.531\n",
      "\t\tfaster\t0.522\n",
      "\t\tbreakneck_speed\t0.487\n",
      "\t\tTSFG_focuses\t0.481\n",
      "\t\trapid\t0.477\n",
      "\t\t\n",
      "Original Word:\tidentical\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['same']\n",
      "Pred Answers:\tsame\t1.0\n",
      "\t\tSame\t0.58\n",
      "\t\tsimilar\t0.517\n",
      "\t\tdifferent\t0.506\n",
      "\t\tcomparable\t0.494\n",
      "\t\tidentical\t0.478\n",
      "\t\texact\t0.457\n",
      "\t\tvirtually_identical\t0.449\n",
      "\t\tsimiliar\t0.443\n",
      "\t\tcompared\t0.438\n",
      "\t\t\n",
      "Original Word:\timpacted\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['affected', 'changed']\n",
      "Pred Answers:\taffected\t1.0\n",
      "\t\timpacted\t0.813\n",
      "\t\tadversely_affected\t0.719\n",
      "\t\taffecting\t0.667\n",
      "\t\tseverely_impacted\t0.66\n",
      "\t\taffect\t0.659\n",
      "\t\teffected\t0.656\n",
      "\t\tnegatively_affected\t0.635\n",
      "\t\tunaffected\t0.614\n",
      "\t\taffects\t0.606\n",
      "\t\t\n",
      "Original Word:\tmaximum\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['greatest', 'largest', 'most']\n",
      "Pred Answers:\tgreatest\t1.0\n",
      "\t\tbiggest\t0.719\n",
      "\t\tfinest\t0.615\n",
      "\t\tbest\t0.582\n",
      "\t\tstrongest\t0.565\n",
      "\t\tgreat\t0.564\n",
      "\t\thugest\t0.553\n",
      "\t\tproudest\t0.538\n",
      "\t\tworst\t0.526\n",
      "\t\tultimate\t0.517\n",
      "\t\t\n",
      "Original Word:\tminimum\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['least', 'smallest']\n",
      "Pred Answers:\tleast\t1.0\n",
      "\t\tPiedra_Blanca_emergency\t0.476\n",
      "\t\tone\t0.451\n",
      "\t\tonly\t0.448\n",
      "\t\tleas\t0.444\n",
      "\t\tnearly\t0.44\n",
      "\t\tminimum\t0.43\n",
      "\t\troughly\t0.43\n",
      "\t\tfive\t0.419\n",
      "\t\tleat\t0.418\n",
      "\t\t\n",
      "Original Word:\tmoreover\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['also']\n",
      "Pred Answers:\talso\t1.0\n",
      "\t\tadditionally\t0.613\n",
      "\t\tmeanwhile\t0.562\n",
      "\t\thowever\t0.547\n",
      "\t\talready\t0.521\n",
      "\t\tthat\t0.518\n",
      "\t\tinitially\t0.509\n",
      "\t\tlikewise\t0.5\n",
      "\t\tpreviously\t0.499\n",
      "\t\tadded\t0.471\n",
      "\t\t\n",
      "Original Word:\tmultiple\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['many']\n",
      "Pred Answers:\tmany\t1.0\n",
      "\t\tseveral\t0.674\n",
      "\t\tnumerous\t0.657\n",
      "\t\tsome\t0.653\n",
      "\t\tcountless\t0.642\n",
      "\t\tdozens\t0.633\n",
      "\t\tfew\t0.605\n",
      "\t\tmultitude\t0.602\n",
      "\t\thandful\t0.6\n",
      "\t\tmyriad\t0.598\n",
      "\t\t\n",
      "Original Word:\tnumerous\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['many']\n",
      "Pred Answers:\tmany\t1.0\n",
      "\t\tseveral\t0.674\n",
      "\t\tnumerous\t0.657\n",
      "\t\tsome\t0.653\n",
      "\t\tcountless\t0.642\n",
      "\t\tdozens\t0.633\n",
      "\t\tfew\t0.605\n",
      "\t\tmultitude\t0.602\n",
      "\t\thandful\t0.6\n",
      "\t\tmyriad\t0.598\n",
      "\t\t\n",
      "Original Word:\toptimum\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['best', 'greatest', 'most']\n",
      "Pred Answers:\tbest\t1.0\n",
      "\t\tfinest\t0.638\n",
      "\t\tworst\t0.584\n",
      "\t\tgreatest\t0.582\n",
      "\t\tstrongest\t0.579\n",
      "\t\tsmartest\t0.57\n",
      "\t\teasiest\t0.553\n",
      "\t\tgood\t0.547\n",
      "\t\tthebest\t0.543\n",
      "\t\tquickest\t0.54\n",
      "\t\t\n",
      "Original Word:\tparticulars\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['details']\n",
      "Pred Answers:\tdetails\t1.0\n",
      "\t\tspecifics\t0.73\n",
      "\t\tDetails\t0.722\n",
      "\t\tparticulars\t0.687\n",
      "\t\tSCE.Q_SCE.Q\t0.615\n",
      "\t\tdetail\t0.614\n",
      "\t\tinformation\t0.606\n",
      "\t\tNWS.A_NWS.A._NWS.A\t0.593\n",
      "\t\tdeatils\t0.592\n",
      "\t\tcompensations_visit_http://www.xplosivestocks.com/Disclaimer.html\t0.592\n",
      "\t\t\n",
      "Original Word:\tpenurious\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['poor']\n",
      "Pred Answers:\tpoor\t1.0\n",
      "\t\tpoorer\t0.646\n",
      "\t\tabysmal\t0.598\n",
      "\t\tpoorest\t0.595\n",
      "\t\tlousy\t0.566\n",
      "\t\twoeful\t0.56\n",
      "\t\tstudent_Abu_Fatmah\t0.559\n",
      "\t\tpitiful\t0.545\n",
      "\t\tbad\t0.535\n",
      "\t\twretched\t0.533\n",
      "\t\t\n",
      "Original Word:\tperchance\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['perhaps']\n",
      "Pred Answers:\tperhaps\t1.0\n",
      "\t\tPossibly\t0.649\n",
      "\t\tpossibly\t0.64\n",
      "\t\tPerhaps\t0.638\n",
      "\t\tmaybe\t0.633\n",
      "\t\tmight\t0.621\n",
      "\t\tprobably\t0.617\n",
      "\t\targuably\t0.615\n",
      "\t\tsurely\t0.615\n",
      "\t\teven\t0.593\n",
      "\t\t\n",
      "Original Word:\tpracticable\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['practical']\n",
      "Pred Answers:\tpractical\t1.0\n",
      "\t\tPractical\t0.66\n",
      "\t\tbeaded_sweaters_replaced\t0.594\n",
      "\t\tscientist_Alice_Lichtenstein\t0.563\n",
      "\t\tjoke_Skrenta\t0.538\n",
      "\t\teminently_practical\t0.533\n",
      "\t\tpracticality\t0.516\n",
      "\t\tbeaded_sweaters\t0.511\n",
      "\t\tsimple\t0.509\n",
      "\t\ttheoretical\t0.506\n",
      "\t\t\n",
      "Original Word:\tpreowned\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['used']\n",
      "Pred Answers:\tused\t1.0\n",
      "\t\tutilized\t0.685\n",
      "\t\tusing\t0.666\n",
      "\t\tuse\t0.636\n",
      "\t\tuses\t0.618\n",
      "\t\tintended\t0.535\n",
      "\t\tUsed\t0.507\n",
      "\t\tUsing\t0.501\n",
      "\t\tmisused\t0.494\n",
      "\t\tdesigned\t0.492\n",
      "\t\t\n",
      "Original Word:\tregarding\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['about', 'of', 'on']\n",
      "Pred Answers:\tabout\t1.0\n",
      "\t\tabut\t0.657\n",
      "\t\taboutthe\t0.564\n",
      "\t\taboout\t0.48\n",
      "\t\tjust\t0.469\n",
      "\t\tregarding\t0.464\n",
      "\t\tmore\t0.462\n",
      "\t\tabou\t0.458\n",
      "\t\tconcerning\t0.444\n",
      "\t\taround\t0.439\n",
      "\t\t\n",
      "Original Word:\tregardless\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['regardless']\n",
      "Pred Answers:\tregardless\t1.0\n",
      "\t\tirrespective\t0.805\n",
      "\t\tRegardless\t0.654\n",
      "\t\tIrrespective\t0.613\n",
      "\t\tirregardless\t0.606\n",
      "\t\twhatever\t0.591\n",
      "\t\tdepending\t0.582\n",
      "\t\tdetermines\t0.569\n",
      "\t\tvary_depending\t0.531\n",
      "\t\tDepending\t0.524\n",
      "\t\t\n",
      "Original Word:\tsubsequent\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['later', 'next', 'after', 'then']\n",
      "Pred Answers:\tlater\t1.0\n",
      "\t\tafter\t0.64\n",
      "\t\tbefore\t0.611\n",
      "\t\tearlier\t0.609\n",
      "\t\tago\t0.606\n",
      "\t\tshortly_thereafter\t0.568\n",
      "\t\tshortly_afterwards\t0.539\n",
      "\t\tsubsequently\t0.538\n",
      "\t\tLater\t0.534\n",
      "\t\teventually\t0.529\n",
      "\t\t\n",
      "Original Word:\tsubstantial\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['large', 'much']\n",
      "Pred Answers:\tlarge\t1.0\n",
      "\t\tsizeable\t0.734\n",
      "\t\tsmall\t0.733\n",
      "\t\tsizable\t0.733\n",
      "\t\tLarge\t0.665\n",
      "\t\thuge\t0.659\n",
      "\t\tlarger\t0.652\n",
      "\t\tmassive\t0.613\n",
      "\t\tsmaller\t0.603\n",
      "\t\tsubstantial\t0.587\n",
      "\t\t\n",
      "Original Word:\tviable\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['practical', 'workable']\n",
      "Pred Answers:\tpractical\t1.0\n",
      "\t\tPractical\t0.66\n",
      "\t\tbeaded_sweaters_replaced\t0.594\n",
      "\t\tscientist_Alice_Lichtenstein\t0.563\n",
      "\t\tjoke_Skrenta\t0.538\n",
      "\t\teminently_practical\t0.533\n",
      "\t\tpracticality\t0.516\n",
      "\t\tbeaded_sweaters\t0.511\n",
      "\t\tsimple\t0.509\n",
      "\t\ttheoretical\t0.506\n",
      "\t\t\n",
      "Original Word:\twhomsoever\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['whoever', 'whomever']\n",
      "Pred Answers:\twhoever\t1.0\n",
      "\t\twhomever\t0.79\n",
      "\t\tWhoever\t0.764\n",
      "\t\tWhomever\t0.66\n",
      "\t\tsomebody\t0.627\n",
      "\t\twhatever\t0.62\n",
      "\t\tsomebody_else\t0.607\n",
      "\t\tsomeone\t0.583\n",
      "\t\tnobody\t0.583\n",
      "\t\teverybody\t0.575\n",
      "\t\t\n",
      "Original Word:\twitnessed\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['saw']\n",
      "Pred Answers:\tsaw\t1.0\n",
      "\t\tnoticed\t0.597\n",
      "\t\twitnessed\t0.59\n",
      "\t\tseeing\t0.581\n",
      "\t\tlooked\t0.568\n",
      "\t\tcame\t0.561\n",
      "\t\twatched\t0.557\n",
      "\t\tseen\t0.549\n",
      "\t\tshowed\t0.541\n",
      "\t\twent\t0.527\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "display(words_df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('understand', 0.4546816945075989),\n",
       " ('know', 0.4448050558567047),\n",
       " ('Unrivalled_insight', 0.42923736572265625),\n",
       " ('discern', 0.4218718409538269),\n",
       " ('believe', 0.41339924931526184),\n",
       " ('slowly_Jasny', 0.41248685121536255),\n",
       " ('determine', 0.41123640537261963),\n",
       " ('knowing', 0.410343199968338),\n",
       " ('clear', 0.409426748752594),\n",
       " ('deduce', 0.4068732261657715)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(w2v['ascertain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Embedding, RNN, LSTM, LSTMCell, Dense, Dropout, Concatenate\n",
    "from keras.layers import TimeDistributed, Bidirectional, Lambda, Layer\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.core import Reshape\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import metrics, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
