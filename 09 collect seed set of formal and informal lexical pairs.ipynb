{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "import gensim\n",
    "import xml.etree.ElementTree as ET\n",
    "from ast import literal_eval\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# put existing gzt and files into pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/acrolinx_gzt/lf.json') as lfjson:\n",
    "    lf = json.load(lfjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/acrolinx_gzt/conv-words.json') as cvjson:\n",
    "    form_with_sugg = json.load(cvjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_gzt = []\n",
    "\n",
    "with open('data/acrolinx_gzt/archaicWords.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countFormalPhrases.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countLatinExpressions.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzt = {}\n",
    "\n",
    "# things i noticed and don't want\n",
    "exceptions = ['use either', '(']\n",
    "\n",
    "for item in unclean_gzt:\n",
    "    if item[0] == '@' or item[0] == '#':\n",
    "        continue\n",
    "    item = item.strip()\n",
    "    if len(item) < 1:\n",
    "        continue\n",
    "    trigger = False\n",
    "    for term in exceptions:\n",
    "        if term in item:\n",
    "            trigger = True\n",
    "    if trigger:\n",
    "        continue\n",
    "    item = re.sub('\\[', '', item)\n",
    "    item = re.sub('\\]', '', item)\n",
    "    item = re.sub('\\n', '', item)\n",
    "    item = re.sub(';', '', item)\n",
    "    if '-->' in item:\n",
    "        pair = [part.strip() for part in item.split('-->')]\n",
    "        if ',' in pair[0]:\n",
    "            form_words = [part.strip() for part in pair[0].split(',')]\n",
    "            for word in form_words:\n",
    "                gzt[word] = [part.strip() for part in pair[1].split(',')]\n",
    "        else:\n",
    "            gzt[pair[0]] = [part.strip() for part in pair[1].split(',')]\n",
    "    else:\n",
    "        gzt[item] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gzt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purchase</td>\n",
       "      <td>[buy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caveat</td>\n",
       "      <td>[warning]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asserted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thenceforward</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pardon me</td>\n",
       "      <td>[Sorry]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          formal suggestions\n",
       "0       purchase       [buy]\n",
       "1         caveat   [warning]\n",
       "2       asserted         NaN\n",
       "3  thenceforward         NaN\n",
       "4      Pardon me     [Sorry]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal = []\n",
    "informal = []\n",
    "\n",
    "for word in gzt:\n",
    "    formal.append(word)\n",
    "    informal.append(gzt[word])\n",
    "\n",
    "words = pd.DataFrame()\n",
    "words['formal'] = formal\n",
    "words['suggestions'] = informal\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-ed875a0d7dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/acrolinx_gzt/initial_words.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"
     ]
    }
   ],
   "source": [
    "words.to_pickle('data/acrolinx_gzt/initial_words.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next: extrapolate to the other words using embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_pickle('data/acrolinx_gzt/initial_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_pickle('data/acrolinx_gzt/initial_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purchase</td>\n",
       "      <td>[buy]</td>\n",
       "      <td>[0.05419922, -0.16699219, -0.18261719, 0.17089...</td>\n",
       "      <td>[0.060302734, -0.17871094, -0.09716797, 0.2753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caveat</td>\n",
       "      <td>[warning]</td>\n",
       "      <td>[0.15234375, -0.03515625, 0.059814453, 0.125, ...</td>\n",
       "      <td>[-0.11376953, -0.15136719, 0.16992188, -0.0500...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asserted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.106933594, 0.14550781, -0.047851562, -0.08...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thenceforward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pardon me</td>\n",
       "      <td>[Sorry]</td>\n",
       "      <td>[0.255859375, -0.052001953125, 0.168701171875,...</td>\n",
       "      <td>[0.052246094, 0.095703125, -0.0028839111, 0.13...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          formal suggestions  \\\n",
       "0       purchase       [buy]   \n",
       "1         caveat   [warning]   \n",
       "2       asserted         NaN   \n",
       "3  thenceforward         NaN   \n",
       "4      Pardon me     [Sorry]   \n",
       "\n",
       "                                               X_w2v  \\\n",
       "0  [0.05419922, -0.16699219, -0.18261719, 0.17089...   \n",
       "1  [0.15234375, -0.03515625, 0.059814453, 0.125, ...   \n",
       "2  [-0.106933594, 0.14550781, -0.047851562, -0.08...   \n",
       "3                                                NaN   \n",
       "4  [0.255859375, -0.052001953125, 0.168701171875,...   \n",
       "\n",
       "                                               y_w2v  \n",
       "0  [0.060302734, -0.17871094, -0.09716797, 0.2753...  \n",
       "1  [-0.11376953, -0.15136719, 0.16992188, -0.0500...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  [0.052246094, 0.095703125, -0.0028839111, 0.13...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('/home/rebekah/Documents/Word Embeddings/GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countenance', 0.3350488245487213),\n",
       " ('revivified', 0.32268810272216797),\n",
       " ('unstinted', 0.32051318883895874)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = 'oppose'\n",
    "w2v.most_similar(positive=[word, 'peruse', 'penurious', 'amidst', 'endeavor'], negative=['read', 'poor', 'among', 'try'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_word_lists(wl, embed):\n",
    "    if len(wl) == 1:\n",
    "        if wl[0] in embed:\n",
    "            return embed[wl[0]]\n",
    "    elif len(wl) > 1:\n",
    "        vecs = [0.0] * len(embed['word'])\n",
    "        for w in wl:\n",
    "            if w in embed:\n",
    "                vecs = list(map(sum, zip(vecs, embed[w])))\n",
    "        if vecs != [0.0] * len(embed['word']):\n",
    "            return vecs\n",
    "    return np.nan\n",
    "\n",
    "def make_data(df, embed, X, y):\n",
    "    X_ph = np.nan * len(df)\n",
    "    y_ph = np.nan * len(df)\n",
    "    df[X] = X_ph\n",
    "    df[X] = df[X].astype(object)\n",
    "    df[y] = y_ph\n",
    "    df[y] = df[y].astype(object)\n",
    "    \n",
    "    for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "        formal_words = nltk.word_tokenize(row['formal'])\n",
    "        df.at[idx, X] = process_word_lists(formal_words, embed) \n",
    "        informal_words = []\n",
    "        if type(row['suggestions']) != float:\n",
    "            for word in row['suggestions']:\n",
    "                word = nltk.word_tokenize(word)\n",
    "                word = process_word_lists(word, embed)\n",
    "                informal_words.append(word)\n",
    "        if len(informal_words) > 0:\n",
    "            df.at[idx, y] = informal_words[0]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b296568c3a3474999d98becb49b1204"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = make_data(words_df, w2v, 'X_w2v', 'y_w2v')\n",
    "words_df.to_pickle('data/acrolinx_gzt/initial_words.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = words_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in train.iterrows():\n",
    "    assert len(row['X_w2v']) == 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(train['X_w2v']))\n",
    "y = np.array(list(train['y_w2v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>duly observe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.259765625, -0.150634765625, 0.21923828125,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>elect</td>\n",
       "      <td>[chose, pick]</td>\n",
       "      <td>[-0.035888672, -0.008422852, -0.011108398, 0.1...</td>\n",
       "      <td>[0.25976562, 0.359375, 0.16796875, 0.119140625...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>beseech</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.17773438, 0.38085938, 0.3125, 0.26953125, -...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>make an attempt</td>\n",
       "      <td>[try]</td>\n",
       "      <td>[0.216796875, 0.311767578125, 0.10986328125, 0...</td>\n",
       "      <td>[0.24023438, 0.20117188, 0.16210938, 0.2089843...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>consumedly</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>contra</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.13183594, -0.17578125, 0.022338867, 0.1137...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Mrs.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.232421875, -0.1875, -0.28125, -0.0654296875...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>alack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.02722168, -0.029541016, -0.061279297, 0.204...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>on a basis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.0037841796875, -0.2734375, 0.015380859375,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>reflect</td>\n",
       "      <td>[say, show]</td>\n",
       "      <td>[-0.34765625, 0.12695312, 0.056152344, -0.0158...</td>\n",
       "      <td>[-0.036132812, -0.12109375, 0.13378906, 0.1142...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              formal    suggestions  \\\n",
       "593     duly observe            NaN   \n",
       "273            elect  [chose, pick]   \n",
       "223          beseech            NaN   \n",
       "378  make an attempt          [try]   \n",
       "578       consumedly            NaN   \n",
       "69            contra            NaN   \n",
       "225             Mrs.            NaN   \n",
       "452            alack            NaN   \n",
       "200       on a basis            NaN   \n",
       "57           reflect    [say, show]   \n",
       "\n",
       "                                                 X_w2v  \\\n",
       "593  [-0.259765625, -0.150634765625, 0.21923828125,...   \n",
       "273  [-0.035888672, -0.008422852, -0.011108398, 0.1...   \n",
       "223  [0.17773438, 0.38085938, 0.3125, 0.26953125, -...   \n",
       "378  [0.216796875, 0.311767578125, 0.10986328125, 0...   \n",
       "578                                                NaN   \n",
       "69   [-0.13183594, -0.17578125, 0.022338867, 0.1137...   \n",
       "225  [0.232421875, -0.1875, -0.28125, -0.0654296875...   \n",
       "452  [0.02722168, -0.029541016, -0.061279297, 0.204...   \n",
       "200  [-0.0037841796875, -0.2734375, 0.015380859375,...   \n",
       "57   [-0.34765625, 0.12695312, 0.056152344, -0.0158...   \n",
       "\n",
       "                                                 y_w2v  \n",
       "593                                                NaN  \n",
       "273  [0.25976562, 0.359375, 0.16796875, 0.119140625...  \n",
       "223                                                NaN  \n",
       "378  [0.24023438, 0.20117188, 0.16210938, 0.2089843...  \n",
       "578                                                NaN  \n",
       "69                                                 NaN  \n",
       "225                                                NaN  \n",
       "452                                                NaN  \n",
       "200                                                NaN  \n",
       "57   [-0.036132812, -0.12109375, 0.13378906, 0.1142...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    pred = lr.predict([word]).reshape(-1, 1)\n",
    "    pred = pred.reshape(300,)\n",
    "    return w2v.similar_by_vector(pred, topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6c5f671ce94927a117192171207faf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-4aef5d843bf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mw2v_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'X_w2v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mword_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_w2v'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2v_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_df' is not defined"
     ]
    }
   ],
   "source": [
    "w2v_pred = []\n",
    "for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "    if type(row['X_w2v']) == float:\n",
    "        formal = nltk.word_tokenize(row['formal'])\n",
    "        vec = process_word_lists(formal, w2v)\n",
    "        if type(vec) == float:\n",
    "            w2v_pred.append(np.nan)\n",
    "        else:\n",
    "            w2v_pred.append(predict(vec))\n",
    "    else:\n",
    "        w2v_pred.append(predict(row['X_w2v']))\n",
    "words_df['pred_w2v'] = w2v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "      <th>pred_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>purchase</td>\n",
       "      <td>[buy]</td>\n",
       "      <td>[0.05419922, -0.16699219, -0.18261719, 0.17089...</td>\n",
       "      <td>[0.060302734, -0.17871094, -0.09716797, 0.2753...</td>\n",
       "      <td>[(buy, 1.0), (sell, 0.8308461904525757), (purc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>caveat</td>\n",
       "      <td>[warning]</td>\n",
       "      <td>[0.15234375, -0.03515625, 0.059814453, 0.125, ...</td>\n",
       "      <td>[-0.11376953, -0.15136719, 0.16992188, -0.0500...</td>\n",
       "      <td>[(warning, 1.0), (warnings, 0.8184125423431396...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>asserted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.106933594, 0.14550781, -0.047851562, -0.08...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(think, 0.5262875556945801), (say, 0.49223661...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thenceforward</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pardon me</td>\n",
       "      <td>[Sorry]</td>\n",
       "      <td>[0.255859375, -0.052001953125, 0.168701171875,...</td>\n",
       "      <td>[0.052246094, 0.095703125, -0.0028839111, 0.13...</td>\n",
       "      <td>[(Sorry, 1.0), (Hey, 0.690428614616394), (Okay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          formal suggestions  \\\n",
       "0       purchase       [buy]   \n",
       "1         caveat   [warning]   \n",
       "2       asserted         NaN   \n",
       "3  thenceforward         NaN   \n",
       "4      Pardon me     [Sorry]   \n",
       "\n",
       "                                               X_w2v  \\\n",
       "0  [0.05419922, -0.16699219, -0.18261719, 0.17089...   \n",
       "1  [0.15234375, -0.03515625, 0.059814453, 0.125, ...   \n",
       "2  [-0.106933594, 0.14550781, -0.047851562, -0.08...   \n",
       "3                                                NaN   \n",
       "4  [0.255859375, -0.052001953125, 0.168701171875,...   \n",
       "\n",
       "                                               y_w2v  \\\n",
       "0  [0.060302734, -0.17871094, -0.09716797, 0.2753...   \n",
       "1  [-0.11376953, -0.15136719, 0.16992188, -0.0500...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  [0.052246094, 0.095703125, -0.0028839111, 0.13...   \n",
       "\n",
       "                                            pred_w2v  \n",
       "0  [(buy, 1.0), (sell, 0.8308461904525757), (purc...  \n",
       "1  [(warning, 1.0), (warnings, 0.8184125423431396...  \n",
       "2  [(think, 0.5262875556945801), (say, 0.49223661...  \n",
       "3                                                NaN  \n",
       "4  [(Sorry, 1.0), (Hey, 0.690428614616394), (Okay...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df['pred_w2v'] = w2v_pred\n",
    "words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        print('Original Word:\\t' + row['formal'])\n",
    "        train = type(row['y_w2v']) != float\n",
    "        print('Training Data?:\\t' + str(train))\n",
    "        if type(row['suggestions']) != float:\n",
    "            print('Given Answer:\\t' + str(row['suggestions']))\n",
    "        if type(row['pred_w2v']) != float:\n",
    "            ans = ''\n",
    "            for item in row['pred_w2v']:\n",
    "                ans += item[0] + '\\t' + str('%s' % float('%.3g' % item[1])) + '\\n\\t\\t'\n",
    "            print('Pred Answers:\\t' + ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word:\tinstill\n",
      "Training Data?:\tFalse\n",
      "Pred Answers:\tWhere're\t0.385\n",
      "\t\thonest\t0.382\n",
      "\t\tcritisize\t0.377\n",
      "\t\tnit_pick\t0.375\n",
      "\t\toogle\t0.372\n",
      "\t\tshowin\t0.369\n",
      "\t\tapreciate\t0.368\n",
      "\t\td_**_khead\t0.367\n",
      "\t\tcomplainin\t0.366\n",
      "\t\tboing_boing\t0.366\n",
      "\t\t\n",
      "Original Word:\tentitlement\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['right']\n",
      "Pred Answers:\tright\t1.0\n",
      "\t\tRight\t0.57\n",
      "\t\twrong\t0.553\n",
      "\t\t##.Help_us\t0.55\n",
      "\t\tGoodwill_Catanese\t0.516\n",
      "\t\tleft\t0.492\n",
      "\t\tfielder_Joe_Borchard\t0.489\n",
      "\t\tNOTE_Xactly_Incent\t0.489\n",
      "\t\tfielder_Ambiorix_Concepcion\t0.484\n",
      "\t\tnow\t0.479\n",
      "\t\t\n",
      "Original Word:\tperspire\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['sweat']\n",
      "Pred Answers:\tsweat\t1.0\n",
      "\t\tperspiration\t0.642\n",
      "\t\tMud_resin\t0.633\n",
      "\t\tsweating\t0.603\n",
      "\t\tsweated\t0.597\n",
      "\t\tsweaty\t0.552\n",
      "\t\tsweat_dripping\t0.546\n",
      "\t\tSweat\t0.515\n",
      "\t\tperspire\t0.505\n",
      "\t\tsweats\t0.5\n",
      "\t\t\n",
      "Original Word:\tdiscover\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['find out']\n",
      "Pred Answers:\tfind\t0.819\n",
      "\t\tout\t0.758\n",
      "\t\tdiscover\t0.569\n",
      "\t\tfinding\t0.567\n",
      "\t\tget\t0.554\n",
      "\t\tsee\t0.551\n",
      "\t\tback\t0.49\n",
      "\t\tfound\t0.489\n",
      "\t\ttofind\t0.489\n",
      "\t\tin.\t0.482\n",
      "\t\t\n",
      "Original Word:\tIt concerns\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['It’s about']\n",
      "Pred Answers:\tIt\t0.73\n",
      "\t\tThat\t0.671\n",
      "\t\tThis\t0.626\n",
      "\t\ts\t0.607\n",
      "\t\tabout\t0.593\n",
      "\t\tItâ_€_™\t0.587\n",
      "\t\tIt'sa\t0.569\n",
      "\t\tWhat\t0.568\n",
      "\t\tThatâ_€_™\t0.564\n",
      "\t\tThat'sa\t0.562\n",
      "\t\t\n",
      "Original Word:\trefer back\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['refer']\n",
      "Pred Answers:\trefer\t1.0\n",
      "\t\treferred\t0.744\n",
      "\t\trefers\t0.634\n",
      "\t\tdescribe\t0.586\n",
      "\t\trefered\t0.557\n",
      "\t\tclassify\t0.514\n",
      "\t\taffectionately_refer\t0.512\n",
      "\t\tascribe\t0.511\n",
      "\t\tcite\t0.507\n",
      "\t\tReferred\t0.499\n",
      "\t\t\n",
      "Original Word:\thereunder\n",
      "Training Data?:\tFalse\n",
      "Pred Answers:\tcrystal_clear\t0.264\n",
      "\t\tsternest\t0.262\n",
      "\t\tKhabir\t0.245\n",
      "\t\tprejudiced_Foxman\t0.242\n",
      "\t\tTjiang\t0.233\n",
      "\t\tmeasurable_outcomes\t0.233\n",
      "\t\tYes_sir\t0.229\n",
      "\t\tPRXL_accordingly\t0.227\n",
      "\t\tTurnidges_harbored_fantasies\t0.227\n",
      "\t\taccordingly\t0.227\n",
      "\t\t\n",
      "Original Word:\tbelated\n",
      "Training Data?:\tTrue\n",
      "Given Answer:\t['late']\n",
      "Pred Answers:\tlate\t1.0\n",
      "\t\tearly\t0.812\n",
      "\t\tmid\t0.625\n",
      "\t\tLate\t0.614\n",
      "\t\tAfter_inventing_microarray\t0.491\n",
      "\t\tprimetime_daytime\t0.466\n",
      "\t\tCMEA_invests\t0.454\n",
      "\t\tEarly\t0.453\n",
      "\t\tsometime\t0.445\n",
      "\t\tafter\t0.444\n",
      "\t\t\n",
      "Original Word:\tupsurge\n",
      "Training Data?:\tFalse\n",
      "Pred Answers:\tabout\t0.501\n",
      "\t\tgrough_wants\t0.39\n",
      "\t\treally\t0.387\n",
      "\t\tscreener_traveler\t0.382\n",
      "\t\tSCHIEFFER_Let\t0.374\n",
      "\t\ttalke\t0.372\n",
      "\t\tOh_gosh\t0.37\n",
      "\t\tstep_Pildegovics\t0.363\n",
      "\t\t'll\t0.36\n",
      "\t\tder_kinder\t0.359\n",
      "\t\t\n",
      "Original Word:\tconsensus\n",
      "Training Data?:\tFalse\n",
      "Pred Answers:\tpreparation\t0.284\n",
      "\t\tREEDLEY_Calif.\t0.278\n",
      "\t\tPreparation\t0.269\n",
      "\t\tTransCanada_itemized\t0.265\n",
      "\t\t####were\t0.254\n",
      "\t\tData_Breach_Study\t0.254\n",
      "\t\tSindh_Madrassah_tul_Islam\t0.254\n",
      "\t\tUPDATED_COVERAGE\t0.251\n",
      "\t\tCryogenian_period\t0.25\n",
      "\t\tGieschen_Consultancy\t0.249\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "display(words_df.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, Embedding, RNN, LSTM, LSTMCell, Dense, Dropout, Concatenate\n",
    "from keras.layers import TimeDistributed, Bidirectional, Lambda, Layer\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.recurrent import Recurrent\n",
    "from keras.layers.core import Reshape\n",
    "from keras.activations import tanh, softmax\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import metrics, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
