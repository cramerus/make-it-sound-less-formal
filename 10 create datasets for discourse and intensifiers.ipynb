{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(loc):\n",
    "    with open(loc) as f:\n",
    "        return [x.strip() for x in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_df(df, terms):\n",
    "    # count number of example sentences (unverified) for each example\n",
    "    terms_dict = defaultdict(list)\n",
    "    for item in tqdm(terms):\n",
    "        if item.strip() in df.columns:\n",
    "            continue\n",
    "        for sent in df['sent']:\n",
    "            sent = ' '.join(sent)\n",
    "            if item + ' ' in sent:\n",
    "                terms_dict[item.strip()].append(1)\n",
    "            else:\n",
    "                terms_dict[item.strip()].append(0)\n",
    "        df[item.strip()] = terms_dict[item.strip()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sent(sent, term):\n",
    "    # remove and recapitalize\n",
    "    # makes sure to remove commas as well\n",
    "    \n",
    "    copy = sent.copy()\n",
    "    \n",
    "    terms = nltk.word_tokenize(term)\n",
    "    if len(terms) == 1:\n",
    "        term = terms[0]\n",
    "    else:\n",
    "        temp_idx = -1\n",
    "        for term_idx in range(len(terms)):\n",
    "            if temp_idx == -1:\n",
    "                temp_idx = copy.index(terms[term_idx])\n",
    "            else:\n",
    "                try:\n",
    "                    assert copy.index(terms[term_idx]) == temp_idx + 1\n",
    "                except: # there's only 3\n",
    "                    print('skip')\n",
    "                    return np.nan\n",
    "                del copy[temp_idx + 1]\n",
    "        term = terms[0]\n",
    "    \n",
    "    idx = sent.index(term)\n",
    "    \n",
    "    if copy[idx + 1] == ',': # remove comma too\n",
    "        del copy[idx + 1]\n",
    "    elif copy[idx + 1] == '.': # make sure you're not removing entire sentence\n",
    "        print('end of sent')\n",
    "        return np.nan\n",
    "    elif copy[idx + 1] == \"''\": # end of quote\n",
    "        print('end of quote')\n",
    "        return np.nan\n",
    "        \n",
    "    copy[idx + 1] = copy[idx + 1].capitalize()\n",
    "    del copy[idx]\n",
    "        \n",
    "    return copy\n",
    "\n",
    "def clean_df(df):\n",
    "    # provide 'clean' version of sentence, without the relevant term\n",
    "    # checks for capitalization and makes proper if necessary\n",
    "    \n",
    "    df['clean'] = [np.nan] * len(df)\n",
    "    df['clean'] = df['clean'].astype(object)\n",
    "    terms = df.columns[1:-1]\n",
    "    \n",
    "    for term in tqdm(terms):\n",
    "        for idx, row in df[df[term] == 1].iterrows():\n",
    "            df.at[idx, 'clean'] = clean_sent(row['sent'], term)\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# discourse markers: Brown corpus"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sents = brown.sents()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "disc = read_file('data/discourse_markers/discourse_markers.txt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "brown_disc_df = pd.DataFrame()\n",
    "brown_disc_df['sent'] = sents"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "brown_disc_df = fill_df(brown_disc_df, disc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "brown_disc_df = clean_df(brown_disc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_disc_df = pd.read_pickle('data/discourse_markers/brown_disc_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_disc_df.to_pickle('data/discourse_markers/brown_disc_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qualifiers/intensifiers: Brown corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "qual = set(read_file('data/qualifiers_intensifiers/qual_intens_list.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_qual_df = pd.DataFrame()\n",
    "brown_qual_df['sent'] = sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17662ee0fc764efa86d00e32fe252b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=71), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "brown_qual_df = fill_df(brown_qual_df, [' ' + x for x in qual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if ever\t3\n",
      "ultimately\t19\n",
      "far\t401\n",
      "all of\t153\n",
      "so-called\t31\n",
      "particularly\t141\n",
      "much\t878\n",
      "admittedly\t3\n",
      "please\t45\n",
      "exactly\t99\n",
      "perfectly\t31\n",
      "actually\t127\n",
      "little\t767\n",
      "big\t308\n",
      "apparently\t102\n",
      "a lot\t85\n",
      "alone\t190\n",
      "vast\t60\n",
      "all\t2611\n",
      "at all\t183\n",
      "in effect\t24\n",
      "clearly\t118\n",
      "extremely\t50\n",
      "generally\t119\n",
      "some kind of\t21\n",
      "quite\t269\n",
      "usually\t185\n",
      "right\t577\n",
      "too\t760\n",
      "sorely\t3\n",
      "also\t983\n",
      "of course\t234\n",
      "surely\t38\n",
      "importantly\t8\n",
      "ever\t328\n",
      "blatantly\t0\n",
      "such\t1124\n",
      "lots of\t26\n",
      "exact\t27\n",
      "honestly\t12\n",
      "at least\t272\n",
      "just\t742\n",
      "necessarily\t49\n",
      "really\t267\n",
      "probably\t232\n",
      "some\t1345\n",
      "even\t954\n",
      "occasionally\t32\n",
      "pretty\t98\n",
      "relatively\t84\n",
      "fully\t80\n",
      "ideally\t5\n",
      "absolutely\t27\n",
      "well\t744\n",
      "definitely\t21\n",
      "a bit\t56\n",
      "incredibly\t7\n",
      "sort of\t117\n",
      "maybe\t66\n",
      "certainly\t115\n",
      "literally\t26\n",
      "simply\t166\n",
      "possibly\t57\n",
      "so\t1641\n",
      "specifically\t36\n",
      "actively\t11\n",
      "then\t984\n",
      "very\t749\n",
      "completely\t109\n",
      "er\t0\n",
      "truly\t56\n"
     ]
    }
   ],
   "source": [
    "# count number of example sentences (unverified) for each example\n",
    "for col in brown_qual_df:\n",
    "    if brown_qual_df[col].dtype == 'int64':\n",
    "        print(col + '\\t' + str(sum(brown_qual_df[col])))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "if ever\t3\n",
    "so-called\t31\n",
    "importantly\n",
    "ideally\n",
    "definitely\n",
    "honestly\n",
    "far\t401\n",
    "all of\t153\n",
    "particularly\t141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has been obvious to the assessors , particularly those in shore communities , that boats comprise the largest category of tangible personal property which they have been unable to reach .\n",
      "\n",
      "The preceding methods allow efficient use of index words and electronic switches during a sectionalized or multi-phase program , particularly when used in conjunction with the LITORIGIN statement .\n",
      "\n",
      "And while no one expects total democracy on the academic scene , the scholar will be particularly sensitive to a line between first and second class citizenship drawn on any basis other than that of academic rank or professional achievement .\n",
      "\n",
      "But it is the wooden sculpture from Bali , the one representing two men with their heads bent backward and their bodies interlaced by a fish , that I particularly call to your attention .\n",
      "\n",
      "Many companies have systems , particularly in R & D , which work more or less well , depending upon size and actual belief in the policy on the part of administration , as will be abundantly apparent in subsequent quotations .\n",
      "\n",
      "The Court said the purpose of the section was principally to spare the Government the embarrassment and trouble of dealing with several parties , one of them a stranger to the claim , and to prevent traffic in claims , particularly tenuous claims , against the Government .\n",
      "\n",
      "Almost inevitably , the first result of this technological revolution was a reaction against the methods and in many cases the conclusions of the Oxford school of Stubbs , Freeman and ( particularly ) Green regarding the nature of the Anglo-Saxon conquest of Britain .\n",
      "\n",
      "He had never felt particularly close to her .\n",
      "\n",
      "Questions and , particularly , exclamations are usually channeled along informal , horizontal lines not indicated in Figure 3 and seldom are carried beyond the nearest neighbor .\n",
      "\n",
      "The cooling requirements are particularly severe at the anode .\n",
      "\n",
      "Confused and divided though this tradition may be , it is an important part of the social and cultural heritage of the group , and acts as a means of socialization , particularly for members of the rural community .\n",
      "\n",
      "The Frankfurt years were particularly noteworthy for his performance of Berg's Wozzek soon after the Berlin premiere under Erich Kleiber , and the world premiere of Schonberg's Von heute auf morgen .\n",
      "\n",
      "The paper has a certain value as a comparatively easy introduction to this approach , particularly since it treats a fairly simple and straightforward phenomenon where it is possible to compare it with a more traditional ( though not structural ) statement .\n",
      "\n",
      "The pansies I cherished most bloomed for me in February during a particularly cold winter .\n",
      "\n",
      "Mrs. Reavey's work is written for the stage -- it is mentioned for an off-Broadway production in the fall -- and , in addition , employs an avant-garde structure that particularly needs to be seen if comprehension is to be encouraged .\n",
      "\n",
      "In any inquiry into the way in which great literature affects the emotions , particularly with respect to the sense of harmony , or relief of tension , or sense of `` a transformed inner nature '' which may occur , a most careful exploration of the particular feature of the experience which produces the effect would be required .\n",
      "\n",
      "It is particularly interesting that those who framed the report should refer to `` the organization which actually owns the university '' : this seems to show an awareness of the fact that there is more to the problem than the ordinary issue of clerical-lay tension .\n",
      "\n",
      "This was particularly noticeable in group A and group B sera , in which cases activity in Regions 1 and 2 was usually not detectable without prior concentration and occasionally could not be detected at all .\n",
      "\n",
      "`` Argiento , this is senseless '' , he complained , not liking to work on the wet floors , particularly in cold weather .\n",
      "\n",
      "Some of us might be inclined to argue , in fact , that an independence of mind and action and an intolerance of regimentation , either mental or physical , are particularly Southern traits .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in brown_qual_df[brown_qual_df['particularly'] == 1].sample(20)['sent']:\n",
    "    print(' '.join(item))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
