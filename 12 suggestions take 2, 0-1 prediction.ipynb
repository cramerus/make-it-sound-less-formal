{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Concatenate, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('code/data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('code/data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)\n",
    "    \n",
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "# we want to mask_zero, so we need to:\n",
    "# remove 0 key from dict and put its content at the end\n",
    "# replace '' entry in embedding with the 0-key element\n",
    "\n",
    "embedding[embedding.shape[0] - 1] = embedding[0]\n",
    "assert w2idx['the'] == 0\n",
    "w2idx['the'] = embedding.shape[0] - 1\n",
    "del w2idx['']\n",
    "\n",
    "pad = 0\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2w = dict((i, word) for word, i in w2idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import acrolinx blog post dataset - but with contractions only just to test\n",
    "\n",
    "def check_df(string):\n",
    "    # basic check for contractions\n",
    "    if \"'\" in string:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df = pd.read_pickle('code/data/acrolinx_blog/acrolinx_blog_annotated_df.pkl')\n",
    "df = df[df['Replacement'].apply(lambda x: check_df(x)) == True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "# NOTE: there is word lowering in this because the pretrained word vectors, GloVe, only include\n",
    "# lowercase tokens\n",
    "\n",
    "def seq_to_idx(string):\n",
    "    # turns sequence of tokens to sequence of indices\n",
    "    seq = word_tokenize(string)\n",
    "    idx = []\n",
    "    for word in seq:\n",
    "        word = word.lower()\n",
    "        if word in w2idx:\n",
    "            idx.append(w2idx[word])\n",
    "        #else: #unknown tokens?\n",
    "    return idx\n",
    "\n",
    "def make_span(start, end, seq_len):\n",
    "    # takes start and end of span and returns 0/1 output for the given sequence length\n",
    "    new = [0] * seq_len\n",
    "    new[start : end] = [1] * (end - start)\n",
    "    return new\n",
    "\n",
    "def reduce_fragments(orig, repl):\n",
    "    # removes repeated sections of original and replacement texts (e.g. minimizes length)\n",
    "    # unless it would make one of the sections empty\n",
    "    \n",
    "    # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to these\n",
    "    # this, the replacement/target text, will be used in the decoder step of training only\n",
    "    \n",
    "    return orig, repl\n",
    "\n",
    "def preprocess(df):\n",
    "    x_token = []\n",
    "    span = []\n",
    "    dec_input = []\n",
    "    dec_target = []\n",
    "    y_repl = []\n",
    "    x_orig = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        \n",
    "        # Converting sentence strings to lists of indices.\n",
    "        sent = seq_to_idx(row['Sentence'])\n",
    "        orig = seq_to_idx(row['Original'])\n",
    "        repl = seq_to_idx(row['Replacement'])\n",
    "        \n",
    "        if len(sent) == 0 or len(orig) == 0 or len(repl) == 0:\n",
    "            x_token.append(np.nan)\n",
    "            span.append(np.nan)\n",
    "            y_repl.append(np.nan)\n",
    "            dec_input.append(np.nan)\n",
    "            dec_target.append(np.nan)\n",
    "            x_orig.append(np.nan)\n",
    "            print('Empty sentence or fragment: ' + row['Sentence'])\n",
    "            continue\n",
    "            \n",
    "        x_token.append(sent)\n",
    "        x_orig.append(orig)\n",
    "        dec_input.append([w2idx['\\t']] + repl)\n",
    "        dec_target.append(repl + [w2idx['\\n']])\n",
    "        y_repl.append(repl)\n",
    "                \n",
    "        # take indices and find the 1st occurrence of the slice in the whole sentence\n",
    "        starts = [i for i, x in enumerate(sent) if x == orig[0]]\n",
    "        current_span = []\n",
    "        y_s = np.nan\n",
    "        y_e = np.nan\n",
    "        for potential_start in starts:\n",
    "            potential_slice = sent[potential_start : potential_start + len(orig)]\n",
    "            if (potential_slice == np.array(orig)).all():\n",
    "                y_s = potential_start\n",
    "                y_e = potential_start + len(orig) + 1\n",
    "                break\n",
    "        if np.isnan(y_s) or np.isnan(y_e):\n",
    "            print('Original not found in sentence.')\n",
    "            print(row['Sentence'])\n",
    "            print(row['Original'])\n",
    "            span.append(np.nan)\n",
    "        else:\n",
    "            span.append(make_span(int(y_s), int(y_e - 1), len(sent)))\n",
    "                \n",
    "    df['x_token'] = x_token\n",
    "    df['span'] = span\n",
    "    df['dec_input'] = dec_input\n",
    "    df['dec_target'] = dec_target\n",
    "    df['y_repl'] = y_repl\n",
    "    df['x_orig'] = x_orig\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce8721acdf74085befad33477950be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3205), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original not found in sentence.\n",
      "Now you have seen all of the problem words that we have collectedd .\n",
      "that we have collected\n",
      "Original not found in sentence.\n",
      "It does not mean… We 're rigid or uptight .\n",
      "It does not mean\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add POST-padding\n",
    "X = pad_sequences(df['x_token'], maxlen = 20, value = pad, padding = 'post').astype('int64')\n",
    "y_span = pad_sequences(df['span'], maxlen = 20, value = 0, padding = 'post').astype('int64')\n",
    "\n",
    "y_span_cat = np.zeros((y_span.shape[0], y_span.shape[1], 2))\n",
    "for idx_1 in range(y_span.shape[0]):\n",
    "    for idx_2 in range(y_span.shape[1]):\n",
    "        y_span_cat[idx_1][idx_2] = to_categorical(y_span[idx_1][idx_2], num_classes = 2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_span_cat, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>you have</td>\n",
       "      <td>you 've</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are</td>\n",
       "      <td>You 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you are</td>\n",
       "      <td>you 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>do not</td>\n",
       "      <td>do n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It is</td>\n",
       "      <td>It 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>They will</td>\n",
       "      <td>They 'll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>That is</td>\n",
       "      <td>That 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>you are thinking</td>\n",
       "      <td>you 're thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>You will have to give</td>\n",
       "      <td>You 've got to give</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>It is not longer enough</td>\n",
       "      <td>It 's no longer enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If you do not , then</td>\n",
       "      <td>If you do n't ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>you will be wasting their time</td>\n",
       "      <td>you 'll be wasting their time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>You need to make</td>\n",
       "      <td>You need to make sure that you 're doing every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>your audience will not do anything</td>\n",
       "      <td>your audience wo n't do anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Do not dilute your message</td>\n",
       "      <td>do n't dilute your message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>you have to work hard</td>\n",
       "      <td>you 've got to work really hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the only bait we have received</td>\n",
       "      <td>the only bait we 've got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>It is fine</td>\n",
       "      <td>It 's fine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>if you are not giving</td>\n",
       "      <td>if you 're not giving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>you should be disappointed</td>\n",
       "      <td>you 're missing out on a big opportunity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>we are at it again</td>\n",
       "      <td>we 're at it again</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Even if you are confident</td>\n",
       "      <td>Even if you 're confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>you are using</td>\n",
       "      <td>you 're using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>if it is a holiday</td>\n",
       "      <td>if it 's a holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Now you have seen</td>\n",
       "      <td>So now you 've seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>That is particularly true</td>\n",
       "      <td>That 's particularly true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>the ones we are talking about</td>\n",
       "      <td>the ones we 're talking about</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>There is a difference</td>\n",
       "      <td>And surely there 's a difference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>For example , we are</td>\n",
       "      <td>Example : We 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>We will continue</td>\n",
       "      <td>We 'll continue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Do you know what the silver lining here is</td>\n",
       "      <td>What 's the silver lining here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>considering</td>\n",
       "      <td>I 'm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>I would like to</td>\n",
       "      <td>Let 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>you are not</td>\n",
       "      <td>It 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>large</td>\n",
       "      <td>you are n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>so</td>\n",
       "      <td>do n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>others</td>\n",
       "      <td>do n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>right ,</td>\n",
       "      <td>you 'll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>you get started</td>\n",
       "      <td>you 've even gotten started</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431</th>\n",
       "      <td>you do</td>\n",
       "      <td>do n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>they are receiving</td>\n",
       "      <td>you 're giving them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2459</th>\n",
       "      <td>When</td>\n",
       "      <td>do n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>would you not</td>\n",
       "      <td>would n't you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>There</td>\n",
       "      <td>is n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>he is</td>\n",
       "      <td>He 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>let 's</td>\n",
       "      <td>well , let 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>allow us to</td>\n",
       "      <td>let 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>you can not</td>\n",
       "      <td>For the life of you , you just ca n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>They are unfortunately</td>\n",
       "      <td>And , unfortunately , they 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>he would</td>\n",
       "      <td>he 'd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>are unable to obtain</td>\n",
       "      <td>ca n't get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>you should</td>\n",
       "      <td>you 're best to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2953</th>\n",
       "      <td>Do n't</td>\n",
       "      <td>So do n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>that it is</td>\n",
       "      <td>it 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>He is</td>\n",
       "      <td>He 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3034</th>\n",
       "      <td>As</td>\n",
       "      <td>we 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3046</th>\n",
       "      <td>Do you not want</td>\n",
       "      <td>Do n't want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3079</th>\n",
       "      <td>you need</td>\n",
       "      <td>you 've got</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>Make sure to be</td>\n",
       "      <td>Make sure you 're</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>partaking of</td>\n",
       "      <td>that 's</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Original  \\\n",
       "0                                       you have   \n",
       "1                                        You are   \n",
       "4                                        you are   \n",
       "6                                         do not   \n",
       "7                                          It is   \n",
       "8                                      They will   \n",
       "9                                        That is   \n",
       "10                              you are thinking   \n",
       "11                         You will have to give   \n",
       "12                       It is not longer enough   \n",
       "13                          If you do not , then   \n",
       "14                you will be wasting their time   \n",
       "15                              You need to make   \n",
       "16            your audience will not do anything   \n",
       "17                    Do not dilute your message   \n",
       "18                         you have to work hard   \n",
       "19                the only bait we have received   \n",
       "20                                    It is fine   \n",
       "21                         if you are not giving   \n",
       "22                    you should be disappointed   \n",
       "23                            we are at it again   \n",
       "24                     Even if you are confident   \n",
       "25                                 you are using   \n",
       "26                            if it is a holiday   \n",
       "27                             Now you have seen   \n",
       "29                     That is particularly true   \n",
       "30                 the ones we are talking about   \n",
       "31                         There is a difference   \n",
       "32                          For example , we are   \n",
       "33                              We will continue   \n",
       "...                                          ...   \n",
       "2124  Do you know what the silver lining here is   \n",
       "2174                                 considering   \n",
       "2201                             I would like to   \n",
       "2249                                 you are not   \n",
       "2250                                       large   \n",
       "2303                                          so   \n",
       "2316                                      others   \n",
       "2401                                     right ,   \n",
       "2429                             you get started   \n",
       "2431                                      you do   \n",
       "2435                          they are receiving   \n",
       "2459                                        When   \n",
       "2473                               would you not   \n",
       "2500                                       There   \n",
       "2573                                       he is   \n",
       "2610                                      let 's   \n",
       "2625                                 allow us to   \n",
       "2798                                 you can not   \n",
       "2880                      They are unfortunately   \n",
       "2884                                    he would   \n",
       "2897                        are unable to obtain   \n",
       "2908                                  you should   \n",
       "2953                                      Do n't   \n",
       "2955                                  that it is   \n",
       "2968                                       He is   \n",
       "3034                                          As   \n",
       "3046                             Do you not want   \n",
       "3079                                    you need   \n",
       "3112                             Make sure to be   \n",
       "3187                                partaking of   \n",
       "\n",
       "                                            Replacement  \n",
       "0                                               you 've  \n",
       "1                                               You 're  \n",
       "4                                               you 're  \n",
       "6                                                do n't  \n",
       "7                                                 It 's  \n",
       "8                                              They 'll  \n",
       "9                                               That 's  \n",
       "10                                     you 're thinking  \n",
       "11                                  You 've got to give  \n",
       "12                               It 's no longer enough  \n",
       "13                                      If you do n't ,  \n",
       "14                        you 'll be wasting their time  \n",
       "15    You need to make sure that you 're doing every...  \n",
       "16                     your audience wo n't do anything  \n",
       "17                           do n't dilute your message  \n",
       "18                      you 've got to work really hard  \n",
       "19                             the only bait we 've got  \n",
       "20                                           It 's fine  \n",
       "21                                if you 're not giving  \n",
       "22             you 're missing out on a big opportunity  \n",
       "23                                   we 're at it again  \n",
       "24                            Even if you 're confident  \n",
       "25                                        you 're using  \n",
       "26                                   if it 's a holiday  \n",
       "27                                  So now you 've seen  \n",
       "29                            That 's particularly true  \n",
       "30                        the ones we 're talking about  \n",
       "31                     And surely there 's a difference  \n",
       "32                                     Example : We 're  \n",
       "33                                      We 'll continue  \n",
       "...                                                 ...  \n",
       "2124                     What 's the silver lining here  \n",
       "2174                                               I 'm  \n",
       "2201                                             Let 's  \n",
       "2249                                              It 's  \n",
       "2250                                        you are n't  \n",
       "2303                                             do n't  \n",
       "2316                                             do n't  \n",
       "2401                                            you 'll  \n",
       "2429                        you 've even gotten started  \n",
       "2431                                             do n't  \n",
       "2435                                you 're giving them  \n",
       "2459                                             do n't  \n",
       "2473                                      would n't you  \n",
       "2500                                             is n't  \n",
       "2573                                              He 's  \n",
       "2610                                      well , let 's  \n",
       "2625                                             let 's  \n",
       "2798              For the life of you , you just ca n't  \n",
       "2880                     And , unfortunately , they 're  \n",
       "2884                                              he 'd  \n",
       "2897                                         ca n't get  \n",
       "2908                                    you 're best to  \n",
       "2953                                          So do n't  \n",
       "2955                                              it 's  \n",
       "2968                                              He 's  \n",
       "3034                                             we 're  \n",
       "3046                                        Do n't want  \n",
       "3079                                        you 've got  \n",
       "3112                                  Make sure you 're  \n",
       "3187                                            that 's  \n",
       "\n",
       "[397 rows x 2 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.drop_duplicates(subset = ['Original'])\n",
    "df[['Original', 'Replacement']] #NOTE: clean the longer ones later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add POST-padding\n",
    "X_orig = pad_sequences(df['x_orig'], value = pad, padding = 'post').astype('int64')\n",
    "dec_input = pad_sequences(df['dec_input'], value = pad, padding = 'post').astype('int64')\n",
    "dec_target = pad_sequences(df['dec_target'], value = pad, padding = 'post').astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = X.shape[1]\n",
    "\n",
    "orig_len = X_orig.shape[1]\n",
    "assert dec_input.shape[1] == dec_target.shape[1]\n",
    "repl_len = dec_input.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model: find spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          mask_zero = True,\n",
    "                          name = 'embedding_layer')\n",
    "    input_embed = embedding_layer(main_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 128\n",
    "\n",
    "bi_lstm = Bidirectional(LSTM(return_sequences = True, units = num_units), name='bi-lstm')(input_embed)\n",
    "dropout_lstm = Dropout(rate = 0.25, name = 'dropout_lstm')(bi_lstm)\n",
    "dense = TimeDistributed(Dense(num_units, activation = 'relu'), name = 'dense')(dropout_lstm)\n",
    "dropout_dense = Dropout(rate = 0.25, name = 'dropout_dense')(dense)\n",
    "# is timedistributed even needed anymore? dense can handle 3D input now?\n",
    "output = TimeDistributed(Dense(2, activation = 'softmax'), name = 'output')(dropout_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 20, 300)           120000900 \n",
      "_________________________________________________________________\n",
      "bi-lstm (Bidirectional)      (None, 20, 256)           439296    \n",
      "_________________________________________________________________\n",
      "dropout_lstm (Dropout)       (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense (TimeDistributed)      (None, 20, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_dense (Dropout)      (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "output (TimeDistributed)     (None, 20, 2)             258       \n",
      "=================================================================\n",
      "Total params: 120,473,350\n",
      "Trainable params: 472,450\n",
      "Non-trainable params: 120,000,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = main_input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2882/2882 [==============================] - 8s 3ms/step - loss: 0.1896 - binary_accuracy: 0.9252\n",
      "Epoch 2/5\n",
      "2882/2882 [==============================] - 7s 2ms/step - loss: 0.1273 - binary_accuracy: 0.9478\n",
      "Epoch 3/5\n",
      "2882/2882 [==============================] - 7s 2ms/step - loss: 0.1132 - binary_accuracy: 0.9540\n",
      "Epoch 4/5\n",
      "2882/2882 [==============================] - 7s 2ms/step - loss: 0.1057 - binary_accuracy: 0.9573\n",
      "Epoch 5/5\n",
      "2882/2882 [==============================] - 7s 2ms/step - loss: 0.0983 - binary_accuracy: 0.9614\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['binary_accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y):\n",
    "    true = np.argmax(y, axis = 2)\n",
    "    pred = np.argmax(model.predict(X), axis = 2)\n",
    "    total = float(y.shape[0])\n",
    "    total_correct = 0\n",
    "    indiv_wrong = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if (true[i] == pred[i]).all():\n",
    "            total_correct += 1\n",
    "        for j in range(y.shape[1]):\n",
    "            if true[i][j] != pred[i][j]:\n",
    "                indiv_wrong += 1\n",
    "            \n",
    "    print('Absolute accuracy (all correct):\\t\\t' + str(total_correct / total))\n",
    "    \n",
    "    print('Average number of incorrect labels per answer:\\t' + str(indiv_wrong / total))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute accuracy (all correct):\t\t0.5856697819314641\n",
      "Average number of incorrect labels per answer:\t0.9003115264797508\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    pad_X = pad_sequences([X], value = pad, padding = 'post', maxlen = input_len).astype('int64')\n",
    "    pred = np.argmax(model.predict([pad_X], batch_size = 1), axis = 2)\n",
    "    result = ''\n",
    "    for i in range(len(X)):\n",
    "        result += str(pred[0][i]) + '\\t' + idx2w[X[i]] + '\\n'\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tare\n",
      "1\tyou\n",
      "1\tnot\n",
      "0\tgoing\n",
      "0\t?\n",
      "\n",
      "0\tif\n",
      "0\tyou\n",
      "1\tdo\n",
      "1\tnot\n",
      "0\tgo\n",
      "1\ti\n",
      "1\twill\n",
      "1\tnot\n",
      "0\teither\n",
      "0\t.\n",
      "\n",
      "0\tis\n",
      "0\tthat\n",
      "0\tnot\n",
      "0\twhat\n",
      "1\tyou\n",
      "1\twould\n",
      "0\thave\n",
      "0\twanted\n",
      "0\t?\n",
      "\n",
      "0\tis\n",
      "0\tthat\n",
      "0\tnot\n",
      "0\twhat\n",
      "0\tyou\n",
      "0\twould\n",
      "0\twant\n",
      "0\t?\n",
      "\n",
      "0\tis\n",
      "1\tthat\n",
      "1\tnot\n",
      "0\twhat\n",
      "0\tyou\n",
      "0\twanted\n",
      "0\t?\n",
      "\n",
      "1\tyou\n",
      "1\twould\n",
      "0\twant\n",
      "0\tto\n",
      "0\tgo\n",
      "0\t.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(seq_to_idx('Are you not going?'))\n",
    "predict(seq_to_idx('If you do not go I will not either.'))\n",
    "predict(seq_to_idx('Is that not what you would have wanted?'))\n",
    "predict(seq_to_idx('Is that not what you would want?'))\n",
    "predict(seq_to_idx('Is that not what you wanted?'))\n",
    "predict(seq_to_idx('You would want to go.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fragmented neural machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          mask_zero = True,\n",
    "                          name = 'embedding_layer')\n",
    "    orig_embed = embedding_layer(orig_input)\n",
    "    repl_embed = embedding_layer(repl_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "num_units = 128\n",
    "\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_embed)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "# between enc-dec\n",
    "\n",
    "dense = TimeDistributed(Dense(num_units, activation = 'relu'), name = 'dense_layer')\n",
    "dec_tdd = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), name = 'dense_output')\n",
    "\n",
    "dec_dense = dense(dec_output)\n",
    "repl_output = dec_tdd(dec_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "repl_input (InputLayer)         (None, 15)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "orig_input (InputLayer)         (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   orig_input[0][0]                 \n",
      "                                                                 repl_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Bidirectional)         [(None, 256), (None, 439296      embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           encoder[0][1]                    \n",
      "                                                                 encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           encoder[0][2]                    \n",
      "                                                                 encoder[0][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  [(None, 15, 256), (N 570368      embedding_layer[1][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (TimeDistributed)   (None, 15, 128)      32896       decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (TimeDistributed)  (None, 15, 400003)   51600387    dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 172,643,847\n",
      "Trainable params: 52,642,947\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nmt_model = Model(inputs = [orig_input, repl_input], outputs = repl_output)\n",
    "\n",
    "nmt_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "nmt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_generator_train(data, batch_size):\n",
    "    X_orig_whole = data[0]\n",
    "    dec_input_whole = data[1]\n",
    "    dec_target_whole = data[2]\n",
    "    \n",
    "    X_orig_whole, dec_input_whole, dec_target_whole = shuffle(X_orig_whole, \n",
    "                                                              dec_input_whole, \n",
    "                                                              dec_target_whole)\n",
    "    \n",
    "    i = 0\n",
    "            \n",
    "    while True:\n",
    "        if i + batch_size > len(X_orig_whole):\n",
    "            X_orig_batch = X_orig[i:]\n",
    "            dec_input_batch = dec_input_whole[i:]\n",
    "            dec_target_batch = dec_target_whole[i:]\n",
    "            i = 0\n",
    "        else:\n",
    "            X_orig_batch = X_orig[i:i+batch_size]\n",
    "            dec_input_batch = dec_input_whole[i:i+batch_size]\n",
    "            dec_target_batch = dec_target_whole[i:i+batch_size]\n",
    "            i += batch_size\n",
    "        \n",
    "        inputs = [X_orig_batch, dec_input_batch]\n",
    "        targets = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in dec_target_batch])\n",
    "        \n",
    "        yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "24/24 [==============================] - 23s 954ms/step - loss: 9.5759 - acc: 0.2300\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 16s 647ms/step - loss: 4.7253 - acc: 0.2194\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 18s 738ms/step - loss: 4.2192 - acc: 0.2203\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 18s 735ms/step - loss: 4.1565 - acc: 0.2210\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 18s 741ms/step - loss: 4.1485 - acc: 0.2195\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "nmt_history = nmt_model.fit_generator(suggest_generator_train([X_orig, dec_input, dec_target], batch_size),\n",
    "                                  steps_per_epoch=len(X_orig) // batch_size,\n",
    "                                  epochs = 5,\n",
    "                                  verbose = 1)#,\n",
    "                                  #validation_data = (x_val, y_val),\n",
    "                                  #use_multiprocessing = True,\n",
    "                                  #workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference mode for nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# redefine encoder model: takes original input, outputs the states\n",
    "enc_model = Model(inputs = orig_input, outputs = [enc_h, enc_c])\n",
    "\n",
    "# define the states to input into the decoder (this is what you get from the encoder)\n",
    "inf_dec_h_input = Input(shape=(num_units * 2,)) #enc_h\n",
    "inf_dec_c_input = Input(shape=(num_units * 2,)) #enc_c\n",
    "inf_dec_states_input = [inf_dec_h_input, inf_dec_c_input]\n",
    "\n",
    "# these are the outputs you get when you run the decoder, set them up matching the original model\n",
    "# repl_embed is more of a placeholder - of course you won't actually have the answer when you infer\n",
    "inf_dec_main, inf_dec_h, inf_dec_c = decoder(repl_embed, initial_state = inf_dec_states_input)\n",
    "inf_dec_states = [inf_dec_h, inf_dec_c]\n",
    "inf_dec_dense = dense(inf_dec_main)\n",
    "inf_dec_output = dec_tdd(inf_dec_dense)\n",
    "\n",
    "# define decoder model\n",
    "dec_model = Model([repl_input] + inf_dec_states_input, [inf_dec_output] + inf_dec_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_seq):\n",
    "    # takes input sequence in form of seq of token indices\n",
    "    states = enc_model.predict(input_seq)\n",
    "    \n",
    "    # begin output sequence, use start character\n",
    "    target_seq = np.zeros((1, repl_len))\n",
    "    target_seq[0, 0] = w2idx['\\t']\n",
    "    \n",
    "    # using batch_size = 1, sample in a loop\n",
    "    stop = False\n",
    "    decoded = []\n",
    "    while not stop:\n",
    "        output_tok, h, c = dec_model.predict([target_seq] + states)\n",
    "        states = [h, c] # update states\n",
    "        \n",
    "        # sample a token\n",
    "        sample_idx = np.argmax(output_tok[0, -1, :]) # takes the last one in output\n",
    "        sample_tok = idx2w[sample_idx]\n",
    "        \n",
    "        # exit if maxlen is reached or stop character is found\n",
    "        if (sample_tok == '\\n' or len(decoded) > repl_len):\n",
    "            stop = True\n",
    "        else:\n",
    "            # update target_seq\n",
    "            decoded.append(sample_tok)\n",
    "            target_seq = np.zeros((1, repl_len))\n",
    "            target_seq[0, 0] = sample_idx\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'is not'\n",
    "\n",
    "decode(pad_sequences([seq_to_idx(test)], value = pad, padding = 'post', maxlen = orig_len).astype('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do not \n",
      "[]\n",
      "most likely they are \n",
      "[]\n",
      "please \n",
      "[]\n",
      "limb , and \n",
      "[]\n",
      "you get started \n",
      "[]\n",
      "they are clichés \n",
      "[]\n",
      "we will look \n",
      "[]\n",
      "you have \n",
      "[]\n",
      "in addition , it is \n",
      "[]\n",
      "you will learn \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for idx in np.random.choice(len(X_orig), 10):\n",
    "    sent = ''\n",
    "    for x in X_orig[idx]:\n",
    "        if x != 0:\n",
    "            sent += idx2w[x] + ' '\n",
    "    print(sent)\n",
    "    print(decode(np.array([X_orig[idx]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
