{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Concatenate, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('code/data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('code/data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)\n",
    "    \n",
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "# we want to mask_zero, so we need to:\n",
    "# remove 0 key from dict and put its content at the end\n",
    "# replace '' entry in embedding with the 0-key element\n",
    "\n",
    "embedding[embedding.shape[0] - 1] = embedding[0]\n",
    "assert w2idx['the'] == 0\n",
    "w2idx['the'] = embedding.shape[0] - 1\n",
    "del w2idx['']\n",
    "\n",
    "pad = 0\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2w = dict((i, word) for word, i in w2idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import acrolinx blog post dataset - but with contractions only just to test\n",
    "\n",
    "def check_df(string):\n",
    "    # basic check for contractions\n",
    "    item_list = ['have', 'are', 'is', 'not', 'will']\n",
    "    for item in item_list:\n",
    "        if item in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df = pd.read_pickle('code/data/acrolinx_blog/acrolinx_blog_annotated_df.pkl')\n",
    "df = df[df['Original'].apply(lambda x: check_df(x)) == True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "# NOTE: there is word lowering in this because the pretrained word vectors, GloVe, only include\n",
    "# lowercase tokens\n",
    "\n",
    "def seq_to_idx(string):\n",
    "    # turns sequence of tokens to sequence of indices\n",
    "    seq = word_tokenize(string)\n",
    "    idx = []\n",
    "    for word in seq:\n",
    "        word = word.lower()\n",
    "        if word in w2idx:\n",
    "            idx.append(w2idx[word])\n",
    "        #else: #unknown tokens?\n",
    "    return idx\n",
    "\n",
    "def make_span(start, end, seq_len):\n",
    "    # takes start and end of span and returns 0/1 output for the given sequence length\n",
    "    new = [0] * seq_len\n",
    "    new[start : end] = [1] * (end - start)\n",
    "    return new\n",
    "\n",
    "def reduce_fragments(orig, repl):\n",
    "    # removes repeated sections of original and replacement texts (e.g. minimizes length)\n",
    "    # unless it would make one of the sections empty\n",
    "    \n",
    "    # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to these\n",
    "    # this, the replacement/target text, will be used in the decoder step of training only\n",
    "    \n",
    "    return orig, repl\n",
    "\n",
    "def preprocess(df):\n",
    "    x_token = []\n",
    "    span = []\n",
    "    dec_input = []\n",
    "    dec_target = []\n",
    "    y_repl = []\n",
    "    x_orig = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        \n",
    "        # Converting sentence strings to lists of indices.\n",
    "        sent = seq_to_idx(row['Sentence'])\n",
    "        orig = seq_to_idx(row['Original'])\n",
    "        repl = seq_to_idx(row['Replacement'])\n",
    "        \n",
    "        if len(sent) == 0 or len(orig) == 0 or len(repl) == 0:\n",
    "            x_token.append(np.nan)\n",
    "            span.append(np.nan)\n",
    "            y_repl.append(np.nan)\n",
    "            dec_input.append(np.nan)\n",
    "            dec_target.append(np.nan)\n",
    "            x_orig.append(np.nan)\n",
    "            print('Empty sentence or fragment: ' + row['Sentence'])\n",
    "            continue\n",
    "            \n",
    "        x_token.append(sent)\n",
    "        x_orig.append(orig)\n",
    "        dec_input.append([w2idx['\\t']] + repl)\n",
    "        dec_target.append(repl + [w2idx['\\n']])\n",
    "        y_repl.append(repl)\n",
    "                \n",
    "        # take indices and find the 1st occurrence of the slice in the whole sentence\n",
    "        starts = [i for i, x in enumerate(sent) if x == orig[0]]\n",
    "        current_span = []\n",
    "        y_s = np.nan\n",
    "        y_e = np.nan\n",
    "        for potential_start in starts:\n",
    "            potential_slice = sent[potential_start : potential_start + len(orig)]\n",
    "            if (potential_slice == np.array(orig)).all():\n",
    "                y_s = potential_start\n",
    "                y_e = potential_start + len(orig) + 1\n",
    "                break\n",
    "        if np.isnan(y_s) or np.isnan(y_e):\n",
    "            print('Original not found in sentence.')\n",
    "            print(row['Sentence'])\n",
    "            print(row['Original'])\n",
    "            span.append(np.nan)\n",
    "        else:\n",
    "            span.append(make_span(int(y_s), int(y_e - 1), len(sent)))\n",
    "                \n",
    "    df['x_token'] = x_token\n",
    "    df['span'] = span\n",
    "    df['dec_input'] = dec_input\n",
    "    df['dec_target'] = dec_target\n",
    "    df['y_repl'] = y_repl\n",
    "    df['x_orig'] = x_orig\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edbf7cbc4674d07b0d17d3961bb017e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3164), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "df = df.dropna()\n",
    "#df = df.drop_duplicates(subset = ['Original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>x_token</th>\n",
       "      <th>span</th>\n",
       "      <th>dec_input</th>\n",
       "      <th>dec_target</th>\n",
       "      <th>y_repl</th>\n",
       "      <th>x_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Beware and be careful .</td>\n",
       "      <td>Beware and be careful .</td>\n",
       "      <td>Beware !</td>\n",
       "      <td>[22056, 5, 30, 5604, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>[400001, 22056, 805]</td>\n",
       "      <td>[22056, 805, 400002]</td>\n",
       "      <td>[22056, 805]</td>\n",
       "      <td>[22056, 5, 30, 5604, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Because it is your customers , and not you , w...</td>\n",
       "      <td>Because it is your</td>\n",
       "      <td>Since it 's your</td>\n",
       "      <td>[113, 20, 14, 392, 1661, 1, 5, 36, 81, 1, 38, ...</td>\n",
       "      <td>[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 108, 20, 9, 392]</td>\n",
       "      <td>[108, 20, 9, 392, 400002]</td>\n",
       "      <td>[108, 20, 9, 392]</td>\n",
       "      <td>[113, 20, 14, 392]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>If you can answer yes to all of them , you wil...</td>\n",
       "      <td>you will</td>\n",
       "      <td>you 'll</td>\n",
       "      <td>[83, 81, 86, 2168, 2772, 4, 64, 3, 101, 1, 81,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 81, 769]</td>\n",
       "      <td>[81, 769, 400002]</td>\n",
       "      <td>[81, 769]</td>\n",
       "      <td>[81, 43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>If you do not want to get left behind , you ne...</td>\n",
       "      <td>If you do not want</td>\n",
       "      <td>If you do n't want</td>\n",
       "      <td>[83, 81, 88, 36, 303, 4, 169, 218, 561, 1, 81,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 83, 81, 88, 70, 303]</td>\n",
       "      <td>[83, 81, 88, 70, 303, 400002]</td>\n",
       "      <td>[83, 81, 88, 70, 303]</td>\n",
       "      <td>[83, 81, 88, 36, 303]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>They are all great resources that we have foun...</td>\n",
       "      <td>we have found</td>\n",
       "      <td>we 've found</td>\n",
       "      <td>[39, 32, 64, 353, 1540, 12, 53, 33, 238, 191, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 53, 462, 238]</td>\n",
       "      <td>[53, 462, 238, 400002]</td>\n",
       "      <td>[53, 462, 238]</td>\n",
       "      <td>[53, 33, 238]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  \\\n",
       "211                            Beware and be careful .   \n",
       "130  Because it is your customers , and not you , w...   \n",
       "197  If you can answer yes to all of them , you wil...   \n",
       "153  If you do not want to get left behind , you ne...   \n",
       "44   They are all great resources that we have foun...   \n",
       "\n",
       "                    Original         Replacement  \\\n",
       "211  Beware and be careful .            Beware !   \n",
       "130       Because it is your    Since it 's your   \n",
       "197                 you will             you 'll   \n",
       "153       If you do not want  If you do n't want   \n",
       "44             we have found        we 've found   \n",
       "\n",
       "                                               x_token  \\\n",
       "211                            [22056, 5, 30, 5604, 2]   \n",
       "130  [113, 20, 14, 392, 1661, 1, 5, 36, 81, 1, 38, ...   \n",
       "197  [83, 81, 86, 2168, 2772, 4, 64, 3, 101, 1, 81,...   \n",
       "153  [83, 81, 88, 36, 303, 4, 169, 218, 561, 1, 81,...   \n",
       "44   [39, 32, 64, 353, 1540, 12, 53, 33, 238, 191, ...   \n",
       "\n",
       "                                                  span  \\\n",
       "211                                    [1, 1, 1, 1, 1]   \n",
       "130  [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "197  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, ...   \n",
       "153  [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "44   [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                         dec_input                     dec_target  \\\n",
       "211           [400001, 22056, 805]           [22056, 805, 400002]   \n",
       "130      [400001, 108, 20, 9, 392]      [108, 20, 9, 392, 400002]   \n",
       "197              [400001, 81, 769]              [81, 769, 400002]   \n",
       "153  [400001, 83, 81, 88, 70, 303]  [83, 81, 88, 70, 303, 400002]   \n",
       "44          [400001, 53, 462, 238]         [53, 462, 238, 400002]   \n",
       "\n",
       "                    y_repl                   x_orig  \n",
       "211           [22056, 805]  [22056, 5, 30, 5604, 2]  \n",
       "130      [108, 20, 9, 392]       [113, 20, 14, 392]  \n",
       "197              [81, 769]                 [81, 43]  \n",
       "153  [83, 81, 88, 70, 303]    [83, 81, 88, 36, 303]  \n",
       "44          [53, 462, 238]            [53, 33, 238]  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5) #NOTE: clean the longer ones later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add POST-padding\n",
    "\n",
    "X = pad_sequences(df['x_token'], maxlen = 20, value = pad, padding = 'post').astype('int64')\n",
    "y_span = pad_sequences(df['span'], maxlen = 20, value = 0, padding = 'post').astype('int64')\n",
    "X_orig = pad_sequences(df['x_orig'], value = pad, padding = 'post').astype('int64')\n",
    "dec_input = pad_sequences(df['dec_input'], value = pad, padding = 'post').astype('int64')\n",
    "dec_target = pad_sequences(df['dec_target'], value = pad, padding = 'post').astype('int64')\n",
    "\n",
    "y_span_cat = np.zeros((y_span.shape[0], y_span.shape[1], 2))\n",
    "for idx_1 in range(y_span.shape[0]):\n",
    "    for idx_2 in range(y_span.shape[1]):\n",
    "        y_span_cat[idx_1][idx_2] = to_categorical(y_span[idx_1][idx_2], num_classes = 2)\n",
    "\n",
    "# set up target data from output sequence, 1 timestep off from y_repl\n",
    "#y_repl_cat = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in y_repl]) \n",
    "\n",
    "input_len = X.shape[1]\n",
    "\n",
    "orig_len = X_orig.shape[1]\n",
    "assert dec_input.shape[1] == dec_target.shape[1]\n",
    "repl_len = dec_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_span_cat, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model: find spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          mask_zero = True,\n",
    "                          name = 'embedding_layer')\n",
    "    input_embed = embedding_layer(main_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_units = 128\n",
    "\n",
    "bi_lstm = Bidirectional(LSTM(return_sequences = True, units = num_units), name='bi-lstm')(input_embed)\n",
    "dropout_lstm = Dropout(rate = 0.25, name = 'dropout_lstm')(bi_lstm)\n",
    "dense = TimeDistributed(Dense(num_units, activation = 'relu'), name = 'dense')(dropout_lstm)\n",
    "dropout_dense = Dropout(rate = 0.25, name = 'dropout_dense')(dense)\n",
    "# is timedistributed even needed anymore? dense can handle 3D input now?\n",
    "output = TimeDistributed(Dense(2, activation = 'softmax'), name = 'output')(dropout_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 20, 300)           120000900 \n",
      "_________________________________________________________________\n",
      "bi-lstm (Bidirectional)      (None, 20, 256)           439296    \n",
      "_________________________________________________________________\n",
      "dropout_lstm (Dropout)       (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense (TimeDistributed)      (None, 20, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_dense (Dropout)      (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "output (TimeDistributed)     (None, 20, 2)             258       \n",
      "=================================================================\n",
      "Total params: 120,473,350\n",
      "Trainable params: 472,450\n",
      "Non-trainable params: 120,000,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = main_input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2847/2847 [==============================] - 7s 2ms/step - loss: 0.2068 - binary_accuracy: 0.9201\n",
      "Epoch 2/5\n",
      "2847/2847 [==============================] - 5s 2ms/step - loss: 0.1288 - binary_accuracy: 0.9480\n",
      "Epoch 3/5\n",
      "2847/2847 [==============================] - 5s 2ms/step - loss: 0.1136 - binary_accuracy: 0.9541\n",
      "Epoch 4/5\n",
      "2847/2847 [==============================] - 5s 2ms/step - loss: 0.1058 - binary_accuracy: 0.9581\n",
      "Epoch 5/5\n",
      "2847/2847 [==============================] - 5s 2ms/step - loss: 0.0995 - binary_accuracy: 0.9606\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['binary_accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y):\n",
    "    true = np.argmax(y, axis = 2)\n",
    "    pred = np.argmax(model.predict(X), axis = 2)\n",
    "    total = float(y.shape[0])\n",
    "    total_correct = 0\n",
    "    indiv_wrong = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if (true[i] == pred[i]).all():\n",
    "            total_correct += 1\n",
    "        for j in range(y.shape[1]):\n",
    "            if true[i][j] != pred[i][j]:\n",
    "                indiv_wrong += 1\n",
    "            \n",
    "    print('Absolute accuracy (all correct):\\t\\t' + str(total_correct / total))\n",
    "    \n",
    "    print('Average number of incorrect labels per answer:\\t' + str(indiv_wrong / total))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute accuracy (all correct):\t\t0.6277602523659306\n",
      "Average number of incorrect labels per answer:\t0.7886435331230284\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    pad_X = pad_sequences([X], value = pad, padding = 'post', maxlen = input_len).astype('int64')\n",
    "    pred = np.argmax(model.predict([pad_X], batch_size = 1), axis = 2)\n",
    "    result = ''\n",
    "    for i in range(len(X)):\n",
    "        result += str(pred[0][i]) + '\\t' + idx2w[X[i]] + '\\n'\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tare\n",
      "1\tyou\n",
      "1\tnot\n",
      "0\tgoing\n",
      "0\t?\n",
      "\n",
      "0\tif\n",
      "0\tyou\n",
      "1\tdo\n",
      "0\tnot\n",
      "0\tgo\n",
      "1\ti\n",
      "1\twill\n",
      "1\tnot\n",
      "0\teither\n",
      "0\t.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(seq_to_idx('Are you not going?'))\n",
    "predict(seq_to_idx('If you do not go I will not either.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: turning binary output to slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          mask_zero = True,\n",
    "                          name = 'embedding_layer')\n",
    "    orig_embed = embedding_layer(orig_input)\n",
    "    repl_embed = embedding_layer(repl_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "num_units = 128\n",
    "\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_embed)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "# between enc-dec\n",
    "\n",
    "dense = TimeDistributed(Dense(num_units, activation = 'relu'), name = 'dense_layer')\n",
    "dec_tdd = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), name = 'dense_output')\n",
    "\n",
    "dec_dense = dense(dec_output)\n",
    "repl_output = dec_tdd(dec_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "repl_input (InputLayer)         (None, 11)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "orig_input (InputLayer)         (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   orig_input[0][0]                 \n",
      "                                                                 repl_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Bidirectional)         [(None, 256), (None, 439296      embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           encoder[0][1]                    \n",
      "                                                                 encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           encoder[0][2]                    \n",
      "                                                                 encoder[0][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  [(None, 11, 256), (N 570368      embedding_layer[1][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (TimeDistributed)   (None, 11, 128)      32896       decoder[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (TimeDistributed)  (None, 11, 400003)   51600387    dense_layer[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 172,643,847\n",
      "Trainable params: 52,642,947\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nmt_model = Model(inputs = [orig_input, repl_input], outputs = repl_output)\n",
    "\n",
    "nmt_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "nmt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest_generator_train(data, batch_size):\n",
    "    X_orig_whole = data[0]\n",
    "    dec_input_whole = data[1]\n",
    "    dec_target_whole = data[2]\n",
    "    \n",
    "    X_orig_whole, dec_input_whole, dec_target_whole = shuffle(X_orig_whole, \n",
    "                                                              dec_input_whole, \n",
    "                                                              dec_target_whole)\n",
    "    \n",
    "    i = 0\n",
    "            \n",
    "    while True:\n",
    "        if i + batch_size > len(X_orig_whole):\n",
    "            X_orig_batch = X_orig[i:]\n",
    "            dec_input_batch = dec_input_whole[i:]\n",
    "            dec_target_batch = dec_target_whole[i:]\n",
    "            i = 0\n",
    "        else:\n",
    "            X_orig_batch = X_orig[i:i+batch_size]\n",
    "            dec_input_batch = dec_input_whole[i:i+batch_size]\n",
    "            dec_target_batch = dec_target_whole[i:i+batch_size]\n",
    "            i += batch_size\n",
    "        \n",
    "        inputs = [X_orig_batch, dec_input_batch]\n",
    "        targets = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in dec_target_batch])\n",
    "        \n",
    "        yield inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "24/24 [==============================] - 19s 793ms/step - loss: 9.7013 - acc: 0.2233\n",
      "Epoch 2/7\n",
      "24/24 [==============================] - 14s 572ms/step - loss: 5.0305 - acc: 0.2241\n",
      "Epoch 3/7\n",
      "24/24 [==============================] - 13s 557ms/step - loss: 4.5299 - acc: 0.2235\n",
      "Epoch 4/7\n",
      "24/24 [==============================] - 13s 543ms/step - loss: 4.3973 - acc: 0.2241\n",
      "Epoch 5/7\n",
      "24/24 [==============================] - 13s 545ms/step - loss: 4.3515 - acc: 0.2251\n",
      "Epoch 6/7\n",
      "24/24 [==============================] - 13s 540ms/step - loss: 4.3245 - acc: 0.2443\n",
      "Epoch 7/7\n",
      "24/24 [==============================] - 13s 540ms/step - loss: 4.2610 - acc: 0.2601\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "nmt_history = nmt_model.fit_generator(suggest_generator_train([X_orig, dec_input, dec_target], batch_size),\n",
    "                                  steps_per_epoch=len(X_orig) // batch_size,\n",
    "                                  epochs = 5,\n",
    "                                  verbose = 1)#,\n",
    "                                  #validation_data = (x_val, y_val),\n",
    "                                  #use_multiprocessing = True,\n",
    "                                  #workers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference mode for nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# redefine encoder model: takes original input, outputs the states\n",
    "enc_model = Model(inputs = orig_input, outputs = [enc_h, enc_c])\n",
    "\n",
    "# define the states to input into the decoder (this is what you get from the encoder)\n",
    "inf_dec_h_input = Input(shape=(num_units * 2,)) #enc_h\n",
    "inf_dec_c_input = Input(shape=(num_units * 2,)) #enc_c\n",
    "inf_dec_states_input = [inf_dec_h_input, inf_dec_c_input]\n",
    "\n",
    "# these are the outputs you get when you run the decoder, set them up matching the original model\n",
    "# repl_embed is more of a placeholder - of course you won't actually have the answer when you infer\n",
    "inf_dec_main, inf_dec_h, inf_dec_c = decoder(repl_embed, initial_state = inf_dec_states_input)\n",
    "inf_dec_states = [inf_dec_h, inf_dec_c]\n",
    "inf_dec_dense = dense(inf_dec_main)\n",
    "inf_dec_output = dec_tdd(inf_dec_dense)\n",
    "\n",
    "# define decoder model\n",
    "dec_model = Model([repl_input] + inf_dec_states_input, [inf_dec_output] + inf_dec_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_seq):\n",
    "    # takes input sequence in form of seq of token indices\n",
    "    states = enc_model.predict(input_seq)\n",
    "    \n",
    "    # begin output sequence, use start character\n",
    "    target_seq = np.zeros((1, repl_len))\n",
    "    target_seq[0, 0] = w2idx['\\t']\n",
    "    \n",
    "    # using batch_size = 1, sample in a loop\n",
    "    stop = False\n",
    "    decoded = []\n",
    "    while not stop:\n",
    "        output_tok, h, c = dec_model.predict([target_seq] + states)\n",
    "        states = [h, c] # update states\n",
    "        \n",
    "        # sample a token\n",
    "        sample_idx = np.argmax(output_tok[0, -1, :]) # takes the last one in output\n",
    "        sample_tok = idx2w[sample_idx]\n",
    "        \n",
    "        # exit if maxlen is reached or stop character is found\n",
    "        if (sample_tok == '\\n' or len(decoded) > repl_len):\n",
    "            stop = True\n",
    "        else:\n",
    "            # update target_seq\n",
    "            decoded.append(sample_tok)\n",
    "            target_seq = np.zeros((1, repl_len))\n",
    "            target_seq[0, 0] = sample_idx\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = 'is not'\n",
    "\n",
    "decode(pad_sequences([seq_to_idx(test)], value = pad, padding = 'post', maxlen = orig_len).astype('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that is easy \n",
      "['you']\n",
      "would you not \n",
      "['you']\n",
      "can not always be easy \n",
      "['you']\n",
      "we have shared \n",
      "['you']\n",
      "discussing \n",
      "['you']\n",
      ". it is \n",
      "['you']\n",
      "your audience will not do anything \n",
      "['you']\n",
      "they have \n",
      "['you']\n",
      "they are unfortunately \n",
      "['you']\n",
      "they are \n",
      "['you']\n"
     ]
    }
   ],
   "source": [
    "for idx in np.random.choice(len(X_orig), 10):\n",
    "    sent = ''\n",
    "    for x in X_orig[idx]:\n",
    "        if x != 0:\n",
    "            sent += idx2w[x] + ' '\n",
    "    print(sent)\n",
    "    print(decode(np.array([X_orig[idx]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
