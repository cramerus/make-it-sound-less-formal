{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from nltk import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Concatenate, TimeDistributed\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries, pretrained embeddings\n",
    "with open('data/glv_w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "with open('data/glv_embed_matrix.pkl', 'rb') as f:\n",
    "    embedding = pickle.load(f)\n",
    "    \n",
    "# need to append BOS ('\\t') and EOS ('\\n') tokens to embeddings\n",
    "# give (consistently) random initialization since they don't actually mean anything\n",
    "# padding already exists as '' at the end of the embedding\n",
    "\n",
    "pad = len(w2idx) - 1\n",
    "\n",
    "w2idx['\\t'] = embedding.shape[0]\n",
    "np.random.seed(1)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)\n",
    "\n",
    "w2idx['\\n'] = embedding.shape[0]\n",
    "np.random.seed(2)\n",
    "embedding = np.append(embedding, np.random.rand(1, 300), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2w = dict((i, word) for word, i in w2idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import acrolinx blog post dataset - but with contractions only just to test\n",
    "\n",
    "def check_df(string):\n",
    "    # basic check for contractions\n",
    "    item_list = ['have', 'are', 'is', 'not', 'will']\n",
    "    for item in item_list:\n",
    "        if item in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "df = pd.read_pickle('data/acrolinx_blog/acrolinx_blog_annotated_df.pkl')\n",
    "df = df[df['Original'].apply(lambda x: check_df(x)) == True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# change from text to indices\n",
    "\n",
    "# NOTE: there is word lowering in this because the pretrained word vectors, GloVe, only include\n",
    "# lowercase tokens\n",
    "\n",
    "def seq_to_idx(string):\n",
    "    # turns sequence of tokens to sequence of indices\n",
    "    seq = word_tokenize(string)\n",
    "    idx = []\n",
    "    for word in seq:\n",
    "        word = word.lower()\n",
    "        if word in w2idx:\n",
    "            idx.append(w2idx[word])\n",
    "        #else: #unknown tokens?\n",
    "    return idx\n",
    "\n",
    "def make_span(start, end, seq_len):\n",
    "    # takes start and end of span and returns 0/1 output for the given sequence length\n",
    "    new = [0] * seq_len\n",
    "    new[start : end] = [1] * (end - start)\n",
    "    return new\n",
    "\n",
    "def reduce_fragments(orig, repl):\n",
    "    # removes repeated sections of original and replacement texts (e.g. minimizes length)\n",
    "    # unless it would make one of the sections empty\n",
    "    \n",
    "    # add start-of-sequence ('\\t') and end-of-sequence ('\\n') markers to these\n",
    "    # this, the replacement/target text, will be used in the decoder step of training only\n",
    "    \n",
    "    return orig, repl\n",
    "\n",
    "def preprocess(df):\n",
    "    x_token = []\n",
    "    span = []\n",
    "    y_repl = []\n",
    "    x_orig = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        \n",
    "        # Converting sentence strings to lists of indices.\n",
    "        sent = seq_to_idx(row['Sentence'])\n",
    "        orig = seq_to_idx(row['Original'])\n",
    "        repl = seq_to_idx(row['Replacement'])\n",
    "        \n",
    "        if len(sent) == 0 or len(orig) == 0 or len(repl) == 0:\n",
    "            x_token.append(np.nan)\n",
    "            span.append(np.nan)\n",
    "            y_repl.append(np.nan)\n",
    "            x_orig.append(np.nan)\n",
    "            print('Empty sentence or fragment: ' + row['Sentence'])\n",
    "            continue\n",
    "            \n",
    "        x_token.append(sent)\n",
    "        x_orig.append(orig)\n",
    "        y_repl.append([w2idx['\\t']] + repl + [w2idx['\\n']])\n",
    "                \n",
    "        # take indices and find the 1st occurrence of the slice in the whole sentence\n",
    "        starts = [i for i, x in enumerate(sent) if x == orig[0]]\n",
    "        current_span = []\n",
    "        y_s = np.nan\n",
    "        y_e = np.nan\n",
    "        for potential_start in starts:\n",
    "            potential_slice = sent[potential_start : potential_start + len(orig)]\n",
    "            if (potential_slice == np.array(orig)).all():\n",
    "                y_s = potential_start\n",
    "                y_e = potential_start + len(orig) + 1\n",
    "                break\n",
    "        if np.isnan(y_s) or np.isnan(y_e):\n",
    "            print('Original not found in sentence.')\n",
    "            print(row['Sentence'])\n",
    "            print(row['Original'])\n",
    "            span.append(np.nan)\n",
    "        else:\n",
    "            span.append(make_span(int(y_s), int(y_e - 1), len(sent)))\n",
    "                \n",
    "    df['x_token'] = x_token\n",
    "    df['span'] = span\n",
    "    df['y_repl'] = y_repl\n",
    "    df['x_orig'] = x_orig\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8f74adc7764bc9a89a7ea4c5908a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3169), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original not found in sentence.\n",
      "Now you have seen all of the problem words that we have collectedd .\n",
      "that we have collected\n",
      "Original not found in sentence.\n",
      "It does not mean… We 're rigid or uptight .\n",
      "It does not mean\n",
      "Original not found in sentence.\n",
      "It is a great event and one that you should definitely check out if you have not't before ( by the way , you can still register for it by clicking here ) .\n",
      "have not\n",
      "Original not found in sentence.\n",
      "Thmay be conference is all about being smarter with your content — whether you 're a marketer or in tech docs — and following the lead of pioneering companies such as Google , IBM , and Cisco Systems .\n",
      "This\n",
      "Empty sentence or fragment: Yes , , that may not a issue for you , but it should be an early warning sign that the company you are dealing with might not be as polished or professional as you 'd expect .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = preprocess(df)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Original</th>\n",
       "      <th>Replacement</th>\n",
       "      <th>x_token</th>\n",
       "      <th>span</th>\n",
       "      <th>y_repl</th>\n",
       "      <th>x_orig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>If you do not embrace most of them , you will ...</td>\n",
       "      <td>do not</td>\n",
       "      <td>do n't</td>\n",
       "      <td>[83, 81, 88, 36, 7444, 96, 3, 101, 1, 81, 43, ...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 88, 70, 400002]</td>\n",
       "      <td>[88, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>It is fine to be creative , but do not dial up...</td>\n",
       "      <td>do not</td>\n",
       "      <td>do n't</td>\n",
       "      <td>[20, 14, 1695, 4, 30, 4069, 1, 34, 88, 36, 125...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 88, 70, 400002]</td>\n",
       "      <td>[88, 36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>Not all music will do this , but scientists ha...</td>\n",
       "      <td>you are</td>\n",
       "      <td>you 're</td>\n",
       "      <td>[36, 64, 403, 43, 88, 37, 1, 34, 2154, 33, 238...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 81, 267, 400002]</td>\n",
       "      <td>[81, 32]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>You have always got to create your content wit...</td>\n",
       "      <td>You have</td>\n",
       "      <td>You 've</td>\n",
       "      <td>[81, 33, 690, 405, 4, 1210, 392, 2768, 17, 7, ...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 81, 462, 400002]</td>\n",
       "      <td>[81, 33]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>With so many options , it is easy to get distr...</td>\n",
       "      <td>it is</td>\n",
       "      <td>it 's</td>\n",
       "      <td>[17, 100, 109, 2780, 1, 20, 14, 1673, 4, 169, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[400001, 20, 9, 400002]</td>\n",
       "      <td>[20, 14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Original Replacement  \\\n",
       "752   If you do not embrace most of them , you will ...    do not      do n't   \n",
       "2916  It is fine to be creative , but do not dial up...    do not      do n't   \n",
       "2795  Not all music will do this , but scientists ha...   you are     you 're   \n",
       "343   You have always got to create your content wit...  You have     You 've   \n",
       "282   With so many options , it is easy to get distr...     it is       it 's   \n",
       "\n",
       "                                                x_token  \\\n",
       "752   [83, 81, 88, 36, 7444, 96, 3, 101, 1, 81, 43, ...   \n",
       "2916  [20, 14, 1695, 4, 30, 4069, 1, 34, 88, 36, 125...   \n",
       "2795  [36, 64, 403, 43, 88, 37, 1, 34, 2154, 33, 238...   \n",
       "343   [81, 33, 690, 405, 4, 1210, 392, 2768, 17, 7, ...   \n",
       "282   [17, 100, 109, 2780, 1, 20, 14, 1673, 4, 169, ...   \n",
       "\n",
       "                                                   span  \\\n",
       "752   [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2916  [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, ...   \n",
       "2795  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "343   [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "282   [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                         y_repl    x_orig  \n",
       "752    [400001, 88, 70, 400002]  [88, 36]  \n",
       "2916   [400001, 88, 70, 400002]  [88, 36]  \n",
       "2795  [400001, 81, 267, 400002]  [81, 32]  \n",
       "343   [400001, 81, 462, 400002]  [81, 33]  \n",
       "282     [400001, 20, 9, 400002]  [20, 14]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5) #NOTE: clean the longer ones later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data to arrays from df, add POST-padding\n",
    "\n",
    "X = pad_sequences(df['x_token'], maxlen = 20, value = pad, padding = 'post').astype('int64')\n",
    "y_span = pad_sequences(df['span'], maxlen = 20, value = 0, padding = 'post').astype('int64')\n",
    "X_orig = pad_sequences(df['x_orig'], value = pad, padding = 'post').astype('int64')\n",
    "y_repl = pad_sequences(df['y_repl'], value = pad, padding = 'post').astype('int64')\n",
    "\n",
    "y_span_cat = np.zeros((y_span.shape[0], y_span.shape[1], 2))\n",
    "for idx_1 in range(y_span.shape[0]):\n",
    "    for idx_2 in range(y_span.shape[1]):\n",
    "        y_span_cat[idx_1][idx_2] = to_categorical(y_span[idx_1][idx_2], num_classes = 2)\n",
    "\n",
    "# set up target data from output sequence, 1 timestep off from y_repl\n",
    "y_repl_cat = np.array([to_categorical(x, num_classes = embedding.shape[0]) for x in y_repl]) \n",
    "\n",
    "input_len = X.shape[1]\n",
    "orig_len = X_orig.shape[1]\n",
    "repl_len = y_repl.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_span_cat, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model: find spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "main_input = Input(shape = (input_len,), dtype = 'int64', name = 'main_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          name = 'embedding_layer')\n",
    "    input_embed = embedding_layer(main_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/users/rcramerus/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "num_units = 128\n",
    "\n",
    "bi_lstm = Bidirectional(LSTM(return_sequences = True, units = num_units), name='bi-lstm')(input_embed)\n",
    "dropout = Dropout(rate = 0.25)(bi_lstm)\n",
    "output = Dense(2, activation='softmax')(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "main_input (InputLayer)      (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "embedding_layer (Embedding)  (None, 20, 300)           120000900 \n",
      "_________________________________________________________________\n",
      "bi-lstm (Bidirectional)      (None, 20, 256)           439296    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20, 2)             514       \n",
      "=================================================================\n",
      "Total params: 120,440,710\n",
      "Trainable params: 439,810\n",
      "Non-trainable params: 120,000,900\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = main_input, outputs = output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/5\n",
      "2847/2847 [==============================] - 11s 4ms/step - loss: 0.1715 - binary_accuracy: 0.9379\n",
      "Epoch 2/5\n",
      "2847/2847 [==============================] - 8s 3ms/step - loss: 0.1112 - binary_accuracy: 0.9558\n",
      "Epoch 3/5\n",
      "2847/2847 [==============================] - 8s 3ms/step - loss: 0.1006 - binary_accuracy: 0.9600\n",
      "Epoch 4/5\n",
      "2847/2847 [==============================] - 8s 3ms/step - loss: 0.0941 - binary_accuracy: 0.9627\n",
      "Epoch 5/5\n",
      "2847/2847 [==============================] - 8s 3ms/step - loss: 0.0883 - binary_accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['binary_accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs = 5, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y):\n",
    "    true = np.argmax(y, axis = 2)\n",
    "    pred = np.argmax(model.predict(X), axis = 2)\n",
    "    total = float(y.shape[0])\n",
    "    total_correct = 0\n",
    "    indiv_wrong = 0\n",
    "    for i in range(y.shape[0]):\n",
    "        if (true[i] == pred[i]).all():\n",
    "            total_correct += 1\n",
    "        for j in range(y.shape[1]):\n",
    "            if true[i][j] != pred[i][j]:\n",
    "                indiv_wrong += 1\n",
    "            \n",
    "    print('Absolute accuracy (all correct):\\t\\t' + str(total_correct / total))\n",
    "    \n",
    "    print('Average number of incorrect labels per answer:\\t' + str(indiv_wrong / total))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute accuracy (all correct):\t\t0.61198738170347\n",
      "Average number of incorrect labels per answer:\t0.8201892744479495\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    pad_X = pad_sequences([X], value = pad, padding = 'post', maxlen = input_len).astype('int64')\n",
    "    pred = np.argmax(model.predict([pad_X], batch_size = 1), axis = 2)\n",
    "    result = ''\n",
    "    for i in range(len(X)):\n",
    "        result += str(pred[0][i]) + '\\t' + idx2w[X[i]] + '\\n'\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tdo\n",
      "1\tyou\n",
      "1\thave\n",
      "0\ta\n",
      "0\tmoment\n",
      "0\t?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(seq_to_idx('Do you have a moment?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 2: turning binary output to slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# step 3: nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "orig_input = Input(shape = (orig_len,), dtype = 'int64', name = 'orig_input')\n",
    "repl_input = Input(shape = (repl_len,), dtype = 'int64', name = 'repl_input')\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # note for later: can use mask_zero parameter in embedding layer, but would need to go back and change some indices\n",
    "    embedding_layer = Embedding(input_dim = embedding.shape[0],\n",
    "                          output_dim = embedding.shape[1],\n",
    "                          weights = [embedding],\n",
    "                          trainable = False, \n",
    "                          name = 'embedding_layer')\n",
    "    orig_embed = embedding_layer(orig_input)\n",
    "    repl_embed = embedding_layer(repl_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### feed encoder input (main_input), decoder input (repl_input) and sliced replacement text to enc-dec system\n",
    "\n",
    "# these should change later to some sort of context-based or conditional model\n",
    "# also with attention\n",
    "\n",
    "# decoder given 2*units to accept bidirectional outputs\n",
    "num_units = 128\n",
    "\n",
    "encoder = Bidirectional(LSTM(return_state = True, units = num_units), name = \"encoder\")\n",
    "decoder = LSTM(return_sequences = True, return_state = True, name = \"decoder\", units = 2 * num_units)\n",
    "\n",
    "# sequence is unnecessary for the encoder - just states, to start the decoder correctly\n",
    "# state and sequence for decoder will be necessary in inference, but not right now\n",
    "enc_output, enc_h_forward, enc_c_forward, enc_h_backward, enc_c_backward = encoder(orig_embed)\n",
    "enc_h = Concatenate()([enc_h_forward, enc_h_backward])\n",
    "enc_c = Concatenate()([enc_c_forward, enc_c_backward])\n",
    "dec_output, _, _ = decoder(repl_embed, initial_state = [enc_h, enc_c])\n",
    "\n",
    "# Dropout?\n",
    "\n",
    "dec_tdd = TimeDistributed(Dense(embedding.shape[0], activation='softmax'), name = 'dense_output')\n",
    "repl_output = dec_tdd(dec_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "repl_input (InputLayer)         (None, 12)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "orig_input (InputLayer)         (None, 9)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_layer (Embedding)     multiple             120000900   orig_input[0][0]                 \n",
      "                                                                 repl_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Bidirectional)         [(None, 256), (None, 439296      embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           encoder[0][1]                    \n",
      "                                                                 encoder[0][3]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           encoder[0][2]                    \n",
      "                                                                 encoder[0][4]                    \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  [(None, 12, 256), (N 570368      embedding_layer[1][0]            \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_output (TimeDistributed)  (None, 12, 400003)   102800771   decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 223,811,335\n",
      "Trainable params: 103,810,435\n",
      "Non-trainable params: 120,000,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nmt_model = Model(inputs = [orig_input, repl_input], outputs = repl_output)\n",
    "\n",
    "nmt_model.compile(optimizer = 'adam',\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "nmt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "1728/3164 [===============>..............] - ETA: 1:39 - loss: 3.4680 - acc: 0.6615"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1111015fbdbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnmt_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_repl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_repl_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    185\u001b[0m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[1;32m    186\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     raise TypeError('TypeError while preparing batch. '\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmt_history = nmt_model.fit([X_orig, y_repl], y_repl_cat, epochs = 5, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inference mode for nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# redefine encoder model: takes original input, outputs the states\n",
    "enc_model = Model(inputs = [orig_input], outputs = [enc_h, enc_c])\n",
    "\n",
    "# define the states to input into the decoder (this is what you get from the encoder)\n",
    "inf_dec_h_input = Input(shape=(num_units * 2,)) #enc_h\n",
    "inf_dec_c_input = Input(shape=(num_units * 2,)) #enc_c\n",
    "inf_dec_states_input = [inf_dec_h_input, inf_dec_c_input]\n",
    "\n",
    "# these are the outputs you get when you run the decoder, set them up matching the original model\n",
    "# repl_embed is more of a placeholder - of course you won't actually have the answer when you infer\n",
    "inf_dec_main, inf_dec_h, inf_dec_c = decoder(repl_embed, initial_state = inf_dec_states_input)\n",
    "inf_dec_states = [inf_dec_h, inf_dec_c]\n",
    "inf_dec_output = dec_tdd(inf_dec_main)\n",
    "\n",
    "# define decoder model\n",
    "dec_model = Model([repl_input] + inf_dec_states_input, [inf_dec_output] + inf_dec_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_repl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(input_seq):\n",
    "    # takes input sequence in form of seq of token indices\n",
    "    states = enc_model.predict(input_seq)\n",
    "    \n",
    "    # begin output sequence, use start character\n",
    "    target_seq = np.zeros((1, repl_len))\n",
    "    target_seq[0, 0] = w2idx['\\t']\n",
    "    \n",
    "    # using batch_size = 1, sample in a loop\n",
    "    stop = False\n",
    "    decoded = []\n",
    "    dec_maxlen = 5\n",
    "    while not stop:\n",
    "        output_tok, h, c = dec_model.predict([target_seq] + states)\n",
    "        states = [h, c] # update states\n",
    "        \n",
    "        # sample a token\n",
    "        sample_idx = np.argmax(output_tok[0, -1, :]) # takes the last one in output\n",
    "        sample_tok = idx2w[sample_idx]\n",
    "        decoded.append(sample_tok)\n",
    "            \n",
    "        # update target_seq\n",
    "        target_seq = np.zeros((1, repl_len))\n",
    "        target_seq[0, 0] = sample_idx\n",
    "        \n",
    "        # exit if maxlen is reached or stop character is found\n",
    "        if (sample_tok == '\\n' or len(decoded) > dec_maxlen):\n",
    "            stop = True\n",
    "    \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = 'why'\n",
    "\n",
    "decode(pad_sequences([seq_to_idx(test)], value = pad, padding = 'post', maxlen = orig_len).astype('int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(100):\n",
    "    print(' '.join(decode(np.array([X_orig[idx]]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
