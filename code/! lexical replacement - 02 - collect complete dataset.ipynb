{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from glob import glob\n",
    "from nltk.corpus import brown\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "import difflib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes the first steps towards a curated dataset to train the fragment translation system. In it, I collect all sentences from the three relevant datasets, split them up into sentences, and put them in a dataframe to use. I also take the validated pairs of formal/informal words and phrases from the Microsoft data and create text files with the sentences from the dataset for each of them to check if they really can be replaced in all contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read manually curated csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creats a dictionary of terms and their informal replacements from the generated and validated lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "613\n"
     ]
    }
   ],
   "source": [
    "ann_df = pd.read_csv('data/microsoft/to_be_checked.csv', encoding='ISO-8859-1')[['Word', 'Replacement']].dropna()\n",
    "\n",
    "dc = {}\n",
    "for idx, row in ann_df.iterrows():\n",
    "    repl = [x.strip() for x in row['Replacement'].split(',')]\n",
    "    dc[row['Word'].lower()] = repl\n",
    "\n",
    "print(len(dc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect all sentences: Brown, OANC, BNC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three different sources of data required different handling methods. The Brown sentences could be directly accessed, pre-tokenized, from nltk, and the BNC/OANC ones had either been accessed and tokenized before for the discourse marker approach, or were stripped and preprocessed from the XML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['sent', 'source', 'description', 'orig', 'repl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sent = brown.sents()\n",
    "df.source = ['brown'] * len(brown.sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/rebekah/Documents/BNC/Texts/'\n",
    "files = [f for f in glob(path + \"**/*.xml\", recursive=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = [['Voice', 'over'], ['Male', 'speaker'], ['Female', 'speaker']]\n",
    "\n",
    "def parse_bnc_xml(path):\n",
    "    # takes path to BNC xml file\n",
    "    # returns description of texts\n",
    "    # returns list sentences, each of which is a list of tokens\n",
    "    \n",
    "    tree = ET.parse(path)\n",
    "    root = tree.getroot()\n",
    "    info = root[0][0][0][0].text\n",
    "    sents = []\n",
    "    \n",
    "    for div in root[1]:\n",
    "        sent = []\n",
    "        for tag in div.iter():\n",
    "            if tag.text == '\\n':\n",
    "                sent = list(filter(None, sent))\n",
    "                if sent.count('.') > 1:\n",
    "                    temp = ' '.join(sent)\n",
    "                    temp = sent_tokenize(temp)\n",
    "                    for temp_sent in temp:\n",
    "                        temp_sent = word_tokenize(temp_sent)\n",
    "                        if len(sent) < 2:\n",
    "                            sent = []\n",
    "                        elif temp_sent in skip: #skip certain things\n",
    "                            sent = []\n",
    "                        elif any([piece.isupper() for piece in temp_sent]):\n",
    "                            sent = []\n",
    "                        else:\n",
    "                            sents.append(temp_sent)\n",
    "                elif len(sent) > 1:\n",
    "                    if sent in skip:\n",
    "                        sent = []\n",
    "                    elif any([piece.isupper() for piece in sent]):\n",
    "                        sent = []\n",
    "                    else:\n",
    "                        sents.append(sent)\n",
    "                sent = []\n",
    "            elif tag.text != None:\n",
    "                sent.append(tag.text.strip())\n",
    "    \n",
    "    return info, sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2539040a18cd438d8ffd8ff5f2f8487b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sent = []\n",
    "source = []\n",
    "description = []\n",
    "\n",
    "for file in tqdm(files):\n",
    "    info, sents = parse_bnc_xml(file)\n",
    "    for s in sents:\n",
    "        sent.append(s)\n",
    "        source.append('bnc')\n",
    "        description.append(info)\n",
    "\n",
    "temp_df = pd.DataFrame(columns = ['sent', 'source', 'description', 'orig', 'repl'])\n",
    "temp_df.sent = sent\n",
    "temp_df.source = source\n",
    "temp_df.description = description\n",
    "df = df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "oanc_df = pd.read_pickle('data/discourse_markers/oanc_df.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3214031091a4b84b48c4df2b66ede35"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sent = []\n",
    "source = []\n",
    "description = []\n",
    "\n",
    "for idx, row in tqdm(oanc_df.iterrows(), total = len(oanc_df)):\n",
    "    for s in row['clean_and_tokenized']:\n",
    "        sent.append(s)\n",
    "        source.append('oanc')\n",
    "        description.append(row['label'])\n",
    "        \n",
    "temp_df = pd.DataFrame(columns = ['sent', 'source', 'description', 'orig', 'repl'])\n",
    "temp_df.sent = sent\n",
    "temp_df.source = source\n",
    "temp_df.description = description\n",
    "df = df.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3818246"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "      <th>orig</th>\n",
       "      <th>repl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2305642</th>\n",
       "      <td>[He, could, see, no, improvement, in, prospect...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>Loving and giving. Sample containing about 4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802073</th>\n",
       "      <td>[But, it, was, not, a, source, of, income, ;, ...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>Jane's journey. Sample containing about 3376...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562886</th>\n",
       "      <td>[She, looked, at, the, rigid, contours, of, hi...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>A French encounter. Sample containing about ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117225</th>\n",
       "      <td>[However, ,, its, coming, is, not, automatic, ...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>I believe in church growth. Sample containin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774196</th>\n",
       "      <td>[â€˜, Gone, .]</td>\n",
       "      <td>bnc</td>\n",
       "      <td>The Mamur Zapt and the girl in the Nile. Sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467875</th>\n",
       "      <td>[Oh, yes, ,, we, could, be, very, chic, when, ...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>[Sainsbury's magazines]. Sample containing a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500951</th>\n",
       "      <td>[â€˜, No, .]</td>\n",
       "      <td>bnc</td>\n",
       "      <td>Towards the end of the morning. Sample conta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687130</th>\n",
       "      <td>[Without, commitment, faith, seems, to, cost, ...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>Doubt. Sample containing about 36915 words f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313473</th>\n",
       "      <td>[â€™, (, He, goes, on, to, describe, how, swans,...</td>\n",
       "      <td>bnc</td>\n",
       "      <td>The Greek world: 479-323BC. Sample containin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265264</th>\n",
       "      <td>[I, ca, n't, even, think, about, my, fish, sau...</td>\n",
       "      <td>oanc</td>\n",
       "      <td>journal/slate/53/ArticleIP_57073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sent source  \\\n",
       "2305642  [He, could, see, no, improvement, in, prospect...    bnc   \n",
       "2802073  [But, it, was, not, a, source, of, income, ;, ...    bnc   \n",
       "2562886  [She, looked, at, the, rigid, contours, of, hi...    bnc   \n",
       "1117225  [However, ,, its, coming, is, not, automatic, ...    bnc   \n",
       "1774196                                       [â€˜, Gone, .]    bnc   \n",
       "467875   [Oh, yes, ,, we, could, be, very, chic, when, ...    bnc   \n",
       "1500951                                         [â€˜, No, .]    bnc   \n",
       "687130   [Without, commitment, faith, seems, to, cost, ...    bnc   \n",
       "1313473  [â€™, (, He, goes, on, to, describe, how, swans,...    bnc   \n",
       "265264   [I, ca, n't, even, think, about, my, fish, sau...   oanc   \n",
       "\n",
       "                                               description orig repl  \n",
       "2305642    Loving and giving. Sample containing about 4...  NaN  NaN  \n",
       "2802073    Jane's journey. Sample containing about 3376...  NaN  NaN  \n",
       "2562886    A French encounter. Sample containing about ...  NaN  NaN  \n",
       "1117225    I believe in church growth. Sample containin...  NaN  NaN  \n",
       "1774196    The Mamur Zapt and the girl in the Nile. Sam...  NaN  NaN  \n",
       "467875     [Sainsbury's magazines]. Sample containing a...  NaN  NaN  \n",
       "1500951    Towards the end of the morning. Sample conta...  NaN  NaN  \n",
       "687130     Doubt. Sample containing about 36915 words f...  NaN  NaN  \n",
       "1313473    The Greek world: 479-323BC. Sample containin...  NaN  NaN  \n",
       "265264                    journal/slate/53/ArticleIP_57073  NaN  NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/lexical_repl/sents_df.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OANC / BNC collect sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('data/lexical_repl/sents_df.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(df, word):\n",
    "    for idx, row in tqdm(df.iterrows(), total = len(df)):\n",
    "        lowered = [word.lower() for word in row.sent]\n",
    "        if np.isnan(row.orig) and word in lowered:\n",
    "            print(' '.join(row.sent))\n",
    "            print(' '.join(map(lambda x: x if x != word else dc[word][0], lowered)))\n",
    "            print()\n",
    "            \n",
    "def print_all_examples(df, dc):\n",
    "    current_status = [file[32:-4] for file in glob('data/lexical_repl/word_contexts/*')]\n",
    "    current_status.extend([file[37:-4] for file in glob('data/lexical_repl/word_contexts_done/*')])\n",
    "    print('already done:\\t' + ' '.join(current_status))\n",
    "        \n",
    "    for term in dc:\n",
    "        print('file started:\\t' + term)\n",
    "        replace = '[' + '/'.join(dc[term]) + ']'\n",
    "        with open('data/lexical_repl/word_contexts/' + term + '.txt', 'w') as f:\n",
    "            for idx, row in tqdm(df.iterrows(), total = len(df)):\n",
    "                lowered = [word.lower() for word in row.sent]\n",
    "                if np.isnan(row.orig) and term in lowered:\n",
    "                    f.write(' '.join(row.sent) + '\\n')\n",
    "                    f.write(' '.join(map(lambda x: x if x != term else replace, lowered)) + '\\n\\n')\n",
    "        print('file written:\\t' + term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "already done:\t\n",
      "file started:\tconsiderations\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54f989b70424ac48b1e6aa4d4d2ce0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3818246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file written:\tconsiderations\n",
      "file started:\taccurate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a57d345839af4b3aa5440ff942253f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3818246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file written:\taccurate\n",
      "file started:\ttriggered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8349bb6cfa4f579a93498f932f2d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3818246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file written:\ttriggered\n",
      "file started:\tobtains\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df47b4157d44c259f625fabe98272c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3818246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-eaaa941194d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_all_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-9db8e975423d>\u001b[0m in \u001b[0;36mprint_all_examples\u001b[0;34m(df, dc)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mreplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'['\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m']'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/lexical_repl/word_contexts/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mlowered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlowered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                 \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36miterrows\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 data = sanitize_array(data, index, dtype, copy,\n\u001b[0;32m--> 262\u001b[0;31m                                       raise_cast_failure=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    702\u001b[0m                                        isinstance(subarr, np.ndarray))):\n\u001b[1;32m    703\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_1d_object_array_from_listlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_extension_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m             subarr = construct_1d_ndarray_preserving_na(subarr, dtype,\n\u001b[1;32m    706\u001b[0m                                                         copy=copy)\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_extension_type\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m   1695\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1697\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1698\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_datetime64tz_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr_or_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeTZDtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print_all_examples(df, dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/w2idx.pkl', 'rb') as f:\n",
    "    w2idx = pickle.load(f)\n",
    "    \n",
    "def collect_all_idx(df):\n",
    "    indices = []\n",
    "    for idx, row in tqdm(df.iterrows(), total = len(df)):\n",
    "        current = []\n",
    "        for item in row.sent:\n",
    "            if item in w2idx:\n",
    "                current.append(w2idx[item])\n",
    "            else: # handle unknowns\n",
    "                current.append(w2idx['[UNK]'])\n",
    "        indices.append(current)\n",
    "    df['idx'] = indices\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062d647431f44b88a9d19681b2960803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3818246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = collect_all_idx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/lexical_repl/sents_df.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
