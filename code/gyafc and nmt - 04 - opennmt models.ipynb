{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "import torch\n",
    "from nltk import word_tokenize, pos_tag, ne_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenNMT required both significant preprocessing in Python to put the files into the right format for the software, and use of the command line to start actual training. The former was done here, and the latter is also recorded here for posterity and examination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare text files to use with OpenNMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Target 0</th>\n",
       "      <th>Target 1</th>\n",
       "      <th>Target 2</th>\n",
       "      <th>Target 3</th>\n",
       "      <th>Category</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean that you have to really be her friend.</td>\n",
       "      <td>And I mean Really be her friend.</td>\n",
       "      <td>Just be her BFF 4 real.</td>\n",
       "      <td>you have to be her friend.</td>\n",
       "      <td>You have to actually be her friend, for real.</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you posing a rhetorical question?</td>\n",
       "      <td>Sounds like a rhetorical question :)</td>\n",
       "      <td>Do you really want an answer?</td>\n",
       "      <td>That sounds more like a rhetorical question th...</td>\n",
       "      <td>Are you asking me a rhetorical question?</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men pretend to love in order to have intercour...</td>\n",
       "      <td>Men play at love to get sex, women play at sex...</td>\n",
       "      <td>Men fake love to get laid, women fake orgasms ...</td>\n",
       "      <td>Guys PRETEND to love so they can get laid, wom...</td>\n",
       "      <td>Dudes just act like they love a chick to get b...</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do not intend to be mean.</td>\n",
       "      <td>I don't want to be mean.</td>\n",
       "      <td>I wasn't trying to be a jerk.</td>\n",
       "      <td>I'm not tryin to be mean...</td>\n",
       "      <td>I didn't want to be mean</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would estimate an average of 45% initially b...</td>\n",
       "      <td>On average I'd say about 45% at first but than...</td>\n",
       "      <td>It's a little less than 50/50 at the start, bu...</td>\n",
       "      <td>Prolly 45% at the start but when you get to no...</td>\n",
       "      <td>I guess it'd be around 45% to start with, but ...</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Original  \\\n",
       "0      I mean that you have to really be her friend.   \n",
       "1              Are you posing a rhetorical question?   \n",
       "2  Men pretend to love in order to have intercour...   \n",
       "3                        I do not intend to be mean.   \n",
       "4  I would estimate an average of 45% initially b...   \n",
       "\n",
       "                                            Target 0  \\\n",
       "0                   And I mean Really be her friend.   \n",
       "1               Sounds like a rhetorical question :)   \n",
       "2  Men play at love to get sex, women play at sex...   \n",
       "3                           I don't want to be mean.   \n",
       "4  On average I'd say about 45% at first but than...   \n",
       "\n",
       "                                            Target 1  \\\n",
       "0                            Just be her BFF 4 real.   \n",
       "1                      Do you really want an answer?   \n",
       "2  Men fake love to get laid, women fake orgasms ...   \n",
       "3                      I wasn't trying to be a jerk.   \n",
       "4  It's a little less than 50/50 at the start, bu...   \n",
       "\n",
       "                                            Target 2  \\\n",
       "0                         you have to be her friend.   \n",
       "1  That sounds more like a rhetorical question th...   \n",
       "2  Guys PRETEND to love so they can get laid, wom...   \n",
       "3                        I'm not tryin to be mean...   \n",
       "4  Prolly 45% at the start but when you get to no...   \n",
       "\n",
       "                                            Target 3              Category  \\\n",
       "0      You have to actually be her friend, for real.  Family_Relationships   \n",
       "1           Are you asking me a rhetorical question?  Family_Relationships   \n",
       "2  Dudes just act like they love a chick to get b...  Family_Relationships   \n",
       "3                           I didn't want to be mean  Family_Relationships   \n",
       "4  I guess it'd be around 45% to start with, but ...  Family_Relationships   \n",
       "\n",
       "  Dataset  \n",
       "0    test  \n",
       "1    test  \n",
       "2    test  \n",
       "3    test  \n",
       "4    test  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_pickle('data/opennmt/rule_based_corrected_df.pkl')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = all_df[all_df['Dataset'] == 'train']['Original']\n",
    "train_tgt = all_df[all_df['Dataset'] == 'train']['Target 0']\n",
    "val_src = all_df[all_df['Dataset'] == 'tune']['Original']\n",
    "val_tgt = all_df[all_df['Dataset'] == 'tune']['Target 0']\n",
    "\n",
    "assert len(train_src) == len(train_tgt)\n",
    "assert len(val_src) == len(val_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_txt(series, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for item in series:\n",
    "            tokens = word_tokenize(item)\n",
    "            tokens = ' '.join(tokens)\n",
    "            f.write(tokens + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_to_txt(val_src, 'data/src-val.txt')\n",
    "series_to_txt(val_tgt, 'data/tgt-val.txt')\n",
    "series_to_txt(train_src, 'data/src-train.txt')\n",
    "series_to_txt(train_tgt, 'data/tgt-train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src = all_df[all_df['Dataset'] == 'test']['Original']\n",
    "test_tgt = all_df[all_df['Dataset'] == 'test']['Target 0']\n",
    "\n",
    "assert len(test_src) == len(test_tgt)\n",
    "\n",
    "series_to_txt(test_src, 'data/src-test.txt')\n",
    "series_to_txt(test_tgt, 'data/tgt-test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openNMT use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a record of the varying command line codes required to train the models used in this thesis which were done using OpenNMT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training took an extremely long time because CUDA could not be used to access the GPU for training locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands below were to train the most basic model, using the GloVe embeddings but no special bells or whistles."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# http://opennmt.net/OpenNMT-py/quickstart.html\n",
    "\n",
    "# % OpenNMT-py/preprocess.py -train_src make-it-sound-less-formal/data/src-train.txt -train_tgt make-it-sound-less-formal/data/tgt-train.txt -valid_src make-it-sound-less-formal/data/src-val.txt -valid_tgt make-it-sound-less-formal/data/tgt-val.txt -save_data make-it-sound-less-formal/data/OpenNMTData\n",
    "\n",
    "# % tools/embeddings_to_torch.py -emb_file_both \"data/YahooCorpus/YahooVectors.txt\" -dict_file \"data/YahooCorpus/OpenNMTData.vocab.pt\" -output_file \"data/YahooCorpus/embeddings\"\n",
    "\n",
    "# % python3 train.py -save_model data/YahooCorpus/model -data data/YahooCorpus/OpenNMTData -word_vec_size 300 -pre_word_vecs_enc \"data/YahooCorpus/embeddings.enc.pt\" -pre_word_vecs_dec \"data/YahooCorpus/embeddings.dec.pt\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second version, similar to the above but just with copy attention turned on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess.py -train_src data/YahooCorpus/src-train.txt -train_tgt data/YahooCorpus/tgt-train.txt -valid_src data/YahooCorpus/src-val.txt -valid_tgt data/YahooCorpus/tgt-val.txt -save_data data/model_pretrained_embed_with_copy/data -dynamic_dict\n",
    "# python3 train.py -save_model data/model_pretrained_embed_with_copy/ -data data/model_pretrained_embed_with_copy/data -word_vec_size 300 -pre_word_vecs_enc \"data/glove_pretrained/embeddings.enc.pt\" -pre_word_vecs_dec \"data/glove_pretrained/embeddings.dec.pt\" -copy_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third version, also with copy attention, and with all named entities removed (see below) from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenNMT-py/preprocess.py -train_src make-it-sound-less-formal/data/src-train-no-ent.txt -train_tgt make-it-sound-less-formal/data/tgt-train-no-ent.txt -valid_src make-it-sound-less-formal/data/src-val-no-ent.txt -valid_tgt make-it-sound-less-formal/data/tgt-val-no-ent.txt -save_data OpenNMT-py/data/model_pretrained_no_ent_with_copy/data -dynamic_dict\n",
    "# python3 train.py -save_model data/model_pretrained_no_ent_with_copy/model -data data/model_pretrained_no_ent_with_copy/data -word_vec_size 300 -pre_word_vecs_enc \"data/glove_pretrained/embeddings.enc.pt\" -pre_word_vecs_dec \"data/glove_pretrained/embeddings.dec.pt\" -copy_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single reversed model (as in, informal to formal instead of formal to informal) trained to use on the Acrolinx dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# informal to formal\n",
    "# OpenNMT-py/preprocess.py -train_src make-it-sound-less-formal/data/OpenNMT\\ files/tgt-train-no-ent.txt -train_tgt make-it-sound-less-formal/data/OpenNMT\\ files/src-train-no-ent.txt -valid_src make-it-sound-less-formal/data/OpenNMT\\ files/tgt-val-no-ent.txt -valid_tgt make-it-sound-less-formal/data/OpenNMT\\ files/src-val-no-ent.txt -save_data make-it-sound-less-formal/data/OpenNMT\\ files/formal-to-informal-data -dynamic_dict\n",
    "# python3 OpenNMT-py/train.py -save_model informal-to-formal -data make-it-sound-less-formal/data/OpenNMT\\ files/informal-to-formal-data -word_vec_size 300 -pre_word_vecs_enc \"embeddings.enc.pt\" -pre_word_vecs_dec \"embeddings.dec.pt\" -copy_attn -world_size 1 -gpu_ranks 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect the results from the OpenNMT files into pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes all the results - from each of the three resulting models - and puts them all together in order to better compare how each one did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rebekah/Documents/OpenNMT-py/data/YahooCorpus\n"
     ]
    }
   ],
   "source": [
    "% cd /home/rebekah/Documents/OpenNMT-py/data/YahooCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = open('pred-test.txt')\n",
    "pred = [line.rstrip() for line in pred_file.readlines()]\n",
    "pred_file.close()\n",
    "\n",
    "source_file = open('src-test.txt')\n",
    "source = [line.rstrip() for line in source_file.readlines()]\n",
    "source_file.close()\n",
    "\n",
    "target_file = open('tgt-test.txt')\n",
    "target = [line.rstrip() for line in target_file.readlines()]\n",
    "target_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_results = pd.DataFrame({'Source': source, 'Target': target, 'Prediction': pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rebekah/Documents/make-it-sound-less-formal/data\n"
     ]
    }
   ],
   "source": [
    "% cd /home/rebekah/Documents/make-it-sound-less-formal/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('version_1_test.xlsx')\n",
    "v1_results.to_excel(writer, engine='xlsxwriter')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>source_lf</th>\n",
       "      <th>target_lf</th>\n",
       "      <th>pred_lf</th>\n",
       "      <th>src_tgt_diff</th>\n",
       "      <th>src_pred_diff</th>\n",
       "      <th>Copy Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean that you have to really be her friend .</td>\n",
       "      <td>And I mean Really be her friend .</td>\n",
       "      <td>I mean you have to really be her friend .</td>\n",
       "      <td>-0.270857</td>\n",
       "      <td>-0.271620</td>\n",
       "      <td>-0.275536</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>I mean you have to really be her friend .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you posing a rhetorical question ?</td>\n",
       "      <td>Sounds like a rhetorical question : )</td>\n",
       "      <td>What kind of question is that ?</td>\n",
       "      <td>-0.142981</td>\n",
       "      <td>-0.178207</td>\n",
       "      <td>-0.207015</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.064035</td>\n",
       "      <td>What are you asking a question ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men pretend to love in order to have intercour...</td>\n",
       "      <td>Men play at love to get sex , women play at se...</td>\n",
       "      <td>Men play love to have sex , women play for sex...</td>\n",
       "      <td>-0.195864</td>\n",
       "      <td>-0.237748</td>\n",
       "      <td>-0.216562</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>Men pretend to love in order to have sex , wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do not intend to be mean .</td>\n",
       "      <td>I do n't want to be mean .</td>\n",
       "      <td>I do n't mean to be mean .</td>\n",
       "      <td>-0.204783</td>\n",
       "      <td>-0.242434</td>\n",
       "      <td>-0.219974</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>0.015191</td>\n",
       "      <td>I do n't mean to be mean .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would estimate an average of 45 % initially ...</td>\n",
       "      <td>On average I 'd say about 45 % at first but th...</td>\n",
       "      <td>I would say a 15 % of 45 % , then once you get...</td>\n",
       "      <td>-0.126478</td>\n",
       "      <td>-0.218232</td>\n",
       "      <td>-0.182693</td>\n",
       "      <td>0.091754</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>45 % of them , but once you get to know the pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Source  \\\n",
       "0     I mean that you have to really be her friend .   \n",
       "1             Are you posing a rhetorical question ?   \n",
       "2  Men pretend to love in order to have intercour...   \n",
       "3                       I do not intend to be mean .   \n",
       "4  I would estimate an average of 45 % initially ...   \n",
       "\n",
       "                                              Target  \\\n",
       "0                  And I mean Really be her friend .   \n",
       "1              Sounds like a rhetorical question : )   \n",
       "2  Men play at love to get sex , women play at se...   \n",
       "3                         I do n't want to be mean .   \n",
       "4  On average I 'd say about 45 % at first but th...   \n",
       "\n",
       "                                          Prediction  source_lf  target_lf  \\\n",
       "0          I mean you have to really be her friend .  -0.270857  -0.271620   \n",
       "1                    What kind of question is that ?  -0.142981  -0.178207   \n",
       "2  Men play love to have sex , women play for sex...  -0.195864  -0.237748   \n",
       "3                         I do n't mean to be mean .  -0.204783  -0.242434   \n",
       "4  I would say a 15 % of 45 % , then once you get...  -0.126478  -0.218232   \n",
       "\n",
       "    pred_lf  src_tgt_diff  src_pred_diff  \\\n",
       "0 -0.275536      0.000763       0.004680   \n",
       "1 -0.207015      0.035226       0.064035   \n",
       "2 -0.216562      0.041885       0.020698   \n",
       "3 -0.219974      0.037651       0.015191   \n",
       "4 -0.182693      0.091754       0.056215   \n",
       "\n",
       "                                     Copy Prediction  \n",
       "0          I mean you have to really be her friend .  \n",
       "1                   What are you asking a question ?  \n",
       "2  Men pretend to love in order to have sex , wom...  \n",
       "3                         I do n't mean to be mean .  \n",
       "4  45 % of them , but once you get to know the pe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_pickle('data/v1_results.pkl')\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_pred_file = open('data/copy-pred-test.txt')\n",
    "copy_pred = [line.rstrip() for line in copy_pred_file.readlines()]\n",
    "copy_pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['Copy Prediction'] = copy_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_no_ent_pred_file = open('data/pred-test-no-ent.txt')\n",
    "copy_no_ent_pred = [line.rstrip() for line in copy_no_ent_pred_file.readlines()]\n",
    "copy_no_ent_pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['No Entity Copy Prediction'] = copy_no_ent_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>source_lf</th>\n",
       "      <th>target_lf</th>\n",
       "      <th>pred_lf</th>\n",
       "      <th>src_tgt_diff</th>\n",
       "      <th>src_pred_diff</th>\n",
       "      <th>Copy Prediction</th>\n",
       "      <th>No Entity Copy Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean that you have to really be her friend .</td>\n",
       "      <td>And I mean Really be her friend .</td>\n",
       "      <td>I mean you have to really be her friend .</td>\n",
       "      <td>-0.270857</td>\n",
       "      <td>-0.271620</td>\n",
       "      <td>-0.275536</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>I mean you have to really be her friend .</td>\n",
       "      <td>I mean you have to be her friend .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you posing a rhetorical question ?</td>\n",
       "      <td>Sounds like a rhetorical question : )</td>\n",
       "      <td>What kind of question is that ?</td>\n",
       "      <td>-0.142981</td>\n",
       "      <td>-0.178207</td>\n",
       "      <td>-0.207015</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.064035</td>\n",
       "      <td>What are you asking a question ?</td>\n",
       "      <td>What kind of question is that ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men pretend to love in order to have intercour...</td>\n",
       "      <td>Men play at love to get sex , women play at se...</td>\n",
       "      <td>Men play love to have sex , women play for sex...</td>\n",
       "      <td>-0.195864</td>\n",
       "      <td>-0.237748</td>\n",
       "      <td>-0.216562</td>\n",
       "      <td>0.041885</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>Men pretend to love in order to have sex , wom...</td>\n",
       "      <td>Men play to love in order to have sex , women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do not intend to be mean .</td>\n",
       "      <td>I do n't want to be mean .</td>\n",
       "      <td>I do n't mean to be mean .</td>\n",
       "      <td>-0.204783</td>\n",
       "      <td>-0.242434</td>\n",
       "      <td>-0.219974</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>0.015191</td>\n",
       "      <td>I do n't mean to be mean .</td>\n",
       "      <td>I do n't mean to be mean .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would estimate an average of 45 % initially ...</td>\n",
       "      <td>On average I 'd say about 45 % at first but th...</td>\n",
       "      <td>I would say a 15 % of 45 % , then once you get...</td>\n",
       "      <td>-0.126478</td>\n",
       "      <td>-0.218232</td>\n",
       "      <td>-0.182693</td>\n",
       "      <td>0.091754</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>45 % of them , but once you get to know the pe...</td>\n",
       "      <td>45 % of 45 % and then after you know the perso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Source  \\\n",
       "0     I mean that you have to really be her friend .   \n",
       "1             Are you posing a rhetorical question ?   \n",
       "2  Men pretend to love in order to have intercour...   \n",
       "3                       I do not intend to be mean .   \n",
       "4  I would estimate an average of 45 % initially ...   \n",
       "\n",
       "                                              Target  \\\n",
       "0                  And I mean Really be her friend .   \n",
       "1              Sounds like a rhetorical question : )   \n",
       "2  Men play at love to get sex , women play at se...   \n",
       "3                         I do n't want to be mean .   \n",
       "4  On average I 'd say about 45 % at first but th...   \n",
       "\n",
       "                                          Prediction  source_lf  target_lf  \\\n",
       "0          I mean you have to really be her friend .  -0.270857  -0.271620   \n",
       "1                    What kind of question is that ?  -0.142981  -0.178207   \n",
       "2  Men play love to have sex , women play for sex...  -0.195864  -0.237748   \n",
       "3                         I do n't mean to be mean .  -0.204783  -0.242434   \n",
       "4  I would say a 15 % of 45 % , then once you get...  -0.126478  -0.218232   \n",
       "\n",
       "    pred_lf  src_tgt_diff  src_pred_diff  \\\n",
       "0 -0.275536      0.000763       0.004680   \n",
       "1 -0.207015      0.035226       0.064035   \n",
       "2 -0.216562      0.041885       0.020698   \n",
       "3 -0.219974      0.037651       0.015191   \n",
       "4 -0.182693      0.091754       0.056215   \n",
       "\n",
       "                                     Copy Prediction  \\\n",
       "0          I mean you have to really be her friend .   \n",
       "1                   What are you asking a question ?   \n",
       "2  Men pretend to love in order to have sex , wom...   \n",
       "3                         I do n't mean to be mean .   \n",
       "4  45 % of them , but once you get to know the pe...   \n",
       "\n",
       "                           No Entity Copy Prediction  \n",
       "0                 I mean you have to be her friend .  \n",
       "1                    What kind of question is that ?  \n",
       "2  Men play to love in order to have sex , women ...  \n",
       "3                         I do n't mean to be mean .  \n",
       "4  45 % of 45 % and then after you know the perso...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_pickle('data/v1_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove NER from dataset for last model type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, one attempt to better the NMT model results was to remove all named entities. This was in the hope of having the model better adapt to out-of-domain data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>Target 0</th>\n",
       "      <th>Target 1</th>\n",
       "      <th>Target 2</th>\n",
       "      <th>Target 3</th>\n",
       "      <th>Category</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I mean that you have to really be her friend.</td>\n",
       "      <td>And I mean Really be her friend.</td>\n",
       "      <td>Just be her BFF 4 real.</td>\n",
       "      <td>you have to be her friend.</td>\n",
       "      <td>You have to actually be her friend, for real.</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Are you posing a rhetorical question?</td>\n",
       "      <td>Sounds like a rhetorical question :)</td>\n",
       "      <td>Do you really want an answer?</td>\n",
       "      <td>That sounds more like a rhetorical question th...</td>\n",
       "      <td>Are you asking me a rhetorical question?</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Men pretend to love in order to have intercour...</td>\n",
       "      <td>Men play at love to get sex, women play at sex...</td>\n",
       "      <td>Men fake love to get laid, women fake orgasms ...</td>\n",
       "      <td>Guys PRETEND to love so they can get laid, wom...</td>\n",
       "      <td>Dudes just act like they love a chick to get b...</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I do not intend to be mean.</td>\n",
       "      <td>I don't want to be mean.</td>\n",
       "      <td>I wasn't trying to be a jerk.</td>\n",
       "      <td>I'm not tryin to be mean...</td>\n",
       "      <td>I didn't want to be mean</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would estimate an average of 45% initially b...</td>\n",
       "      <td>On average I'd say about 45% at first but than...</td>\n",
       "      <td>It's a little less than 50/50 at the start, bu...</td>\n",
       "      <td>Prolly 45% at the start but when you get to no...</td>\n",
       "      <td>I guess it'd be around 45% to start with, but ...</td>\n",
       "      <td>Family_Relationships</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Original  \\\n",
       "0      I mean that you have to really be her friend.   \n",
       "1              Are you posing a rhetorical question?   \n",
       "2  Men pretend to love in order to have intercour...   \n",
       "3                        I do not intend to be mean.   \n",
       "4  I would estimate an average of 45% initially b...   \n",
       "\n",
       "                                            Target 0  \\\n",
       "0                   And I mean Really be her friend.   \n",
       "1               Sounds like a rhetorical question :)   \n",
       "2  Men play at love to get sex, women play at sex...   \n",
       "3                           I don't want to be mean.   \n",
       "4  On average I'd say about 45% at first but than...   \n",
       "\n",
       "                                            Target 1  \\\n",
       "0                            Just be her BFF 4 real.   \n",
       "1                      Do you really want an answer?   \n",
       "2  Men fake love to get laid, women fake orgasms ...   \n",
       "3                      I wasn't trying to be a jerk.   \n",
       "4  It's a little less than 50/50 at the start, bu...   \n",
       "\n",
       "                                            Target 2  \\\n",
       "0                         you have to be her friend.   \n",
       "1  That sounds more like a rhetorical question th...   \n",
       "2  Guys PRETEND to love so they can get laid, wom...   \n",
       "3                        I'm not tryin to be mean...   \n",
       "4  Prolly 45% at the start but when you get to no...   \n",
       "\n",
       "                                            Target 3              Category  \\\n",
       "0      You have to actually be her friend, for real.  Family_Relationships   \n",
       "1           Are you asking me a rhetorical question?  Family_Relationships   \n",
       "2  Dudes just act like they love a chick to get b...  Family_Relationships   \n",
       "3                           I didn't want to be mean  Family_Relationships   \n",
       "4  I guess it'd be around 45% to start with, but ...  Family_Relationships   \n",
       "\n",
       "  Dataset  \n",
       "0    test  \n",
       "1    test  \n",
       "2    test  \n",
       "3    test  \n",
       "4    test  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_pickle('data/rule_based_corrected_df.pkl')\n",
    "all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ents(sent):\n",
    "    entities = []\n",
    "    for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(sent))):\n",
    "        if hasattr(chunk, 'label'):\n",
    "            entities.append(' '.join(c[0] for c in chunk))\n",
    "    return entities\n",
    "\n",
    "def replace_ents(sent):\n",
    "    entities = ents(sent)\n",
    "    for ent in entities:\n",
    "        sent = sent.replace(ent, 'ENT')\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111266/111266 [07:59<00:00, 232.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             I mean that you have to really be her friend.\n",
       "1                     Are you posing a rhetorical question?\n",
       "2         Men pretend to love in order to have intercour...\n",
       "3                               I do not intend to be mean.\n",
       "4         I would estimate an average of 45% initially b...\n",
       "5         Because some women send subtle messages to men...\n",
       "6         Let us purchase coffee and converse and procee...\n",
       "7             Also, i dislike it when my father is unhappy.\n",
       "8                    Ask him if you should go see a doctor.\n",
       "9             You can post more questioins on ENT! answers.\n",
       "10        He probably has many things to worry about rig...\n",
       "11        But I do not believe that he will be unfaithfu...\n",
       "12                             Will I always feel that way?\n",
       "13        However, he may enjoy all of the waiting, drea...\n",
       "14                         Also, I would like to try again.\n",
       "15                 Some men shave, it depends on the woman.\n",
       "16        Well, if you are really attracted to this guy,...\n",
       "17        I am not certain whether he loves you, but he ...\n",
       "18        I would invite you on a date but I live in ENT...\n",
       "19                                  Women are coomplicated.\n",
       "20        I realize I am overly selective when it comes ...\n",
       "21                   Doing that does sound rather feminine.\n",
       "22        Sometimes, if the good outweighs the bad, then...\n",
       "23                 That is if both of you agree to do this.\n",
       "24        One female, ENT, who most likely would not bei...\n",
       "25        Well, why do you like the one boy who picks on...\n",
       "26        In addition, men sometimes think that they do ...\n",
       "27        ENT, if a male inquires of you, do not be frig...\n",
       "28                               Do I desire to be in love?\n",
       "29        That's the name I applied to it. For what reas...\n",
       "                                ...                        \n",
       "111236    If you are referring to a prisoner then I am u...\n",
       "111237          The should produce one similar to that one.\n",
       "111238                 I think nearly anyone would suffice.\n",
       "111239                   I found \"ENT\" to be a boring film.\n",
       "111240     I'm not familiar with her but I am a fan of ENT.\n",
       "111241    I really like ENT C. I also like ENT (ENT's Fo...\n",
       "111242    I don't really know but I am thinking that ENT...\n",
       "111243    ENT don't get upset about the other questions ...\n",
       "111244    I may not like them but they were very nice an...\n",
       "111245                 I wasn't but I knew someone who was.\n",
       "111246        ENT ENT was born on June 4, 1975 in ENT, ENT.\n",
       "111247    Besides, I am sure that you are an amazing roc...\n",
       "111248           No, the book is all about ENT and the ENT.\n",
       "111249        It probably is not it, but it is still close!\n",
       "111250    ENT, stand-up comedies are outdated, but I lik...\n",
       "111251                  You'll drown. I've tried it before.\n",
       "111252                     It's a central american country.\n",
       "111253    I haven't seen it in a while, but I do recall ...\n",
       "111254               It's an ideal song to get in the mood!\n",
       "111255    I never watched it. I'm afraid she will succee...\n",
       "111256           I have tried it before and almost drowned.\n",
       "111257                            That is a country in ENT.\n",
       "111258    I have not seen that in a while but I do remem...\n",
       "111259    I feel that the song is ideal when trying to g...\n",
       "111260    I have never seen the show but I am worried th...\n",
       "111261    This is amazing and funny. Please send your id...\n",
       "111262    ENT yahoo.com, and click on music. From there ...\n",
       "111263                               ENT shave or try nair.\n",
       "111264    She grew up to be a bad person, who rapes youn...\n",
       "111265    I do have it. Please send me a message and I w...\n",
       "Name: Original, Length: 111266, dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Original'].progress_apply(replace_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111266/111266 [07:41<00:00, 241.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                          And I mean Really be her friend.\n",
       "1                         ENT like a rhetorical question :)\n",
       "2         ENT play at love to get sex, women play at sex...\n",
       "3                                  I don't want to be mean.\n",
       "4         On average I'd say about 45% at first but than...\n",
       "5         Because some women send men tiny messages with...\n",
       "6         let's get coffee and chat and take it from there!\n",
       "7                        I also hate seeing my dad unhappy.\n",
       "8                                  Ask him to go see a doc.\n",
       "9                               Post more questions on ENT!\n",
       "10        Besides don't you think he has enough to worry...\n",
       "11        But I don't htink that by not having sex with ...\n",
       "12        Anyway my question is... Will I always feel th...\n",
       "13        But he might enjoy all the waiting, dreaming &...\n",
       "14                                 And I want to try again.\n",
       "15        Not all the time, sometimes men shave them, it...\n",
       "16        Well if you really like this guy smile and mak...\n",
       "17        I don't know about love, but he likes you for ...\n",
       "18        I'd ask you out, but I live in ENT and have no...\n",
       "19               I can onli say... women are complicated...\n",
       "20        I know I'm overtly picky about people HOW CAN ...\n",
       "21                           It does sound a little girlie.\n",
       "22        Sometimes the difficulties are worth it if the...\n",
       "23                 That's if you both agreed on doing this.\n",
       "24        One girl ENT, who probably wouldn't mind being...\n",
       "25         Well, if the one boy picks on you, why like him?\n",
       "26        Also sometimes guys think they don't need you ...\n",
       "27         But if a guy asks you don't be afraid to say NO.\n",
       "28                                 Do I want to be in love?\n",
       "29                   (that's what I called it)... but, why?\n",
       "                                ...                        \n",
       "111236    If you are talking about a prisoner I am not s...\n",
       "111237                         They should make 1 like that\n",
       "111238                             Any idiot would do :-) .\n",
       "111239                        ENT ENT - what a boring movie\n",
       "111240              I Don't know her I'm more of a Rani fan\n",
       "111241    I really love ENT Graduation Song ( ENT's Fore...\n",
       "111242    I guess taylor might be next in line to win it...\n",
       "111243    Don't explode please :) um, regarding your oth...\n",
       "111244                 They were kool and big daddy though.\n",
       "111245                      No, but I knew someone who was.\n",
       "111246    ENT jolie, born june 4 1975 los angeles califo...\n",
       "111247        Besides I bet you're an amazing rocker *wink*\n",
       "111248       No, the book is all about jesus and the bible.\n",
       "111249         It probably isn't it, but it is still close!\n",
       "111250    ENT stand up comedies are outdated, I like ENT...\n",
       "111251                        ENT because I tried it before\n",
       "111252                     Its a country in central america\n",
       "111253    I haven't seen it in a while, but I remember i...\n",
       "111254     I think that it's ideal song to get in the mood!\n",
       "111255    I never watch the show but I am afraid she wil...\n",
       "111256                        ENT because I tried it before\n",
       "111257                     Its a country in central america\n",
       "111258    I haven't seen it in a while, but I remember i...\n",
       "111259     I think that it's ideal song to get in the mood!\n",
       "111260    I never watch the show but I am afraid she wil...\n",
       "111261    ENT, ENT plz sendur ID so I can add you in y m...\n",
       "111262    Go to yahoo.com then click on music and type i...\n",
       "111263          Hell yea shave that shit please or try nair\n",
       "111264    She grew up to become an evil old person who r...\n",
       "111265    I have it if you would like it... message me a...\n",
       "Name: Target 0, Length: 111266, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df['Target 0'].progress_apply(replace_ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = all_df[all_df['Dataset'] == 'train']['Original']\n",
    "train_tgt = all_df[all_df['Dataset'] == 'train']['Target 0']\n",
    "val_src = all_df[all_df['Dataset'] == 'tune']['Original']\n",
    "val_tgt = all_df[all_df['Dataset'] == 'tune']['Target 0']\n",
    "\n",
    "assert len(train_src) == len(train_tgt)\n",
    "assert len(val_src) == len(val_tgt)\n",
    "\n",
    "def series_to_txt(series, filename):\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for item in series:\n",
    "            tokens = word_tokenize(item)\n",
    "            tokens = ' '.join(tokens)\n",
    "            f.write(tokens + '\\n')\n",
    "            \n",
    "series_to_txt(val_src, 'data/src-val-no-ent.txt')\n",
    "series_to_txt(val_tgt, 'data/tgt-val-no-ent.txt')\n",
    "series_to_txt(train_src, 'data/src-train-no-ent.txt')\n",
    "series_to_txt(train_tgt, 'data/tgt-train-no-ent.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
