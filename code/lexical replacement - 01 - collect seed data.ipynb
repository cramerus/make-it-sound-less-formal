{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from glob import glob\n",
    "import gensim\n",
    "import xml.etree.ElementTree as ET\n",
    "from ast import literal_eval\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import sklearn\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook was to gather, automatically augment, and then manually check and curate, a small dataset of formal words and their replacements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Acrolinx gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acro_test_df = pd.read_pickle('data/lexical_repl/acro_test_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acro_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>orig</th>\n",
       "      <th>repl</th>\n",
       "      <th>mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Using, long, ,, overly, complex, sentences, ,...</td>\n",
       "      <td>[a, lot, of, acronyms]</td>\n",
       "      <td>[lots, of, acronyms]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[If, you, write, your, next, piece, of, conten...</td>\n",
       "      <td>[If, you, write]</td>\n",
       "      <td>[So, before, you, write]</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4, ), Does, your, content, have, the, appropr...</td>\n",
       "      <td>[the, appropriate, tone]</td>\n",
       "      <td>[the, right, tone]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Is, it, acceptable, to, adopt, a, casual, ton...</td>\n",
       "      <td>[Is, it, acceptable]</td>\n",
       "      <td>[Is, it, ok]</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[It, is, okay, to, introduce, a, little, humor...</td>\n",
       "      <td>[It, is, okay]</td>\n",
       "      <td>[Is, it, ok]</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent  \\\n",
       "0  [Using, long, ,, overly, complex, sentences, ,...   \n",
       "1  [If, you, write, your, next, piece, of, conten...   \n",
       "2  [4, ), Does, your, content, have, the, appropr...   \n",
       "3  [Is, it, acceptable, to, adopt, a, casual, ton...   \n",
       "4  [It, is, okay, to, introduce, a, little, humor...   \n",
       "\n",
       "                       orig                      repl  \\\n",
       "0    [a, lot, of, acronyms]      [lots, of, acronyms]   \n",
       "1          [If, you, write]  [So, before, you, write]   \n",
       "2  [the, appropriate, tone]        [the, right, tone]   \n",
       "3      [Is, it, acceptable]              [Is, it, ok]   \n",
       "4            [It, is, okay]              [Is, it, ok]   \n",
       "\n",
       "                                                mark  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n",
       "1  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2               [0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]  \n",
       "3   [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "4  [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acro_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "acro_dict = {}\n",
    "for idx, row in acro_test_df.iterrows():\n",
    "    if ' '.join(row.orig) not in acro_dict:\n",
    "        acro_dict[' '.join(row.orig)] = ' '.join(row.repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{', and it is also clear that': 'which means that',\n",
       " ', as well': ', too',\n",
       " ', perhaps for': 'for',\n",
       " ', regardless of': 'no matter',\n",
       " ', therefore ,': 'so that',\n",
       " '. Both of those': ', both of which',\n",
       " '. However ,': ', though',\n",
       " 'A spoiler is that they': 'Spoiler alert : They',\n",
       " 'Actually': 'In fact',\n",
       " 'Additionally ,': 'And ,',\n",
       " 'Additionally , you need to': 'Plus you need to',\n",
       " 'Almost': 'nearly',\n",
       " 'Also': 'Plus',\n",
       " 'Also ,': 'And',\n",
       " 'Also , please': 'And please also',\n",
       " 'Also , thank you': 'And thanks',\n",
       " 'Also , we are': \"Plus , we 're\",\n",
       " 'Although he is not': \"And , even though he 's not\",\n",
       " 'And': 'Still ,',\n",
       " 'As an example': 'So , for example',\n",
       " 'As tools': 'While tools',\n",
       " 'At that point , it': 'It then',\n",
       " 'Be': 'Make',\n",
       " 'Be sure': 'So make sure',\n",
       " 'Be sure to': 'So make sure that you',\n",
       " 'Because': 'Since',\n",
       " 'Because I am': \"Since I 'm\",\n",
       " 'Because it is your': \"Since it 's your\",\n",
       " 'Because marketing materials': 'Since marketing materials',\n",
       " 'Begin': 'Start',\n",
       " 'Consider': 'Think of',\n",
       " 'Currently': 'Today',\n",
       " 'Currently ,': \"Today 's\",\n",
       " 'Despite the fact that': 'And yet even though',\n",
       " 'Do not call it': 'Never call it',\n",
       " 'Ensure': 'Make sure',\n",
       " 'Even if': 'And , as if',\n",
       " 'Even though': 'while',\n",
       " 'Even though it has gotten easier': 'Localization , however , has become easier',\n",
       " 'Everything': 'Really anything',\n",
       " 'First of all': 'First off',\n",
       " 'Focus on what matters most': 'Figure out what matters most',\n",
       " 'For example ,': 'Example :',\n",
       " 'For example , let me': 'Example : Let me',\n",
       " 'For example , there': 'Example : There',\n",
       " 'For example , what': 'Example : What',\n",
       " 'For example :': 'Example :',\n",
       " 'For instance ,': 'Example :',\n",
       " 'Forget about': 'Forget',\n",
       " 'Go see': 'Check out',\n",
       " 'Great balloon .': 'Nice balloon !',\n",
       " 'However': 'Admittedly',\n",
       " 'However ,': 'But',\n",
       " 'However , the reality is': 'But the reality is',\n",
       " \"I 'd prefer to\": 'Again , better',\n",
       " 'I am positive': \"I 'm sure\",\n",
       " 'I am sure': 'Surely',\n",
       " 'I apologize , but': 'Sorry',\n",
       " 'I believe it means': 'Alternate means',\n",
       " 'I feel like': 'Looks like',\n",
       " 'I hope': 'Hopefully',\n",
       " 'I hope that': 'Hopefully',\n",
       " 'I would like to': \"Let 's\",\n",
       " 'If': 'In case',\n",
       " 'If that is true': 'If so',\n",
       " 'If the answer is yes': 'If yes',\n",
       " 'If you write': 'So before you write',\n",
       " 'In addition': 'Plus ,',\n",
       " 'In addition ,': 'Plus ,',\n",
       " 'In addition , it has been': \"it 's also been\",\n",
       " 'In addition , it is': \"Still , it 's\",\n",
       " 'In addition , we can': 'We can also',\n",
       " 'In addition , you will': \"You 'll also\",\n",
       " 'In any case': 'Plus',\n",
       " 'In any case ,': 'Instead ,',\n",
       " 'In any case , you': 'And you',\n",
       " 'In either case': 'Instead',\n",
       " 'In my opinion': 'In my view',\n",
       " 'In my opinion ,': 'Yet',\n",
       " 'In order to': 'To',\n",
       " 'In order to do so': 'To do so',\n",
       " 'In order to do this': 'To do so',\n",
       " 'In order to earn it ,': 'To earn it ,',\n",
       " 'In order to find out': 'To find out',\n",
       " 'In order to help': 'To help',\n",
       " 'In order to make': 'To make',\n",
       " 'In our opinion': 'In our view',\n",
       " 'In that case': 'That way',\n",
       " 'In the meantime': 'Meanwhile',\n",
       " 'In the meantime ,': 'Meanwhile',\n",
       " 'In the next instance': 'Next',\n",
       " 'Is it acceptable': 'Is it ok',\n",
       " 'Is there any explaination to': 'Any guesses as to',\n",
       " 'It': 'That',\n",
       " 'It also refers to': 'It also means',\n",
       " 'It does not matter': 'Regardless of',\n",
       " 'It is': \"That 's\",\n",
       " 'It is better to': 'Better yet ,',\n",
       " 'It is important to pay attention': \"it 's critical to pay attention\",\n",
       " 'It is likely that': 'Chances are that',\n",
       " 'It is often possible': 'Unfortunately ,',\n",
       " 'It is okay': 'Is it ok',\n",
       " 'It is possible for them to understand': 'They can know',\n",
       " 'It is possible for you to have': 'Perhaps you have',\n",
       " 'It is possible that': 'Sure , maybe',\n",
       " 'It is possible to make': 'You can also make',\n",
       " 'It is simply another': 'Just another',\n",
       " 'It is the fact': \"we 're\",\n",
       " 'It makes it difficult': 'This makes it hard',\n",
       " 'It may be possible for them to': 'They may',\n",
       " 'It may be possible to': 'You can also',\n",
       " 'It may seem obvious': 'That may seem like an obvious point',\n",
       " 'It means that you': 'This means you',\n",
       " 'It seems as though': \"What 's more\",\n",
       " 'Just': 'Simply',\n",
       " 'Many': 'A lot of',\n",
       " 'Many people': 'Most people',\n",
       " 'Maybe': 'Maybe so',\n",
       " 'Most likely they are': \"They 're probably\",\n",
       " 'No one': 'Nobody',\n",
       " 'Now': 'And yet',\n",
       " 'Okay': 'Ok',\n",
       " 'Once you have': \"After you 've got\",\n",
       " 'Only free': 'Just free',\n",
       " 'People familiar with': 'Anyone familiar with',\n",
       " 'Perhaps': 'Maybe',\n",
       " 'Picture': 'Imagine',\n",
       " 'Please': \"Let 's\",\n",
       " 'Please remember ,': 'But hold on ,',\n",
       " 'Possibly loud': 'Maybe even loud',\n",
       " 'Rather than': 'Instead',\n",
       " 'Regardless of': 'And , no matter',\n",
       " 'Regardless of what': 'No matter what',\n",
       " 'Regardless of what you write': 'whatever you do write',\n",
       " 'Similar to': 'Like',\n",
       " 'Similar to how': 'Just like',\n",
       " 'Simply': 'Just',\n",
       " 'Some people': 'Some',\n",
       " 'Speak': 'Talk',\n",
       " 'Start out with': 'Start out by',\n",
       " 'Such as': 'For example',\n",
       " 'Take': 'Grab',\n",
       " 'Take a look': 'Just look',\n",
       " 'Taking under consideration that': 'Consider',\n",
       " 'Thank you': 'Thanks',\n",
       " 'The first thing is that': 'First ,',\n",
       " 'The majority': 'Most',\n",
       " 'The majority of': 'Most of',\n",
       " 'The majority of this is not': \"All of this is n't\",\n",
       " 'The problem is that': 'The thing is ,',\n",
       " 'There are': 'Here are',\n",
       " 'There are many great ideas': 'There are lots of great ideas',\n",
       " 'Think': 'Brainstorm',\n",
       " 'This': 'That',\n",
       " 'This includes': 'It includes',\n",
       " 'This is': \"Here 's\",\n",
       " 'This is our list': \"Here 's our list\",\n",
       " 'To be certain': 'To be sure ,',\n",
       " 'To begin': 'To start off',\n",
       " 'To begin with ,': 'Now ,',\n",
       " 'To start': 'For starters ,',\n",
       " 'Very well': 'Really',\n",
       " 'Virtually every': 'Nearly every',\n",
       " 'Wait a little bit': 'Now wait a second…',\n",
       " 'We often hear': 'We hear a lot',\n",
       " 'What': 'And how',\n",
       " 'What in the world': 'What the ...',\n",
       " 'What is the problem': \"So what 's the takeaway\",\n",
       " 'Whether or not': 'Whether',\n",
       " 'With': 'Then , using',\n",
       " 'With said that': 'Having said that',\n",
       " 'With that said': 'That said',\n",
       " 'Without further information': 'So , without further ado',\n",
       " 'Would we like': 'Want',\n",
       " 'Would you like': 'Want',\n",
       " 'Wow': 'Yikes',\n",
       " 'Yes': 'Yep',\n",
       " 'Yes ,': 'Sure ,',\n",
       " 'Yes , he': 'Sure he',\n",
       " 'You can': 'All you do is',\n",
       " 'You need to begin thinking': 'you need to start thinking',\n",
       " 'You should begin small': 'That said , start small',\n",
       " 'You should not ask': 'Not a big ask',\n",
       " 'You will find many': \"You 'll find lots\",\n",
       " 'Your website probably': 'Maybe your website',\n",
       " 'a certain amount': 'a considerable amount',\n",
       " 'a great thing': 'all great stuff',\n",
       " 'a large change': 'a huge change',\n",
       " 'a large opportunity': 'a huge opportunity',\n",
       " 'a long way': 'a long ways away',\n",
       " 'a lot': 'lots',\n",
       " 'a lot of acronyms': 'lots of acronyms',\n",
       " \"a person 's\": \"people 's\",\n",
       " 'a strong advantage': 'a clear advantage',\n",
       " 'actual': 'real',\n",
       " 'actually': 'really',\n",
       " 'advertisements': 'ads',\n",
       " 'advice': 'tips',\n",
       " 'ago': 'back',\n",
       " 'all of the time': 'every time',\n",
       " 'allow it': 'let it',\n",
       " 'allow us to': \"let 's\",\n",
       " 'allows us to': 'we use to',\n",
       " 'also': ', too',\n",
       " 'amount': 'dose',\n",
       " 'and so': \"that 's\",\n",
       " 'are able to': 'can',\n",
       " 'are many': \"'s a whole bunch of\",\n",
       " 'are not acquainted with': \"do n't actually know\",\n",
       " 'are unable to obtain': \"ca n't get\",\n",
       " 'as': 'like',\n",
       " 'as well': 'too',\n",
       " 'assist': 'help',\n",
       " 'assists': 'helps',\n",
       " 'at the worst time': 'at worst',\n",
       " 'attempting': 'trying',\n",
       " 'attractive': 'hot',\n",
       " 'avoid': 'stave off',\n",
       " 'be concerned': 'worry',\n",
       " 'be overlooked': 'get overlooked',\n",
       " 'be relocated': 'get turned on its head',\n",
       " 'become familiar with': 'know',\n",
       " 'begin': 'start',\n",
       " 'begins': 'starts',\n",
       " 'being able to get': 'getting',\n",
       " 'believe': 'think',\n",
       " 'believed': 'thought',\n",
       " 'big': 'huge',\n",
       " 'build': 'create',\n",
       " 'but': 'yet',\n",
       " 'but if we did not': \"however , if we did n't\",\n",
       " 'can be repaired': 'lacks',\n",
       " 'can not always be easy': \"is n't always easy\",\n",
       " 'certain': 'sticklers',\n",
       " 'certain thing': 'no-brainer',\n",
       " 'choose': 'take',\n",
       " 'correct': 'right',\n",
       " 'covered': 'covered guys',\n",
       " 'culture': 'culture like',\n",
       " 'decides': 'chose',\n",
       " 'demonstrate': 'show',\n",
       " 'describes': 'says',\n",
       " 'desire': 'want',\n",
       " 'develop': 'building',\n",
       " 'difficult': 'hard',\n",
       " 'disappear': 'slip through cracks',\n",
       " 'discover': 'find out',\n",
       " 'discuss': 'be talking about',\n",
       " 'discussing': 'talking about',\n",
       " 'doughnut': 'donuts',\n",
       " 'due to the fact that': 'because',\n",
       " 'enjoy': 'like',\n",
       " 'ensure': 'make sure',\n",
       " 'error': 'mistake',\n",
       " 'errors': 'mistakes',\n",
       " 'especially': 'particularly',\n",
       " 'everyone': 'everybody',\n",
       " 'excellent': 'really good',\n",
       " 'excitement': 'hype',\n",
       " 'explains': 'tells you',\n",
       " 'extravagant': 'slick',\n",
       " 'fairly': 'pretty',\n",
       " 'fairly big': 'pretty major',\n",
       " 'fast': 'quick',\n",
       " 'fine': 'all well and good',\n",
       " 'finished': 'done',\n",
       " 'foolish': 'a Fool',\n",
       " 'frequently': 'all of the time',\n",
       " 'from': 'out of',\n",
       " 'from the beginning': 'from start to finish',\n",
       " 'genuine': 'real',\n",
       " 'good': 'nifty',\n",
       " 'happen': 'come across',\n",
       " 'hard': 'a real challenge',\n",
       " 'have': 'get',\n",
       " 'how were we doing': \"how 'd we do\",\n",
       " 'however': 'Although',\n",
       " 'however ,': 'but',\n",
       " 'idea': 'trick',\n",
       " 'in my eyes': 'In my view',\n",
       " 'in my opinion': 'in my view',\n",
       " 'in our opinion': 'in our view',\n",
       " 'in this area': 'there',\n",
       " 'incorrect': 'wrong',\n",
       " 'individuals': 'people',\n",
       " 'inexpensive': 'cheap',\n",
       " 'is able to': 'can',\n",
       " 'is important': 'matters',\n",
       " 'is located': \"'s at\",\n",
       " 'issue': 'deal-breaker',\n",
       " 'it has': \"that 's\",\n",
       " 'it is': 'probably take',\n",
       " 'it is not': \"that 's not\",\n",
       " 'it is obvious that': 'yes ,',\n",
       " 'it is possible': \"it 's far likelier\",\n",
       " 'it is very important': \"it 's also important\",\n",
       " 'large': 'massive',\n",
       " 'larger': 'bigger',\n",
       " 'laugh': 'get a chuckle out',\n",
       " 'learn': 'figure out',\n",
       " 'less expensive': 'cheaper',\n",
       " 'limb , and': \"We 're\",\n",
       " 'list': 'radar',\n",
       " 'long conversations': 'long been talking',\n",
       " 'look': 'take a look',\n",
       " 'losing your credibility': 'putting your credibility on the line',\n",
       " 'makes it difficult': 'makes it harde',\n",
       " 'man': 'guy',\n",
       " 'manner': 'way',\n",
       " 'many': 'hundreds of',\n",
       " 'many different responsibilities': 'a lot of different responsibilities',\n",
       " 'may': 'might',\n",
       " 'may not': \"could n't\",\n",
       " 'might': 'may',\n",
       " 'misunderstand me': 'get me wrong',\n",
       " 'more difficult': 'harder',\n",
       " 'most enjoyable': 'best',\n",
       " 'most likely': 'probably',\n",
       " 'must': 'have to',\n",
       " 'need': 'have to',\n",
       " 'need to': \"we 'd like to\",\n",
       " 'needs to be': \"'s got to be\",\n",
       " 'no one': 'Nobody',\n",
       " 'numerous': 'lots of',\n",
       " 'obtain': 'get',\n",
       " 'odd': 'quirky',\n",
       " 'of assistance': 'helpful',\n",
       " 'often': 'a lot',\n",
       " 'okay': 'OK',\n",
       " 'on': 'on and on',\n",
       " 'only': 'just',\n",
       " 'only that': 'just that',\n",
       " 'opinion': 'view',\n",
       " 'opinions about': 'insights into',\n",
       " 'or': '/',\n",
       " 'other people': 'others',\n",
       " 'partaking': 'doing',\n",
       " 'partaking of': \"that 's\",\n",
       " 'people': 'folks',\n",
       " 'perhaps': 'maybe',\n",
       " 'physically subdue': 'tackle',\n",
       " 'please': \"So let 's\",\n",
       " 'prefer': 'like',\n",
       " 'problem': 'thing',\n",
       " 'problems': 'issues',\n",
       " 'provide': 'establish',\n",
       " 'pull': 'assemble',\n",
       " 'purchase': 'buy',\n",
       " 'purchasing': 'buying',\n",
       " 'pursuing': 'chasing',\n",
       " 'question': 'ask',\n",
       " 'quickly': 'fast',\n",
       " 'quite': 'really',\n",
       " 'rather than': 'Instead of',\n",
       " 'ready': 'ready to roll',\n",
       " 'reason': 'Why',\n",
       " 'reasons': 'why',\n",
       " 'received': 'got',\n",
       " 'referring to': 'talking about',\n",
       " 'regardless of': 'no matter',\n",
       " 'relax': 'Loosen Up',\n",
       " 'require': 'need',\n",
       " 'secret': 'secret sauce',\n",
       " 'see': 'stumble upon',\n",
       " 'see it': 'check it out',\n",
       " 'should': 'needs to',\n",
       " 'should require': 'needs to',\n",
       " 'silly': 'insane',\n",
       " 'simple': 'easy',\n",
       " 'simple to navigate': 'easy to navigate',\n",
       " 'simply': 'really',\n",
       " 'situation': 'findings',\n",
       " 'speak': 'talk',\n",
       " 'spectacular': 'great',\n",
       " 'start': 'begin',\n",
       " 'starting': 'just getting started',\n",
       " 'statistics': 'stats',\n",
       " 'such as': 'like',\n",
       " 'taught': 'taught to',\n",
       " 'technology': 'tech',\n",
       " 'thank you': 'thanks',\n",
       " 'that is': 'so',\n",
       " 'the appropriate tone': 'the right tone',\n",
       " 'the best thing you can do': 'your best bet',\n",
       " 'the information they require': 'the information they need',\n",
       " 'the majority': 'most',\n",
       " 'the most': 'best',\n",
       " 'the reason why': 'why',\n",
       " 'their size': \"whether they 're big or small\",\n",
       " 'therefore': 'so',\n",
       " 'they are correct': \"they 're right\",\n",
       " 'they are receiving': \"you 're giving them\",\n",
       " 'they have': 'for example',\n",
       " 'things': 'that stuff',\n",
       " 'think': 'reckon',\n",
       " 'thinking': 'convinced',\n",
       " 'to be accomplished': 'to be done',\n",
       " 'tons': 'lots',\n",
       " 'truly': 'really',\n",
       " 'truth': 'reality',\n",
       " 'turn out': 'crank out',\n",
       " 'type': 'kinds',\n",
       " 'types': 'lots of',\n",
       " 'understand': 'see',\n",
       " 'unusual': 'odd',\n",
       " 'usually': 'often',\n",
       " 'vehicle': 'cars',\n",
       " 'very': 'quite',\n",
       " 'very harsh': 'a 100-page monster',\n",
       " 'very important': 'so important',\n",
       " 'very useful . We': 'so useful , that we',\n",
       " 'was': 'got',\n",
       " 'we are': 'The fact is',\n",
       " 'we may be able to': 'we might be able to',\n",
       " 'we must not only know': 'we not only need to know',\n",
       " 'we will like to': \"we 'd like to\",\n",
       " 'what is happening': \"what 's going on\",\n",
       " 'what you need': \"what 's going to help\",\n",
       " 'will help us': 'allow us',\n",
       " 'will help you find a laugh': 'gave you a chuckle',\n",
       " 'with the fact that': 'that',\n",
       " 'with this': 'doing this',\n",
       " 'wonderful': 'great',\n",
       " 'work': 'work wonders',\n",
       " 'worth it': 'worth its weight in gold',\n",
       " 'would imply': 'means',\n",
       " 'would like': 'want',\n",
       " 'would like to': 'want to',\n",
       " 'would you like': 'Want',\n",
       " 'you are specifically doing': \"you 're actually doing\",\n",
       " 'you begin': 'you start',\n",
       " 'you do': \"do n't\",\n",
       " 'you must': \"you 've got to\",\n",
       " 'you need': \"you 've got\",\n",
       " 'you should': \"you 're best to\",\n",
       " 'you should be disappointed': \"you 're missing out on a big opportunity\",\n",
       " 'you should ensure that': 'make sure',\n",
       " 'you will': 'That means if',\n",
       " 'your ability to communicate': 'how you communicate',\n",
       " 'your content is not simply': \"your content is n't just\",\n",
       " 'your own': 'yours'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acro_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "441"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acro_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existing Acrolinx Gazetteers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This begins the dataset by collecting all the previously used gazetteers of formal words, with or without suggestions, in Acrolinx's databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/acrolinx_gzt/lf.json') as lfjson:\n",
    "    lf = json.load(lfjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/acrolinx_gzt/conv-words.json') as cvjson:\n",
    "    form_with_sugg = json.load(cvjson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unclean_gzt = []\n",
    "\n",
    "with open('data/acrolinx_gzt/archaicWords.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countFormalPhrases.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())\n",
    "\n",
    "with open('data/acrolinx_gzt/countLatinExpressions.gzt') as file:\n",
    "    unclean_gzt.extend(file.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gzt = {}\n",
    "\n",
    "# things i noticed and don't want\n",
    "exceptions = ['use either', '(']\n",
    "\n",
    "for item in unclean_gzt:\n",
    "    if item[0] == '@' or item[0] == '#':\n",
    "        continue\n",
    "    item = item.strip()\n",
    "    if len(item) < 1:\n",
    "        continue\n",
    "    trigger = False\n",
    "    for term in exceptions:\n",
    "        if term in item:\n",
    "            trigger = True\n",
    "    if trigger:\n",
    "        continue\n",
    "    item = re.sub('\\[', '', item)\n",
    "    item = re.sub('\\]', '', item)\n",
    "    item = re.sub('\\n', '', item)\n",
    "    item = re.sub(';', '', item)\n",
    "    if '-->' in item:\n",
    "        pair = [part.strip() for part in item.split('-->')]\n",
    "        if ',' in pair[0]:\n",
    "            form_words = [part.strip() for part in pair[0].split(',')]\n",
    "            for word in form_words:\n",
    "                gzt[word] = [part.strip() for part in pair[1].split(',')]\n",
    "        else:\n",
    "            gzt[pair[0]] = [part.strip() for part in pair[1].split(',')]\n",
    "    else:\n",
    "        gzt[item] = np.nan\n",
    "        \n",
    "# There are 597 items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formal</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>admissible</td>\n",
       "      <td>[allowed, accepted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the case of</td>\n",
       "      <td>[when]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>due to the fact that</td>\n",
       "      <td>[because]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>on request</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>contain</td>\n",
       "      <td>[has]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 formal          suggestions\n",
       "0            admissible  [allowed, accepted]\n",
       "1        in the case of               [when]\n",
       "2  due to the fact that            [because]\n",
       "3            on request                  NaN\n",
       "4               contain                [has]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formal = []\n",
    "informal = []\n",
    "\n",
    "for word in gzt:\n",
    "    formal.append(word)\n",
    "    informal.append(gzt[word])\n",
    "\n",
    "words = pd.DataFrame()\n",
    "words['formal'] = formal\n",
    "words['suggestions'] = informal\n",
    "words.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.to_pickle('data/acrolinx_gzt/clean_words.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microsoft Azure: Flagged Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, I had scanned the output of running Acrolinx on a large selection of Microsoft Azure documents, and gathered the formal words. Here I once more accessed those words and added them (without suggestions) to my list of words which have been confirmed as formal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/microsoft/words.pkl', 'rb') as f:\n",
    "    mic_words = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doe',\n",
       " 'on the other hand',\n",
       " 'ensuring',\n",
       " 'supported',\n",
       " 'architecture',\n",
       " 'grant',\n",
       " 'liaison',\n",
       " 'unrestricted',\n",
       " 'publish',\n",
       " 'xxxxx',\n",
       " 'enumerated',\n",
       " 'warrants',\n",
       " 'mobility',\n",
       " 'operation',\n",
       " 'excluding',\n",
       " 'confirm',\n",
       " 'multi-hop',\n",
       " 'decreased',\n",
       " 'substantial',\n",
       " 'in the event of',\n",
       " 'input',\n",
       " 'vice-versa',\n",
       " 'isolated',\n",
       " 'maximum',\n",
       " 'limitation',\n",
       " 'on a daily basis',\n",
       " 'entails',\n",
       " 'authorizing',\n",
       " 'enrichment',\n",
       " 'review',\n",
       " 'requested',\n",
       " 'strategize',\n",
       " 'override',\n",
       " 'anticipate',\n",
       " 'temperature',\n",
       " 'inquires',\n",
       " 'attain',\n",
       " 'reflect',\n",
       " 'partitioning',\n",
       " 'reside',\n",
       " 'expose',\n",
       " 'replicas',\n",
       " 'distribution',\n",
       " 'location',\n",
       " 'decreasing',\n",
       " 'binding',\n",
       " 'ascertaining',\n",
       " 'lest',\n",
       " 'recovery',\n",
       " 'provides guidance for',\n",
       " 'inception',\n",
       " 'datasets',\n",
       " 'prompt',\n",
       " 'in the case of',\n",
       " 'verification',\n",
       " 'releases',\n",
       " 'reports',\n",
       " 'item',\n",
       " 'contains',\n",
       " 'zones',\n",
       " 'constitutes',\n",
       " 'condition',\n",
       " 'in addition',\n",
       " 'transit',\n",
       " 'eg',\n",
       " 'possess',\n",
       " 'factors',\n",
       " 'percentage',\n",
       " 'aggregate',\n",
       " 'terminated',\n",
       " 'configurations',\n",
       " 'expedites',\n",
       " 'modified',\n",
       " 'in accordance with',\n",
       " 'discovering',\n",
       " 'requirements',\n",
       " 'endorses',\n",
       " 'were not',\n",
       " 'department',\n",
       " 'framework',\n",
       " 'definition',\n",
       " 'we are',\n",
       " 'ascertain',\n",
       " 'precondition',\n",
       " 'climate',\n",
       " 'diagnostic',\n",
       " 'amongst',\n",
       " 'adjustment',\n",
       " 'substitute',\n",
       " 'computes',\n",
       " 'exhibits',\n",
       " 'result',\n",
       " 'should not',\n",
       " 'retention',\n",
       " 'cornerstone',\n",
       " 'migrated',\n",
       " 'nonce',\n",
       " 'evidenced',\n",
       " 'omitting',\n",
       " 'purchase',\n",
       " 'protections',\n",
       " 'regulations',\n",
       " 'specifying',\n",
       " 'are writing to',\n",
       " 'request',\n",
       " 'if and when',\n",
       " 'equivalent',\n",
       " 'equally as',\n",
       " 'pertaining to',\n",
       " 'adjustments',\n",
       " 'on behalf of',\n",
       " 'maps',\n",
       " 'sources',\n",
       " 'reflected',\n",
       " 'delaying',\n",
       " 'notification',\n",
       " 'approval',\n",
       " 'delegated',\n",
       " 'simulated',\n",
       " 'export',\n",
       " 'phases',\n",
       " 'panel',\n",
       " 'alleviates',\n",
       " 'procuring',\n",
       " 'daunting',\n",
       " 'with regard to',\n",
       " 'they are',\n",
       " 'application',\n",
       " 'accompanied',\n",
       " 'obtaining',\n",
       " 'in all likelihood',\n",
       " 'decrease',\n",
       " 'utilization',\n",
       " 'declarations',\n",
       " 'regulation',\n",
       " 'exclusion',\n",
       " 'entity',\n",
       " 'property',\n",
       " 'components',\n",
       " 'establish',\n",
       " 'provider',\n",
       " 'was able to',\n",
       " 'optimum',\n",
       " 'increment',\n",
       " 'restriction',\n",
       " 'attaining',\n",
       " 'consolidated',\n",
       " 'distributions',\n",
       " 'equipment',\n",
       " 'extraction',\n",
       " 'logs',\n",
       " 'increasing',\n",
       " 'readiness',\n",
       " 'et al',\n",
       " 'remains',\n",
       " 'structure',\n",
       " 'hierarchical',\n",
       " 'minimum',\n",
       " 'whom',\n",
       " 'in between',\n",
       " 'certifying',\n",
       " 'linking',\n",
       " 'criteria',\n",
       " 'displayed',\n",
       " 'license',\n",
       " 'locations',\n",
       " 'communication',\n",
       " 'distinguishing',\n",
       " 'modifications',\n",
       " 'permits',\n",
       " 'an absence of',\n",
       " 'remainder',\n",
       " 'pipeline',\n",
       " 'conditional',\n",
       " 'updating',\n",
       " 'restrictions',\n",
       " 'assets',\n",
       " 'locally',\n",
       " 'alternative',\n",
       " 'residing',\n",
       " 'replacement',\n",
       " 'improvements',\n",
       " 'certificate',\n",
       " 'selection',\n",
       " 'protected',\n",
       " 'it  is',\n",
       " 'define',\n",
       " 'it appears',\n",
       " 'authorize',\n",
       " 'analyze',\n",
       " 'do not',\n",
       " 'obtained',\n",
       " 'was not',\n",
       " 'attempting',\n",
       " 'related',\n",
       " 'triggered',\n",
       " 'container',\n",
       " 'specifically',\n",
       " 'eg.',\n",
       " 'limitations',\n",
       " 'permitted',\n",
       " 'subsequently',\n",
       " 'acknowledged',\n",
       " 'assigned',\n",
       " 'comprise',\n",
       " 'provide guidance for',\n",
       " 'terminate',\n",
       " 'trigger',\n",
       " 'releasing',\n",
       " 'despite the fact that',\n",
       " 'maintains',\n",
       " 'currently',\n",
       " 'provisioning',\n",
       " 'abundance',\n",
       " 'capabilities',\n",
       " 'compliance',\n",
       " 'modify',\n",
       " 'database',\n",
       " 'enumerating',\n",
       " 'enables',\n",
       " 'programmatic',\n",
       " 'in relation to',\n",
       " 'range',\n",
       " 'investigate',\n",
       " 'state-of-the-art',\n",
       " 'due to',\n",
       " 'with reference to',\n",
       " 'agents',\n",
       " 'specified',\n",
       " 'et al.',\n",
       " 'exhibiting',\n",
       " 'connectivity',\n",
       " 'magnitude',\n",
       " 'does not',\n",
       " 'sample',\n",
       " 'encountering',\n",
       " 'exception',\n",
       " 'rendering',\n",
       " 'mr.',\n",
       " 'enumerate',\n",
       " 'precludes',\n",
       " 'viable',\n",
       " 'redundancy',\n",
       " 'detection',\n",
       " 'integrity',\n",
       " 'outputs',\n",
       " 'on request',\n",
       " 'etc',\n",
       " 'relocate',\n",
       " 'synopsis',\n",
       " 'breakdown',\n",
       " 'failed',\n",
       " 'expirations',\n",
       " 'subject to',\n",
       " 'procure',\n",
       " 'resides',\n",
       " 'above-mentioned',\n",
       " 'elected',\n",
       " 'entitlements',\n",
       " 'complying with',\n",
       " 'because of the fact that',\n",
       " 'designate',\n",
       " 'finalizing',\n",
       " 'consistent',\n",
       " 'whilst',\n",
       " 'attribute',\n",
       " 'analysis',\n",
       " 'expand',\n",
       " 'extensions',\n",
       " 'samples',\n",
       " 'enabling',\n",
       " 'tabular',\n",
       " 'as a result of',\n",
       " 'secondary',\n",
       " 'inaccurate',\n",
       " 'assign',\n",
       " 'assigning',\n",
       " 'services',\n",
       " 'in favor of',\n",
       " 'phase',\n",
       " 'close proximity',\n",
       " 'invoking',\n",
       " 'been able to',\n",
       " 'notifications',\n",
       " 'terminates',\n",
       " 'she will',\n",
       " 'compliant',\n",
       " 'for the purpose of',\n",
       " 'as prescribed by',\n",
       " 'provided that',\n",
       " 'regions',\n",
       " 'delineates',\n",
       " 'in terms of',\n",
       " 'newly',\n",
       " 'in excess of',\n",
       " 'convene',\n",
       " 'in the amount of',\n",
       " 'attempt',\n",
       " 'designated',\n",
       " 'invokes',\n",
       " 'alleviated',\n",
       " 'in the near future',\n",
       " 'expiration',\n",
       " 'explode',\n",
       " 'did not',\n",
       " 'operations',\n",
       " 'null',\n",
       " 'provide',\n",
       " 'exceeding',\n",
       " 'consolidates',\n",
       " 'one-time',\n",
       " 'operator',\n",
       " 'enumerates',\n",
       " 'fie',\n",
       " 'entities',\n",
       " 'alternatively',\n",
       " 'permitting',\n",
       " 'pools',\n",
       " 'products',\n",
       " 'thereby',\n",
       " 'encounters',\n",
       " 'is readable',\n",
       " 'begging',\n",
       " 'warranted',\n",
       " 'i.e.,',\n",
       " 'monitor',\n",
       " 'will not',\n",
       " 'policy',\n",
       " 'external',\n",
       " 'aforementioned',\n",
       " 'i have',\n",
       " 'you  will',\n",
       " 'delay',\n",
       " 'anomaly',\n",
       " 'limits',\n",
       " 'alleviate',\n",
       " 'applications',\n",
       " 'discovery',\n",
       " 'attains',\n",
       " 'proceed',\n",
       " 'at your earliest convenience',\n",
       " 'they will',\n",
       " 'exploded',\n",
       " 'authorization',\n",
       " 'asserted',\n",
       " 'deems',\n",
       " 'records',\n",
       " 'there is',\n",
       " 'unregistered',\n",
       " 'exemplifies',\n",
       " 'partitioned',\n",
       " 'prioritizes',\n",
       " 'removed',\n",
       " 'subset',\n",
       " 'render',\n",
       " 'supports',\n",
       " 'exposing',\n",
       " 'i.e.',\n",
       " 'is able to',\n",
       " 'certifies',\n",
       " 'categories',\n",
       " 'substituting',\n",
       " 'acknowledge',\n",
       " 'substituted',\n",
       " 'shall not',\n",
       " 'dual',\n",
       " 'due to the fact that',\n",
       " 'enforce',\n",
       " 'during the period',\n",
       " 'for a period of',\n",
       " 'access',\n",
       " 'types',\n",
       " 'high-level',\n",
       " 'yon',\n",
       " 'provision',\n",
       " 'federated',\n",
       " 'entail',\n",
       " 'exhibit',\n",
       " 'have the ability',\n",
       " 'profile',\n",
       " 'remediation',\n",
       " 'had the ability',\n",
       " 'as a means of',\n",
       " 'routing',\n",
       " 'deny',\n",
       " 'e.g.',\n",
       " 'remained',\n",
       " 'confirmation',\n",
       " 'credential',\n",
       " 'unverified',\n",
       " 'oversight',\n",
       " 'transactions',\n",
       " 'techniques',\n",
       " 'exposed',\n",
       " 'exemplify',\n",
       " 'fields',\n",
       " 'concurrent',\n",
       " 'caveat',\n",
       " 'ameliorate',\n",
       " 'scope',\n",
       " 'proxy',\n",
       " 'requesting',\n",
       " 'provisioned',\n",
       " 'terminating',\n",
       " 'depict',\n",
       " 'dataset',\n",
       " 'omitted',\n",
       " 'multiple',\n",
       " 'endeavor',\n",
       " 'provided',\n",
       " 'should you wish',\n",
       " 'cease',\n",
       " 'at the present time',\n",
       " 'be readable',\n",
       " 'function',\n",
       " 'region',\n",
       " 'guidance',\n",
       " 'authorizations',\n",
       " 'endpoints',\n",
       " 'domain',\n",
       " 'remain',\n",
       " 'has the option to',\n",
       " 'component',\n",
       " 'flow',\n",
       " 'thus',\n",
       " 'classification',\n",
       " 'accordingly',\n",
       " 'replication',\n",
       " 'facilitates',\n",
       " 'globally',\n",
       " 'provisions',\n",
       " 'prioritize',\n",
       " 'roles',\n",
       " 'desire',\n",
       " 'capacity',\n",
       " 'manifest',\n",
       " 'intent',\n",
       " 'operating',\n",
       " 'inside of',\n",
       " 'assessment',\n",
       " 'multi',\n",
       " 'it is',\n",
       " 'utilize',\n",
       " 'foremost',\n",
       " 'facilitated',\n",
       " 'is\\xa0not',\n",
       " 'proficiency',\n",
       " 'protection',\n",
       " 'applicability',\n",
       " 'we apologize',\n",
       " 'updatable',\n",
       " 'in the interim',\n",
       " 'in-situ',\n",
       " 'decreases',\n",
       " 'restrict',\n",
       " 'ie',\n",
       " 'actions',\n",
       " 'contain',\n",
       " 'in regard to',\n",
       " 'exceptions',\n",
       " 'attempts',\n",
       " 'duration',\n",
       " 'defines',\n",
       " 'you have',\n",
       " 'as well as',\n",
       " 'as soon as possible',\n",
       " 'at this point in time',\n",
       " 'status',\n",
       " 'providers',\n",
       " 'incident',\n",
       " 'configuration',\n",
       " 'ceases',\n",
       " \"'re writing to\",\n",
       " 'discontinues',\n",
       " 'whether or not',\n",
       " 'attempted',\n",
       " 'reflecting',\n",
       " 'retain',\n",
       " 'ad hoc',\n",
       " 'in the process of',\n",
       " 'enrollment',\n",
       " 'functional',\n",
       " 'prior to',\n",
       " 'registered',\n",
       " 'outside of',\n",
       " 'therefore',\n",
       " 'expedited',\n",
       " 'draft',\n",
       " 'tracing',\n",
       " 'composite',\n",
       " 'diagnostics',\n",
       " 'initialized',\n",
       " 'cannot',\n",
       " 'ensure',\n",
       " 'retained',\n",
       " 'consent',\n",
       " 'certificates',\n",
       " 'reference',\n",
       " 'reserved',\n",
       " 'deficiencies',\n",
       " 'regenerate',\n",
       " 'fails',\n",
       " 'secured',\n",
       " 'corresponding',\n",
       " 'additional',\n",
       " 'represented',\n",
       " 'interval',\n",
       " 'having the ability',\n",
       " 'identified',\n",
       " 'encounter',\n",
       " 'comprises',\n",
       " 'increase',\n",
       " 'prerequisite',\n",
       " 'thereof',\n",
       " 'depicts',\n",
       " 'inspect',\n",
       " 'continuous',\n",
       " 'in a timely manner',\n",
       " 'sensitivity',\n",
       " 'parent',\n",
       " 'logistic',\n",
       " 'staging',\n",
       " 'revision',\n",
       " 'transformations',\n",
       " 'anticipates',\n",
       " 'as yet',\n",
       " 'facilitate',\n",
       " 'first and foremost',\n",
       " 'exceeded',\n",
       " 'repatriation',\n",
       " 'identifier',\n",
       " 'desires',\n",
       " 'adaptive',\n",
       " 'depicted',\n",
       " 'prerequisites',\n",
       " 'numerous',\n",
       " 'unique',\n",
       " 'exceed',\n",
       " 'resided',\n",
       " 'endorsed',\n",
       " 'utilizing',\n",
       " 'units',\n",
       " 'delayed',\n",
       " 'mobile',\n",
       " 'exhibited',\n",
       " 'you  are',\n",
       " 'foregoing',\n",
       " 'it is requested',\n",
       " 'completed',\n",
       " 'reported',\n",
       " 'attest',\n",
       " 'expanded',\n",
       " 'variable',\n",
       " 'listing',\n",
       " 'vulnerability',\n",
       " 'requests',\n",
       " 'acquisition',\n",
       " 'previously',\n",
       " 'relocating',\n",
       " 'possessing',\n",
       " 'valid',\n",
       " 'retaining',\n",
       " 'irrespective',\n",
       " 'consolidate',\n",
       " 'dependency',\n",
       " 'discovers',\n",
       " 'findings',\n",
       " 'provides',\n",
       " 'systems',\n",
       " 'functions',\n",
       " 'codes',\n",
       " 'objectives',\n",
       " 'purchasing',\n",
       " 'adoption',\n",
       " 'extend',\n",
       " 'with the exception of',\n",
       " 'method',\n",
       " 'audited',\n",
       " 'complete',\n",
       " 'certify',\n",
       " 'comprising',\n",
       " 'section',\n",
       " 'display',\n",
       " 'approve',\n",
       " 'compute',\n",
       " 'omits',\n",
       " 'specification',\n",
       " 'ensures',\n",
       " 'assess',\n",
       " 'deemed',\n",
       " 'degraded',\n",
       " 'aggregation',\n",
       " 'bulk',\n",
       " 'procedure',\n",
       " 'estimated',\n",
       " 'delineated',\n",
       " 'purchases',\n",
       " 'he has',\n",
       " 'alternate',\n",
       " 'controls',\n",
       " 'invoked',\n",
       " 'registration',\n",
       " 'in an effort to',\n",
       " 'array',\n",
       " 'initiating',\n",
       " 'purchased',\n",
       " 'i am',\n",
       " 'elicited',\n",
       " 'discontinue',\n",
       " 'beverage',\n",
       " 'policies',\n",
       " 'event',\n",
       " 'containers',\n",
       " 'encode',\n",
       " 'associate',\n",
       " 'properties',\n",
       " 'as of',\n",
       " 'forbids',\n",
       " 'anticipating',\n",
       " 'operators',\n",
       " 'has not',\n",
       " 'tests',\n",
       " 'authorizes',\n",
       " 'discontinuing',\n",
       " 'is writing to',\n",
       " 'advanced',\n",
       " 'universally',\n",
       " 'successfully',\n",
       " 'perform',\n",
       " 'redundant',\n",
       " 'equitable',\n",
       " 'hereby',\n",
       " 'pin number',\n",
       " 'it is essential',\n",
       " 'reflects',\n",
       " 'acknowledges',\n",
       " 'residence',\n",
       " 'administration',\n",
       " 'hybrid',\n",
       " 'remaining',\n",
       " 'attesting',\n",
       " 'flexibility',\n",
       " 'disclosing',\n",
       " 'have the option to',\n",
       " 'sequential',\n",
       " 'regarding',\n",
       " 'in order to',\n",
       " 'govern',\n",
       " 'certified',\n",
       " 'derived',\n",
       " 'internal',\n",
       " 'detailed',\n",
       " 'departs',\n",
       " 'are readable',\n",
       " 'forwarding',\n",
       " 'hubs',\n",
       " 'delays',\n",
       " 'automatic',\n",
       " 'forbidden',\n",
       " 'inputs',\n",
       " 'import',\n",
       " 'compatibility',\n",
       " 'capable of',\n",
       " 'activated',\n",
       " 'established',\n",
       " 'generate',\n",
       " 'large quantities of',\n",
       " 'procured',\n",
       " 'implicit',\n",
       " 'had not',\n",
       " 'anticipated',\n",
       " 'delineate',\n",
       " 'pursuant to',\n",
       " 'hence',\n",
       " 'warrant',\n",
       " 'you will',\n",
       " 'are not',\n",
       " 'finalized',\n",
       " 'verifies',\n",
       " 'profiles',\n",
       " 'primary',\n",
       " 'activity',\n",
       " 'placement',\n",
       " 'reliable',\n",
       " 'allocated',\n",
       " 'acknowledgement',\n",
       " 'capability',\n",
       " 'on the basis of',\n",
       " 'anomalous',\n",
       " 'with respect to',\n",
       " 'credentials',\n",
       " 'alleviating',\n",
       " 'successfully complete',\n",
       " 'precluded',\n",
       " 'summary',\n",
       " 'invoke',\n",
       " 'specify',\n",
       " 'in some instances',\n",
       " 'refer back',\n",
       " 'elicit',\n",
       " 'modifies',\n",
       " 'requiring',\n",
       " 'unauthorized',\n",
       " 'retains',\n",
       " 'by virtue of',\n",
       " 'endpoint',\n",
       " 'recipients',\n",
       " 'mrs.',\n",
       " 'output',\n",
       " 'omit',\n",
       " 'in lieu of',\n",
       " 'acknowledging',\n",
       " 'devices',\n",
       " 'eventual',\n",
       " 'discontinued',\n",
       " 'whereas',\n",
       " 'constitute',\n",
       " 'television',\n",
       " 'gateway',\n",
       " 'finalize',\n",
       " 'etc.',\n",
       " 'whatsoever',\n",
       " 'required',\n",
       " 'designates',\n",
       " 'migration',\n",
       " 'nevertheless',\n",
       " 'rule',\n",
       " 'representing',\n",
       " 'servicing',\n",
       " 'by means of',\n",
       " 'permit',\n",
       " 'we will',\n",
       " 'initiate',\n",
       " 'acknowledgment',\n",
       " 'regardless',\n",
       " 'as of yet',\n",
       " 'domains',\n",
       " 'administrative',\n",
       " 'deactivate',\n",
       " 'he will',\n",
       " 'zone',\n",
       " 'portal',\n",
       " 'indicators',\n",
       " 'stages',\n",
       " 'revocation',\n",
       " 'obligates',\n",
       " 'administrator',\n",
       " 'adjacent to',\n",
       " 'validation',\n",
       " 'mitigation',\n",
       " 'being able to',\n",
       " 'comprised',\n",
       " 'expired',\n",
       " 'released',\n",
       " 'you are requested',\n",
       " 'please note that',\n",
       " 'testing',\n",
       " 'accrue',\n",
       " 'impacted',\n",
       " 'mandatory',\n",
       " 'interpretation',\n",
       " 'afore',\n",
       " 'top-level',\n",
       " 'complies with',\n",
       " 'commences',\n",
       " 'behavioral',\n",
       " 'atomic',\n",
       " 'stored',\n",
       " 'pending',\n",
       " 'usage',\n",
       " 'we have',\n",
       " 'allocate',\n",
       " 'during the time that',\n",
       " 'exposes',\n",
       " 'transaction',\n",
       " 'automation',\n",
       " 'preclude',\n",
       " 'consensus',\n",
       " 'inexpensive',\n",
       " 'volume',\n",
       " 'licenses',\n",
       " 'represents',\n",
       " 'specifications',\n",
       " 'distinguish',\n",
       " 'encountered',\n",
       " 'prioritizing',\n",
       " 'recommended',\n",
       " 'characteristic',\n",
       " 'they have',\n",
       " 'parameter',\n",
       " 'expended',\n",
       " 'permanent',\n",
       " 'initiative',\n",
       " 'element',\n",
       " 'analyzer',\n",
       " 'responses',\n",
       " 'allocating',\n",
       " 'deletion',\n",
       " 'have not',\n",
       " 'stipulated',\n",
       " 'none',\n",
       " 'verify',\n",
       " 'make an effort',\n",
       " 'stability',\n",
       " 'procedural',\n",
       " 'consolidating',\n",
       " 'platforms',\n",
       " 'appropriate',\n",
       " 'hereafter',\n",
       " 'per se',\n",
       " 'bind',\n",
       " 'deployment',\n",
       " 'documentation',\n",
       " 'accompanies',\n",
       " 'agent',\n",
       " 'necessitates',\n",
       " 'desired',\n",
       " 'relevant',\n",
       " 'distinguishes',\n",
       " 'determine',\n",
       " 'exceeds',\n",
       " 'response',\n",
       " 'mapping',\n",
       " 'limit',\n",
       " 'repositories',\n",
       " 'initiates',\n",
       " 'ingestion',\n",
       " 'in view of',\n",
       " 'include',\n",
       " 'integration',\n",
       " 'herein',\n",
       " 'anew',\n",
       " 'distinguished',\n",
       " 'reviewing',\n",
       " 'identify with',\n",
       " 'efficiency',\n",
       " \"'re able to\",\n",
       " 'target',\n",
       " 'subsequent',\n",
       " 'constituted',\n",
       " 'considerations',\n",
       " 'thereafter',\n",
       " 'monitoring',\n",
       " 'device',\n",
       " 'conceptual',\n",
       " 'serial',\n",
       " 'comply with',\n",
       " 'restore',\n",
       " 'direct',\n",
       " 'initial',\n",
       " 'affected',\n",
       " 'accompanying',\n",
       " 'a variety of',\n",
       " 'obtain',\n",
       " 'delivery',\n",
       " 'would not',\n",
       " 'active',\n",
       " 'global',\n",
       " 'to summarize',\n",
       " 'deactivated',\n",
       " 'substitutes',\n",
       " 'encompass',\n",
       " 'accrued',\n",
       " 'registrations',\n",
       " 'infrastructure',\n",
       " 'processing',\n",
       " 'expediting',\n",
       " 'initiated',\n",
       " 'requirement',\n",
       " 'transferred',\n",
       " 'conditions',\n",
       " 'she is',\n",
       " 'is authorized to',\n",
       " 'investigation',\n",
       " 'identical',\n",
       " 'resource',\n",
       " 'represent',\n",
       " 'magnitudes',\n",
       " 'dynamic',\n",
       " 'imported',\n",
       " 'nb',\n",
       " 'manifests',\n",
       " 'inactive',\n",
       " 'are able to',\n",
       " 'appreciable',\n",
       " 'in regards to',\n",
       " 'branches',\n",
       " 'endorse',\n",
       " 'validate',\n",
       " 'accelerated',\n",
       " 'register',\n",
       " 'operational',\n",
       " 'apparent',\n",
       " 'state',\n",
       " 'accurate',\n",
       " 'she has',\n",
       " 'evaluation',\n",
       " 'he is',\n",
       " 'transfers',\n",
       " 'is not',\n",
       " 'commence',\n",
       " 'vehicles',\n",
       " 'nominate',\n",
       " 'ceased',\n",
       " 'regional',\n",
       " 'necessitating',\n",
       " 'repository',\n",
       " 'were able to',\n",
       " 'therein',\n",
       " 'facilitating',\n",
       " 'performed',\n",
       " 'accessibility',\n",
       " 'be advised',\n",
       " 'enabled',\n",
       " 'synchronization',\n",
       " 'total',\n",
       " 'central',\n",
       " 'warehousing',\n",
       " 'ternary',\n",
       " 'objective',\n",
       " 'instances',\n",
       " 'scheduling',\n",
       " 'maintain',\n",
       " 'triggers',\n",
       " 'providing',\n",
       " 'obtains',\n",
       " 'maintenance',\n",
       " 'fore',\n",
       " 'selected',\n",
       " 'is responsible for',\n",
       " 'relocated',\n",
       " 'and/or',\n",
       " 'incompatible',\n",
       " 'extension',\n",
       " 'processes',\n",
       " 'evaluate',\n",
       " 'accrues',\n",
       " 'extract',\n",
       " 'allocates',\n",
       " 'entitlement',\n",
       " 'allocation',\n",
       " 'articulated',\n",
       " 'circuit',\n",
       " 'moreover',\n",
       " 'requesters',\n",
       " 'degradation',\n",
       " 'execution',\n",
       " 'parameters',\n",
       " 'possesses',\n",
       " 'existing',\n",
       " 'expedite',\n",
       " 'manifested',\n",
       " 'endeavors',\n",
       " 'definitely',\n",
       " 'tiering',\n",
       " 'specifies',\n",
       " 'relative to',\n",
       " 'identities',\n",
       " 'hub',\n",
       " 'disclosed',\n",
       " 'discovered',\n",
       " 'performing',\n",
       " 'has the ability',\n",
       " 'registry',\n",
       " 'discover',\n",
       " 'initiator',\n",
       " 'designating',\n",
       " 'embodies',\n",
       " 'methods',\n",
       " 'performs',\n",
       " 'large-scale',\n",
       " 'vice versa',\n",
       " 'accompany',\n",
       " 'i will',\n",
       " 'select',\n",
       " 'obligated',\n",
       " 'authorized',\n",
       " 'predictive',\n",
       " 'audit',\n",
       " 'forbid',\n",
       " 'rendered',\n",
       " 'routes',\n",
       " 'activation',\n",
       " 'prioritized',\n",
       " 'storage',\n",
       " 'stipulate',\n",
       " 'could not',\n",
       " 'invalid',\n",
       " 'contained',\n",
       " 'you are',\n",
       " 'containing',\n",
       " 'release',\n",
       " 'ensured',\n",
       " 'spatial',\n",
       " 'attributes',\n",
       " 'elect',\n",
       " 'certainty',\n",
       " 'applicable',\n",
       " 'be able to',\n",
       " 'accruing',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_words = list(set([str(x).strip().lower() for x in list(mic_words)]))\n",
    "mic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sugg = [np.nan] * len(mic_words)\n",
    "sugg += list(words_df['suggestions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_words += list(words_df['formal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mic_df = pd.DataFrame()\n",
    "mic_df['words'] = mic_words\n",
    "mic_df['sugg'] = sugg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>sugg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>compute</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>ensuring</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>integrity</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>requesters</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>e.g.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>permitted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>invokes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>request</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>devices</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>apparent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words sugg\n",
       "644      compute  NaN\n",
       "1499    ensuring  NaN\n",
       "898    integrity  NaN\n",
       "194   requesters  NaN\n",
       "1483        e.g.  NaN\n",
       "90     permitted  NaN\n",
       "649      invokes  NaN\n",
       "1254     request  NaN\n",
       "693      devices  NaN\n",
       "913     apparent  NaN"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mic_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_df.to_pickle('data/lexical_repl/all_words_clean.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extrapolation Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pretrained Google News word2vec embeddings, add to the existing dataframe with word vectors (if they are in the vocabulary) for each of the formal words and their informal suggestions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_pickle('data/lexical_repl/all_words_clean.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('/home/rebekah/Documents/Word Embeddings/GoogleNews-vectors-negative300.bin', binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_word_lists(wl, embed, one_word_only = False):\n",
    "    if len(wl) == 1:\n",
    "        if wl[0] in embed:\n",
    "            return embed[wl[0]]\n",
    "    elif len(wl) > 1 and one_word_only == False:\n",
    "        vecs = [0.0] * len(embed['word'])\n",
    "        for w in wl:\n",
    "            if w in embed:\n",
    "                vecs = list(map(sum, zip(vecs, embed[w])))\n",
    "        if vecs != [0.0] * len(embed['word']):\n",
    "            return vecs\n",
    "    return np.nan\n",
    "\n",
    "def make_data(df, embed, X, y, one_word_only = False):\n",
    "    X_ph = np.nan * len(df)\n",
    "    y_ph = np.nan * len(df)\n",
    "    df[X] = X_ph\n",
    "    df[X] = df[X].astype(object)\n",
    "    df[y] = y_ph\n",
    "    df[y] = df[y].astype(object)\n",
    "    \n",
    "    for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "        formal_words = nltk.word_tokenize(row['words'])\n",
    "        df.at[idx, X] = process_word_lists(formal_words, embed, one_word_only) \n",
    "        informal_words = []\n",
    "        if type(row['sugg']) != float:\n",
    "            for word in row['sugg']:\n",
    "                word = nltk.word_tokenize(word)\n",
    "                word = process_word_lists(word, embed, one_word_only)\n",
    "                informal_words.append(word)\n",
    "        if len(informal_words) > 0:\n",
    "            df.at[idx, y] = informal_words[0]\n",
    "                \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae306b85fea46edb19c14d0d93aea8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = make_data(words_df, w2v, 'X_w2v', 'y_w2v', one_word_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>sugg</th>\n",
       "      <th>X_w2v</th>\n",
       "      <th>y_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>fore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.018798828, 0.123046875, -0.03100586, -0.125...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>distributions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.18066406, -0.15429688, -0.024414062, 0.3339...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>invoke</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.2734375, 0.23828125, 0.19726562, 0.078125, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>attempt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.20410156, 0.15820312, -0.05419922, -0.00970...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>cornerstone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.01977539, 0.09765625, 0.07373047, 0.203125,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>pending</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.16601562, 0.06640625, 0.29101562, -0.273437...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>item</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.024291992, 0.010803223, -0.107421875, 0.302...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>initiate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.21386719, 0.015991211, 0.096191406, 0.1259...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>acknowledge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.16601562, -0.13183594, -0.15625, 0.1367187...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>decreased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.2578125, -0.140625, -0.23925781, 0.0893554...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              words sugg                                              X_w2v  \\\n",
       "1242           fore  NaN  [0.018798828, 0.123046875, -0.03100586, -0.125...   \n",
       "1584  distributions  NaN  [0.18066406, -0.15429688, -0.024414062, 0.3339...   \n",
       "1529         invoke  NaN  [0.2734375, 0.23828125, 0.19726562, 0.078125, ...   \n",
       "769         attempt  NaN  [0.20410156, 0.15820312, -0.05419922, -0.00970...   \n",
       "936     cornerstone  NaN  [0.01977539, 0.09765625, 0.07373047, 0.203125,...   \n",
       "1214        pending  NaN  [0.16601562, 0.06640625, 0.29101562, -0.273437...   \n",
       "559            item  NaN  [0.024291992, 0.010803223, -0.107421875, 0.302...   \n",
       "1465       initiate  NaN  [-0.21386719, 0.015991211, 0.096191406, 0.1259...   \n",
       "2046    acknowledge  NaN  [-0.16601562, -0.13183594, -0.15625, 0.1367187...   \n",
       "91        decreased  NaN  [-0.2578125, -0.140625, -0.23925781, 0.0893554...   \n",
       "\n",
       "     y_w2v  \n",
       "1242   NaN  \n",
       "1584   NaN  \n",
       "1529   NaN  \n",
       "769    NaN  \n",
       "936    NaN  \n",
       "1214   NaN  \n",
       "559    NaN  \n",
       "1465   NaN  \n",
       "2046   NaN  \n",
       "91     NaN  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.dropna(subset=['X_w2v']).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set words aside to manually go over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I put the resulting word lists into two different formats: a text file to potentially use with doccano, and a CSV to open in Excel for manual work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4965a2bfe0484c86bebb37589b20097b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('data/lexical_repl/doccano_to_check.txt', 'w') as f:\n",
    "    for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "        if row['pred_w2v'] != None:\n",
    "            ans = ''\n",
    "            for item in row['pred_w2v']:\n",
    "                ans += item[0] + '\\t'\n",
    "            f.write(row['words'].upper() + '\\t' + ans + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n"
     ]
    }
   ],
   "source": [
    "with open('data/lexical_repl/doccano_to_check.txt', 'r') as f:\n",
    "    tests = f.readlines()\n",
    "print(len(tests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tuples = []\n",
    "\n",
    "for item in tests:\n",
    "    split = item.split('\\t')[:-1]\n",
    "    test_tuples.append((split[0], split[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1865\n",
      "996\n"
     ]
    }
   ],
   "source": [
    "words = [tup[0] for tup in test_tuples]\n",
    "print(len(words))\n",
    "words = list(set(words))\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16600ed27781449d859f1fab59fadc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=996), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_sets = defaultdict(list)\n",
    "\n",
    "for item in tqdm(words):\n",
    "    for pair in test_tuples:\n",
    "        if pair[0] == item:\n",
    "            for possible in pair[1]:\n",
    "                new_sets[item].append(possible)\n",
    "                \n",
    "for term in new_sets:\n",
    "    new_sets[term] = list(set([x.lower() for x in new_sets[term]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_be_checked = pd.DataFrame.from_dict(new_sets, \n",
    "                                       orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_checked.to_csv('data/microsoft/to_be_checked.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unused: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, to find most similar words one would use simple vector addition using the gensim most_similar function. This approach uses a basic linear regression model to add complexity to the predictions in an attempt to make them more comprehensive and accurate. With such high-dimensional features thanks to word2vec and a very small training set, results can't be expected to be amazing and are almost certainly overfit (see the 99.9% accuracy on training set), but the hope is that they could be better than the simple vector addition approach.\n",
    "\n",
    "(Unused as results were unexciting.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = words_df.dropna() # only the words that have suggestions and vectors for both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in train.iterrows():\n",
    "    assert len(row['X_w2v']) == 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(train['X_w2v']))\n",
    "y = np.array(list(train['y_w2v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:420: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999999999982279"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the trained linear regression model is used to give a list of possibilities for each of the non-training-set words; that is, each of the formal words that did not already have a suggestion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(word):\n",
    "    pred = lr.predict([word]).reshape(-1, 1)\n",
    "    pred = pred.reshape(300,)\n",
    "    return w2v.similar_by_vector(pred, topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea2d9c32b284b269dba95152a0da82e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict for all other words\n",
    "\n",
    "w2v_pred = []\n",
    "\n",
    "for idx, row in tqdm(words_df.iterrows(), total=len(words_df)):\n",
    "    if type(row['X_w2v']) == float:\n",
    "        w2v_pred.append(None)\n",
    "        #formal = nltk.word_tokenize(row['words'])\n",
    "        #vec = process_word_lists(formal, w2v, one_word_only = True)\n",
    "        #if type(vec) == float:\n",
    "        #    w2v_pred.append(np.nan)\n",
    "        #else:\n",
    "        #    w2v_pred.append(predict(vec))\n",
    "    else:\n",
    "        w2v_pred.append(predict(row['X_w2v']))\n",
    "\n",
    "words_df['pred_w2v'] = w2v_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(df, num = 10):\n",
    "    current = 0\n",
    "    for idx, row in df.sample(frac=1).iterrows():\n",
    "        if current > num:\n",
    "            break\n",
    "        train = type(row['y_w2v']) != float\n",
    "        if train:\n",
    "            continue\n",
    "        print('Original Word:\\t' + row['words'])\n",
    "        #print('Training Data?:\\t' + str(train))\n",
    "        if type(row['sugg']) != float:\n",
    "            print('Given Answer:\\t' + str(row['sugg']))\n",
    "        else:\n",
    "            print()\n",
    "        if type(row['pred_w2v']) != float:\n",
    "            ans = ''\n",
    "            for item in row['pred_w2v']:\n",
    "                ans += item[0] + '\\t' + str('%s' % float('%.3g' % item[1])) + '\\n\\t\\t'\n",
    "            print('Pred Answers:\\t' + ans)\n",
    "        current += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Word:\tyon\n",
      "\n",
      "Pred Answers:\tthink\t0.511\n",
      "\t\tknow\t0.51\n",
      "\t\tchoose\t0.479\n",
      "\t\tguess\t0.469\n",
      "\t\tsuppose\t0.462\n",
      "\t\tMARK_LATHAM_OPPOSITION_LEADER\t0.459\n",
      "\t\tdo\t0.458\n",
      "\t\tBEGALA\t0.453\n",
      "\t\tMr._NAVARRETTE\t0.451\n",
      "\t\tRENDELL_Well\t0.451\n",
      "\t\t\n",
      "Original Word:\ttelevision\n",
      "Given Answer:\t['T.V.']\n",
      "Pred Answers:\tmany\t0.563\n",
      "\t\tnowadays\t0.465\n",
      "\t\tlaypersons_alike\t0.446\n",
      "\t\toften\t0.437\n",
      "\t\tsimplifiers\t0.424\n",
      "\t\tsimplistic_notions\t0.423\n",
      "\t\tloathe\t0.422\n",
      "\t\tTh_ere\t0.419\n",
      "\t\tculturally_ingrained\t0.416\n",
      "\t\thesays\t0.414\n",
      "\t\t\n",
      "Original Word:\tcomponents\n",
      "\n",
      "Pred Answers:\tJin_Qi\t0.324\n",
      "\t\tprebuilt_templates\t0.317\n",
      "\t\talso\t0.311\n",
      "\t\tability\t0.309\n",
      "\t\tease\t0.304\n",
      "\t\tStrikers_Charged\t0.299\n",
      "\t\tLUCRF\t0.292\n",
      "\t\telectromechanical_steering\t0.292\n",
      "\t\tsturdiness\t0.286\n",
      "\t\trappel_tower\t0.285\n",
      "\t\t\n",
      "Original Word:\tresource\n",
      "\n",
      "Pred Answers:\tmeet\t0.382\n",
      "\t\tease\t0.357\n",
      "\t\tuse\t0.354\n",
      "\t\tutilize\t0.352\n",
      "\t\tpurchase\t0.345\n",
      "\t\toutplace\t0.341\n",
      "\t\tselect\t0.339\n",
      "\t\tNSLI_Y\t0.333\n",
      "\t\tworkwith\t0.327\n",
      "\t\treasonable\t0.326\n",
      "\t\t\n",
      "Original Word:\tenumerate\n",
      "\n",
      "Pred Answers:\tcount\t1.0\n",
      "\t\tcounts\t0.689\n",
      "\t\tcounted\t0.594\n",
      "\t\tcounting\t0.533\n",
      "\t\ttally\t0.526\n",
      "\t\tself_effacement_literary\t0.512\n",
      "\t\tthrowing_hittable_pitches\t0.491\n",
      "\t\tAsdrubal_Cabrera_bunted\t0.479\n",
      "\t\tCount\t0.467\n",
      "\t\ttotals\t0.457\n",
      "\t\t\n",
      "Original Word:\tacknowledge\n",
      "\n",
      "Pred Answers:\tsay\t0.594\n",
      "\t\tbelieve\t0.498\n",
      "\t\tthink\t0.47\n",
      "\t\targue\t0.468\n",
      "\t\twarn\t0.462\n",
      "\t\tknow\t0.43\n",
      "\t\ttell\t0.402\n",
      "\t\tremain_unconvinced\t0.4\n",
      "\t\tsee\t0.396\n",
      "\t\tsuggest\t0.392\n",
      "\t\t\n",
      "Original Word:\tspecified\n",
      "\n",
      "Pred Answers:\tregardless\t0.504\n",
      "\t\tirrespective\t0.444\n",
      "\t\twhichever\t0.44\n",
      "\t\tvast_majority\t0.438\n",
      "\t\tchoose\t0.432\n",
      "\t\tleast\t0.422\n",
      "\t\tone\t0.411\n",
      "\t\tgreatest\t0.405\n",
      "\t\tsame\t0.405\n",
      "\t\tmultiple\t0.399\n",
      "\t\t\n",
      "Original Word:\tdiscovering\n",
      "\n",
      "Pred Answers:\tdo\t0.415\n",
      "\t\tunderstand\t0.407\n",
      "\t\tanymore\t0.392\n",
      "\t\torient\t0.39\n",
      "\t\ttell\t0.387\n",
      "\t\tknow\t0.381\n",
      "\t\tThatÕs\t0.376\n",
      "\t\treally\t0.375\n",
      "\t\tjust\t0.372\n",
      "\t\tmeet\t0.372\n",
      "\t\t\n",
      "Original Word:\toperational\n",
      "\n",
      "Pred Answers:\tuse\t0.45\n",
      "\t\tdeploy\t0.391\n",
      "\t\t_Creating\t0.37\n",
      "\t\tLumeta_empowers_large\t0.367\n",
      "\t\toperate\t0.36\n",
      "\t\temploy\t0.359\n",
      "\t\tutilize\t0.352\n",
      "\t\tprioritize\t0.349\n",
      "\t\tallow\t0.346\n",
      "\t\taffect\t0.345\n",
      "\t\t\n",
      "Original Word:\texception\n",
      "\n",
      "Pred Answers:\twarning\t0.535\n",
      "\t\twarnings\t0.43\n",
      "\t\talert\t0.404\n",
      "\t\talso\t0.383\n",
      "\t\talerting\t0.35\n",
      "\t\thowever\t0.337\n",
      "\t\tKeri_Embry\t0.337\n",
      "\t\tPuddles_formed\t0.333\n",
      "\t\tprompting\t0.329\n",
      "\t\tadvising\t0.324\n",
      "\t\t\n",
      "Original Word:\tprocure\n",
      "\n",
      "Pred Answers:\tbuy\t0.489\n",
      "\t\tprocure\t0.475\n",
      "\t\tsell\t0.471\n",
      "\t\tget\t0.447\n",
      "\t\tobtain\t0.441\n",
      "\t\tuse\t0.428\n",
      "\t\tpurchase\t0.416\n",
      "\t\talso\t0.4\n",
      "\t\tinstall_microgeneration\t0.397\n",
      "\t\tdistribute\t0.393\n",
      "\t\t\n"
     ]
    }
   ],
   "source": [
    "display(words_df.dropna(subset=['pred_w2v']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.to_pickle('data/lexical_repl/all_words_filled.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
