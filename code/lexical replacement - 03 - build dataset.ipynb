{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from glob import glob\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import json\n",
    "from random import sample\n",
    "\n",
    "import spacy\n",
    "import pyinflect\n",
    "from pyinflect import getAllInflections, getInflection\n",
    "from spacy.tokens import Doc\n",
    "import time\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the sentences have been collected, they must be sorted and organized. Phrases containing formal words need to be extracted and marked, as well as translated in a semi-automatic process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load & save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_df = pd.read_pickle('data/lexical_repl/sents_df.zip')\n",
    "sents_df = sents_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/words_dict.pkl', 'rb') as f:\n",
    "    dc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/words_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(dc, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('data/lexical_repl/data_df.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.to_pickle('data/lexical_repl/data_df.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compile lists of sentences per term: helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInflectList(term):\n",
    "    terms = []\n",
    "    inflections = getAllInflections(term)\n",
    "    for pos in inflections:\n",
    "        for item in inflections[pos]:\n",
    "            terms.append(item)\n",
    "    return list(set(terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_examples(df, word, repl):\n",
    "    for idx, item in tqdm(df.sent.iteritems(), total = len(df)):\n",
    "        lowered = [word.lower() for word in item]\n",
    "        if word in ' '.join(lowered):\n",
    "            print(' '.join(item))\n",
    "            print(' '.join(map(lambda x: x if x != word else repl, lowered)))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create .json of words that can be suggested with Acrolinx's current setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the already-existing lexicons of marked formal words are expanded with all possible inflections of each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/acrolinx.json', 'r') as f:\n",
    "    acro = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInflectReplacements(orig, repls):\n",
    "    dc = defaultdict(set)\n",
    "    orig_i = getAllInflections(orig)\n",
    "    repl_i = [getAllInflections(repl) for repl in repls]\n",
    "    for pos in orig_i:\n",
    "        for repl_dict in repl_i:\n",
    "            if pos in repl_dict:\n",
    "                dc[orig_i[pos][0]].add(repl_dict[pos][0])\n",
    "    if not dc:\n",
    "        return dict({orig: repls})\n",
    "    return dict(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whence': ['from what', 'from which']}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = getInflectReplacements('whence', ['from what', 'from which'])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'thither': {'there'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "acro.update(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'abaft': ['behind'],\n",
       " 'abominate': ['hate'],\n",
       " 'abominated': ['hated'],\n",
       " 'abominates': ['hates'],\n",
       " 'abominating': ['hating'],\n",
       " 'accelerate': ['speed up'],\n",
       " 'accelerated': ['sped up', 'quickened'],\n",
       " 'accelerates': ['speeds up'],\n",
       " 'accelerating': ['quickening', 'speeding up'],\n",
       " 'accompanied': ['come with', 'came with'],\n",
       " 'accompanies': ['comes with'],\n",
       " 'accompany': ['come with'],\n",
       " 'accompanying': ['coming with'],\n",
       " 'accordingly': ['so', 'as such'],\n",
       " 'accrue': ['follow', 'come', 'grow'],\n",
       " 'accrued': ['followed', 'grew', 'came', 'grown', 'come'],\n",
       " 'accrues': ['comes', 'grows', 'follows'],\n",
       " 'accruing': ['following', 'coming', 'growing'],\n",
       " 'accurate': ['correct', 'right'],\n",
       " 'acknowledge': ['note', 'recognize'],\n",
       " 'acknowledged': ['recognized', 'noted'],\n",
       " 'acknowledges': ['notes', 'recognizes'],\n",
       " 'acknowledging': ['noting', 'recognizing'],\n",
       " 'acquiesce': ['agree'],\n",
       " 'acquiesced': ['agreed'],\n",
       " 'acquiesces': ['agrees'],\n",
       " 'acquiescing': ['agreeing'],\n",
       " 'activate': ['trigger', 'start'],\n",
       " 'activated': ['started', 'triggered'],\n",
       " 'activates': ['triggers', 'starts'],\n",
       " 'activating': ['starting', 'triggering'],\n",
       " 'activation': ['starting', 'start'],\n",
       " 'activations': ['startings', 'starts'],\n",
       " 'adjustment': ['change'],\n",
       " 'adjustments': ['changes'],\n",
       " 'administration': ['management'],\n",
       " 'administrative': ['managing', 'management'],\n",
       " 'administrator': ['boss', 'manager'],\n",
       " 'administrators': ['bosses', 'managers'],\n",
       " 'admissible': ['acceptable', 'allowed'],\n",
       " 'aforementioned': ['mentioned', 'previously mentioned'],\n",
       " 'aforesaid': ['mentioned', 'previously mentioned'],\n",
       " 'aggregated': ['totaled'],\n",
       " 'aggregates': ['totals'],\n",
       " 'aggregating': ['totaling'],\n",
       " 'aggregation': ['collection'],\n",
       " 'aggregations': ['collections'],\n",
       " 'alleged': ['supposed'],\n",
       " 'alleviate': ['ease'],\n",
       " 'alleviated': ['eased'],\n",
       " 'alleviates': ['eases'],\n",
       " 'alleviating': ['easing'],\n",
       " 'allocate': ['split up', 'give', 'divide'],\n",
       " 'allocated': ['split up', 'divided', 'given', 'gave'],\n",
       " 'allocates': ['splits up', 'divides', 'gives'],\n",
       " 'allocating': ['dividing', 'splitting up', 'giving'],\n",
       " 'alternative': ['other'],\n",
       " 'alternatively': ['otherwise'],\n",
       " 'alternatives': ['others'],\n",
       " 'am functional': ['work'],\n",
       " 'ameliorate': ['improve', 'ease'],\n",
       " 'ameliorated': ['eased', 'improved'],\n",
       " 'ameliorates': ['improves', 'eases'],\n",
       " 'ameliorating': ['easing', 'improving'],\n",
       " 'amid': ['among'],\n",
       " 'amidst': ['among'],\n",
       " 'amongst': ['among'],\n",
       " 'an abundance of': ['a lot of'],\n",
       " 'anew': ['again'],\n",
       " 'anomalous': ['unusual', 'strange'],\n",
       " 'anticipate': ['expect'],\n",
       " 'anticipated': ['expected'],\n",
       " 'anticipates': ['expects'],\n",
       " 'anticipating': ['expecting'],\n",
       " 'apologize': ['say sorry'],\n",
       " 'apologized': ['said sorry'],\n",
       " 'apologizes': ['says sorry'],\n",
       " 'apologizing': ['saying sorry'],\n",
       " 'apparent': ['clear', 'obvious'],\n",
       " 'apprehend': ['grasp', 'catch'],\n",
       " 'apprehended': ['grasped', 'caught'],\n",
       " 'apprehending': ['catching', 'grasping'],\n",
       " 'apprehends': ['catches', 'grasps'],\n",
       " 'articulate': ['well-spoken', 'expressive', 'express'],\n",
       " 'articulated': ['expressed'],\n",
       " 'articulates': ['expresses'],\n",
       " 'articulating': ['expressing'],\n",
       " 'ascertain': ['understand', 'know'],\n",
       " 'ascertained': ['understood', 'knew', 'known'],\n",
       " 'ascertaining': ['understanding', 'knowing'],\n",
       " 'ascertains': ['understands', 'knows'],\n",
       " 'assert': ['claim', 'state'],\n",
       " 'asserted': ['stated', 'claimed'],\n",
       " 'asserting': ['claiming', 'stating'],\n",
       " 'assertion': ['statement', 'claim'],\n",
       " 'assertions': ['claims', 'statements'],\n",
       " 'asserts': ['claims', 'states'],\n",
       " 'assess': ['judge'],\n",
       " 'assessed': ['judged'],\n",
       " 'assesses': ['judges'],\n",
       " 'assessing': ['judging'],\n",
       " 'assessment': ['judgment'],\n",
       " 'assessments': ['judgments'],\n",
       " 'asset': ['skill'],\n",
       " 'assets': ['skills'],\n",
       " 'assign': ['give'],\n",
       " 'assigned': ['given', 'gave'],\n",
       " 'assigning': ['giving'],\n",
       " 'assigns': ['gives'],\n",
       " 'attain': ['achieve', 'get'],\n",
       " 'attained': ['got', 'achieved'],\n",
       " 'attaining': ['getting', 'achieving'],\n",
       " 'attains': ['achieves', 'gets'],\n",
       " 'attest to': ['confirm'],\n",
       " 'attested to': ['confirmed'],\n",
       " 'attesting to': ['confirming'],\n",
       " 'attests to': ['confirms'],\n",
       " 'audit': ['inspection', 'check', 'inspect'],\n",
       " 'audited': ['checked', 'inspected'],\n",
       " 'auditing': ['checking', 'inspecting'],\n",
       " 'audits': ['checks', 'inspects', 'inspections'],\n",
       " 'aught': ['nothing'],\n",
       " 'authorization': ['permission', 'approval'],\n",
       " 'authorizations': ['permissions', 'approvals'],\n",
       " 'authorize': ['allow', 'approve'],\n",
       " 'authorized': ['approved', 'allowed'],\n",
       " 'authorizes': ['approves', 'allows'],\n",
       " 'authorizing': ['approving', 'allowing'],\n",
       " 'aver': ['declare', 'claim'],\n",
       " 'averred': ['declared', 'claimed'],\n",
       " 'averring': ['declaring', 'claiming'],\n",
       " 'avers': ['claims', 'declares'],\n",
       " 'aye': ['yes'],\n",
       " 'ayes': ['yeses'],\n",
       " 'be functional': ['work'],\n",
       " 'becometh': ['becomes'],\n",
       " 'been functional': ['worked'],\n",
       " 'being functional': ['working'],\n",
       " 'belated': ['late'],\n",
       " 'beseech': ['ask', 'beg'],\n",
       " 'beseeched': ['begged', 'asked'],\n",
       " 'beseeches': ['begs', 'asks'],\n",
       " 'beseeching': ['asking', 'begging'],\n",
       " 'besought': ['begged', 'asked'],\n",
       " 'betwixt': ['between'],\n",
       " 'beverage': ['drink'],\n",
       " 'beverages': ['drinks'],\n",
       " 'capabilities': ['skills'],\n",
       " 'capability': ['skill'],\n",
       " 'caveat': ['warning'],\n",
       " 'caveats': ['warnings'],\n",
       " 'charm': ['enchant', 'enchanted'],\n",
       " 'charmed': ['enchanted'],\n",
       " 'charming': ['enchanting'],\n",
       " 'charms': ['enchants'],\n",
       " 'cogitate': ['think'],\n",
       " 'cogitated': ['thought'],\n",
       " 'cogitates': ['thinks'],\n",
       " 'cogitating': ['thinking'],\n",
       " 'comestibles': ['food'],\n",
       " 'commence': ['begin', 'start'],\n",
       " 'commenced': ['started', 'began', 'begun'],\n",
       " 'commences': ['begins', 'starts'],\n",
       " 'commencing': ['starting', 'beginning'],\n",
       " 'compliant': ['helpful'],\n",
       " 'component': ['part'],\n",
       " 'components': ['parts'],\n",
       " 'comprise': ['contain', 'form'],\n",
       " 'comprised': ['formed', 'contained'],\n",
       " 'comprises': ['forms', 'contains'],\n",
       " 'comprising': ['forming', 'containing'],\n",
       " 'compute': ['calculate'],\n",
       " 'computed': ['calculated'],\n",
       " 'computes': ['calculates'],\n",
       " 'computing': ['calculating'],\n",
       " 'conceal': ['hide'],\n",
       " 'concealed': ['hid', 'hidden'],\n",
       " 'concealing': ['hiding'],\n",
       " 'conceals': ['hides'],\n",
       " 'configuration': ['setup'],\n",
       " 'configurations': ['setups'],\n",
       " 'conjure up': ['create', 'inspire'],\n",
       " 'conjured up': ['created', 'inspired'],\n",
       " 'conjures up': ['creates', 'inspires'],\n",
       " 'conjuring up': ['inspiring', 'creating'],\n",
       " 'consensus': ['agreement'],\n",
       " 'consensuses': ['agreements'],\n",
       " 'contain': ['have'],\n",
       " 'contained': ['had'],\n",
       " 'containing': ['having'],\n",
       " 'contains': ['has'],\n",
       " 'criteria': ['standards'],\n",
       " 'criterion': ['standard'],\n",
       " 'currently': ['now'],\n",
       " 'daunting': ['scary'],\n",
       " 'decrease': ['lower', 'drop'],\n",
       " 'decreased': ['dropped', 'lowered'],\n",
       " 'decreases': ['drops', 'lowers'],\n",
       " 'decreasing': ['dropping', 'lowering'],\n",
       " 'deem': ['consider'],\n",
       " 'deemed': ['considered'],\n",
       " 'deeming': ['considering'],\n",
       " 'deems': ['considers'],\n",
       " 'deficiencies': ['lacks', 'shortages'],\n",
       " 'deficiency': ['lack', 'shortage'],\n",
       " 'degradation': ['loss', 'shame'],\n",
       " 'degradations': ['losses', 'shames'],\n",
       " 'delegate': ['assign'],\n",
       " 'delegated': ['assigned'],\n",
       " 'delegates': ['assigns'],\n",
       " 'delegating': ['assigning'],\n",
       " 'deletion': ['removal'],\n",
       " 'deletions': ['removals'],\n",
       " 'delineate': ['define'],\n",
       " 'delineated': ['defined'],\n",
       " 'delineates': ['defines'],\n",
       " 'delineating': ['defining'],\n",
       " 'depart': ['exit', 'leave'],\n",
       " 'departed': ['left', 'exited'],\n",
       " 'departing': ['leaving', 'exiting'],\n",
       " 'departs': ['leaves', 'exits'],\n",
       " 'departure': ['exit'],\n",
       " 'departures': ['exits'],\n",
       " 'depict': ['show'],\n",
       " 'depicted': ['showed', 'shown'],\n",
       " 'depicting': ['showing'],\n",
       " 'depicts': ['shows'],\n",
       " 'desire': ['want', 'wish'],\n",
       " 'desired': ['wanted', 'wished'],\n",
       " 'desires': ['wishes', 'wants'],\n",
       " 'desiring': ['wishing', 'wanting'],\n",
       " 'determine': ['shape', 'find out'],\n",
       " 'determined': ['shaped', 'found out'],\n",
       " 'determines': ['finds out', 'shapes'],\n",
       " 'determining': ['shaping', 'finding out'],\n",
       " 'diagnostics': ['tests'],\n",
       " 'disclose': ['reveal'],\n",
       " 'disclosed': ['revealed'],\n",
       " 'discloses': ['reveals'],\n",
       " 'disclosing': ['revealing'],\n",
       " 'discontinue': ['stop', 'quit'],\n",
       " 'discontinued': ['stopped', 'quit'],\n",
       " 'discontinues': ['stops', 'quits'],\n",
       " 'discontinuing': ['quitting', 'stopping'],\n",
       " 'discover': ['find', 'find out'],\n",
       " 'discovered': ['found', 'found out'],\n",
       " 'discovering': ['finding', 'finding out'],\n",
       " 'discovers': ['finds', 'finds out'],\n",
       " 'disseminate': ['spread'],\n",
       " 'disseminated': ['spread'],\n",
       " 'disseminates': ['spreads'],\n",
       " 'disseminating': ['spreading'],\n",
       " 'domain': ['field', 'area'],\n",
       " 'domains': ['fields', 'areas'],\n",
       " 'doth': ['does'],\n",
       " 'duration': ['time', 'length'],\n",
       " 'durations': ['lengths', 'times'],\n",
       " 'elicit': ['prompt', 'draw out'],\n",
       " 'elicited': ['drew out', 'prompted', 'drawn out'],\n",
       " 'eliciting': ['prompting', 'drawing out'],\n",
       " 'elicits': ['prompts', 'draws out'],\n",
       " 'elucidate': ['explain', 'clear up'],\n",
       " 'elucidated': ['explained', 'cleared up'],\n",
       " 'elucidates': ['clears up', 'explains'],\n",
       " 'elucidating': ['clearing up', 'explaining'],\n",
       " 'embodied': ['represented'],\n",
       " 'embodies': ['represents'],\n",
       " 'embodiment': ['representation'],\n",
       " 'embodiments': ['representations'],\n",
       " 'embody': ['represent'],\n",
       " 'embodying': ['representing'],\n",
       " 'emolument': ['fee'],\n",
       " 'emoluments': ['fees'],\n",
       " 'encompass': ['surround', 'include'],\n",
       " 'encompassed': ['included', 'surrounded'],\n",
       " 'encompasses': ['surrounds', 'includes'],\n",
       " 'encompassing': ['surrounding', 'including'],\n",
       " 'encounter': ['find', 'meet'],\n",
       " 'encountered': ['found', 'met'],\n",
       " 'encountering': ['meeting', 'finding'],\n",
       " 'encounters': ['finds', 'meets'],\n",
       " 'endeavor': ['effort', 'try'],\n",
       " 'endeavored': ['tried'],\n",
       " 'endeavoring': ['trying'],\n",
       " 'endeavors': ['efforts', 'tries'],\n",
       " 'endorse': ['support'],\n",
       " 'endorsed': ['supported'],\n",
       " 'endorses': ['supports'],\n",
       " 'endorsing': ['supporting'],\n",
       " 'enforce': ['carry out', 'apply'],\n",
       " 'enforced': ['applied', 'carried out'],\n",
       " 'enforces': ['carries out', 'applies'],\n",
       " 'enforcing': ['carrying out', 'applying'],\n",
       " 'ensure': ['make sure', 'secure'],\n",
       " 'ensured': ['secured', 'made sure'],\n",
       " 'ensures': ['secures', 'makes sure'],\n",
       " 'ensuring': ['securing', 'making sure'],\n",
       " 'entail': ['mean', 'lead to'],\n",
       " 'entailed': ['meant', 'led to'],\n",
       " 'entailing': ['leading to', 'meaning'],\n",
       " 'entails': ['leads to', 'means'],\n",
       " 'entities': ['things'],\n",
       " 'entity': ['thing', 'being'],\n",
       " 'enumerate': ['list', 'number'],\n",
       " 'enumerated': ['numbered', 'listed'],\n",
       " 'enumerates': ['numbers', 'lists'],\n",
       " 'enumerating': ['numbering', 'listing'],\n",
       " 'enunciate': ['pronounce'],\n",
       " 'enunciated': ['pronounced'],\n",
       " 'enunciates': ['pronounces'],\n",
       " 'enunciating': ['pronouncing'],\n",
       " 'equitable': ['fair'],\n",
       " 'ere': ['before'],\n",
       " 'ergo': ['so'],\n",
       " 'establish': ['set', 'form'],\n",
       " 'established': ['set', 'formed'],\n",
       " 'establishes': ['forms', 'sets'],\n",
       " 'establishing': ['forming', 'setting'],\n",
       " 'etc': ['and so on'],\n",
       " 'evidenced': ['shown'],\n",
       " 'evince': ['reveal', 'show'],\n",
       " 'evinced': ['showed', 'revealed', 'shown'],\n",
       " 'evinces': ['reveals', 'shows'],\n",
       " 'evincing': ['showing', 'revealing'],\n",
       " 'evoke': ['prompt', 'inspire'],\n",
       " 'evoked': ['prompted', 'inspired'],\n",
       " 'evokes': ['inspires', 'prompts'],\n",
       " 'evoking': ['prompting', 'inspiring'],\n",
       " 'exceed': ['go over', 'top'],\n",
       " 'exceeded': ['topped', 'went over', 'gone over'],\n",
       " 'exceeding': ['going over', 'topping'],\n",
       " 'exceeds': ['tops', 'goes over'],\n",
       " 'exclude': ['ban', 'keep out'],\n",
       " 'excluded': ['banned', 'kept out'],\n",
       " 'excludes': ['bans', 'keeps out'],\n",
       " 'excluding': ['keeping out', 'banning'],\n",
       " 'exemplified': ['showed', 'shown', 'represented'],\n",
       " 'exemplifies': ['represents', 'shows'],\n",
       " 'exemplify': ['represent', 'show'],\n",
       " 'exemplifying': ['representing', 'showing'],\n",
       " 'exhibit': ['show', 'display'],\n",
       " 'exhibited': ['showed', 'displayed', 'shown'],\n",
       " 'exhibiting': ['showing', 'displaying'],\n",
       " 'exhibits': ['displays', 'shows'],\n",
       " 'expedite': ['speed up', 'hurry'],\n",
       " 'expedited': ['hurried', 'sped up'],\n",
       " 'expedites': ['speeds up', 'hurries'],\n",
       " 'expediting': ['hurrying', 'speeding up'],\n",
       " 'expeditious': ['quick', 'fast'],\n",
       " 'expend': ['use', 'spend'],\n",
       " 'expended': ['spent', 'used'],\n",
       " 'expending': ['spending', 'using'],\n",
       " 'expends': ['spends', 'uses'],\n",
       " 'expiration': ['end'],\n",
       " 'expirations': ['ends'],\n",
       " 'expire': ['finish', 'end'],\n",
       " 'expired': ['ended', 'finished'],\n",
       " 'expires': ['ends', 'finishes'],\n",
       " 'expiring': ['finishing', 'ending'],\n",
       " 'expose': ['reveal'],\n",
       " 'exposed': ['revealed'],\n",
       " 'exposes': ['reveals'],\n",
       " 'exposing': ['revealing'],\n",
       " 'external': ['outside'],\n",
       " 'fabricate': ['make up', 'invent'],\n",
       " 'fabricated': ['invented', 'made up'],\n",
       " 'fabricates': ['invents', 'makes up'],\n",
       " 'fabricating': ['making up', 'inventing'],\n",
       " 'facilitate': ['help'],\n",
       " 'facilitated': ['helped'],\n",
       " 'facilitates': ['helps'],\n",
       " 'facilitating': ['helping'],\n",
       " 'fain': ['gladly'],\n",
       " 'farewell': ['goodbye', 'bye'],\n",
       " 'farewells': ['goodbyes', 'byes'],\n",
       " 'finalize': ['complete'],\n",
       " 'finalized': ['completed'],\n",
       " 'finalizes': ['completes'],\n",
       " 'finalizing': ['completing'],\n",
       " 'foregoing': ['previous'],\n",
       " 'forfeit': ['lost', 'lose', 'give up'],\n",
       " 'forfeited': ['lost', 'gave up', 'given up'],\n",
       " 'forfeiting': ['giving up', 'losing'],\n",
       " 'forfeits': ['gives up', 'loses'],\n",
       " 'forsooth': ['indeed'],\n",
       " 'forthright': ['direct', 'honest'],\n",
       " 'forthwith': ['now', 'immediately'],\n",
       " 'framework': ['structure'],\n",
       " 'frameworks': ['structures'],\n",
       " 'generate': ['produce', 'create'],\n",
       " 'generated': ['produced', 'created'],\n",
       " 'generates': ['produces', 'creates'],\n",
       " 'generating': ['creating', 'producing'],\n",
       " 'govern': ['rule'],\n",
       " 'governed': ['ruled'],\n",
       " 'governing': ['ruling'],\n",
       " 'governs': ['rules'],\n",
       " 'guidance': ['advice'],\n",
       " 'guidances': ['advices'],\n",
       " 'hark at': ['listen to'],\n",
       " 'hark back to': ['recall'],\n",
       " 'harked at': ['listened to'],\n",
       " 'harked back to': ['recalled'],\n",
       " 'harking at': ['listening to'],\n",
       " 'harking back to': ['recalling'],\n",
       " 'harks at': ['listens to'],\n",
       " 'harks back to': ['recalls'],\n",
       " 'hath': ['has'],\n",
       " 'hence': ['as such', 'so'],\n",
       " 'henceforth': ['from now on'],\n",
       " 'henceforward': ['from now on'],\n",
       " 'hereafter': ['from now on'],\n",
       " 'hereby': ['as such'],\n",
       " 'herein': ['here'],\n",
       " 'hereinafter': ['from now on'],\n",
       " 'hereof': ['here'],\n",
       " 'heretofore': ['before now'],\n",
       " 'hereunder': ['here'],\n",
       " 'hereunto': ['here'],\n",
       " 'identified': ['known', 'spotted', 'knew', 'named'],\n",
       " 'identifies': ['spots', 'knows', 'names'],\n",
       " 'identify': ['know', 'name', 'spot'],\n",
       " 'identifying': ['knowing', 'spotting', 'naming'],\n",
       " 'impervious': ['resistant'],\n",
       " 'implicit': ['implied'],\n",
       " 'in abeyance': ['suspended'],\n",
       " 'inasmuch': ['so far'],\n",
       " 'inception': ['origin', 'start'],\n",
       " 'inceptions': ['starts', 'origins'],\n",
       " 'increase': ['rise', 'raise'],\n",
       " 'increased': ['risen', 'raised', 'rose'],\n",
       " 'increases': ['raises', 'rises'],\n",
       " 'increasing': ['raising', 'rising'],\n",
       " 'increment': ['gain'],\n",
       " 'incremented': ['gained'],\n",
       " 'incrementing': ['gaining'],\n",
       " 'increments': ['gains'],\n",
       " 'indicator': ['sign'],\n",
       " 'indicators': ['signs'],\n",
       " 'indubitably': ['definitely', 'no doubt'],\n",
       " 'inexpensive': ['cheap', 'affordable'],\n",
       " 'ingestion': ['intake'],\n",
       " 'ingestions': ['intakes'],\n",
       " 'initial': ['first'],\n",
       " 'initialize': ['start'],\n",
       " 'initialized': ['started'],\n",
       " 'initializes': ['starts'],\n",
       " 'initializing': ['starting'],\n",
       " 'initiate': ['start'],\n",
       " 'initiated': ['started'],\n",
       " 'initiates': ['starts'],\n",
       " 'initiating': ['starting'],\n",
       " 'inquire': ['ask'],\n",
       " 'inquired': ['asked'],\n",
       " 'inquires': ['asks'],\n",
       " 'inquiring': ['asking'],\n",
       " 'instill': ['introduce'],\n",
       " 'instilled': ['introduced'],\n",
       " 'instilling': ['introducing'],\n",
       " 'instills': ['introduces'],\n",
       " 'internal': ['inside'],\n",
       " 'invoke': ['call on', 'cause'],\n",
       " 'invoked': ['caused', 'called on'],\n",
       " 'invokes': ['calls on', 'causes'],\n",
       " 'invoking': ['calling on', 'causing'],\n",
       " 'irrespective': ['regardless'],\n",
       " 'is functional': ['works'],\n",
       " 'magnitude': ['size'],\n",
       " 'magnitudes': ['sizes'],\n",
       " 'maintain': ['keep', 'keep up'],\n",
       " 'maintained': ['kept', 'kept up'],\n",
       " 'maintaining': ['keeping', 'keeping up'],\n",
       " 'maintains': ['keeps up', 'keeps'],\n",
       " 'manifest': ['clear', 'show'],\n",
       " 'manifested': ['showed', 'shown'],\n",
       " 'manifesting': ['showing'],\n",
       " 'manifests': ['shows'],\n",
       " 'masticate': ['chew'],\n",
       " 'masticated': ['chewed'],\n",
       " 'masticates': ['chews'],\n",
       " 'masticating': ['chewing'],\n",
       " 'methinks': ['I think'],\n",
       " 'modification': ['change'],\n",
       " 'modifications': ['changes'],\n",
       " 'modified': ['changed'],\n",
       " 'modifies': ['changes'],\n",
       " 'modify': ['change'],\n",
       " 'modifying': ['changing'],\n",
       " 'moreover': ['also'],\n",
       " 'nary': ['not'],\n",
       " 'necessitate': ['need', 'call for'],\n",
       " 'necessitated': ['called for', 'needed'],\n",
       " 'necessitates': ['needs', 'calls for'],\n",
       " 'necessitating': ['needing', 'calling for'],\n",
       " 'nevertheless': ['in any case'],\n",
       " 'notwithstanding': ['despite', 'even so'],\n",
       " 'numerous': ['many'],\n",
       " 'obtain': ['get'],\n",
       " 'obtained': ['got'],\n",
       " 'obtaining': ['getting'],\n",
       " 'obtains': ['gets'],\n",
       " 'omit': ['leave out'],\n",
       " 'omits': ['leaves out'],\n",
       " 'omitted': ['left out'],\n",
       " 'omitting': ['leaving out'],\n",
       " 'on aggregate': ['in total'],\n",
       " 'operate': ['work'],\n",
       " 'operated': ['worked'],\n",
       " 'operates': ['works'],\n",
       " 'operating': ['working'],\n",
       " 'operator': ['user', 'worker'],\n",
       " 'operators': ['workers', 'users'],\n",
       " 'oppose': ['go against'],\n",
       " 'opposed': ['gone against', 'went against'],\n",
       " 'opposes': ['goes against'],\n",
       " 'opposing': ['going against'],\n",
       " 'optimum': ['perfect'],\n",
       " 'particulars': ['details'],\n",
       " 'penurious': ['poor'],\n",
       " 'perchance': ['by any chance'],\n",
       " 'permit': ['pass', 'allow'],\n",
       " 'permits': ['passes', 'allows'],\n",
       " 'permitted': ['allowed'],\n",
       " 'permitting': ['allowing'],\n",
       " 'perspire': ['sweat'],\n",
       " 'perspired': ['sweat'],\n",
       " 'perspires': ['sweats'],\n",
       " 'perspiring': ['sweating'],\n",
       " 'peruse': ['read'],\n",
       " 'perused': ['read'],\n",
       " 'peruses': ['reads'],\n",
       " 'perusing': ['reading'],\n",
       " 'portray': ['show'],\n",
       " 'portrayed': ['showed', 'shown'],\n",
       " 'portraying': ['showing'],\n",
       " 'portrays': ['shows'],\n",
       " 'posit': ['suggest'],\n",
       " 'posited': ['suggested'],\n",
       " 'positing': ['suggesting'],\n",
       " 'posits': ['suggests'],\n",
       " 'possess': ['have'],\n",
       " 'possessed': ['had'],\n",
       " 'possesses': ['has'],\n",
       " 'possessing': ['having'],\n",
       " 'potentialities': ['possibilities'],\n",
       " 'potentiality': ['potential', 'possibility'],\n",
       " 'preclude': ['prevent'],\n",
       " 'precluded': ['prevented'],\n",
       " 'precludes': ['prevents'],\n",
       " 'precluding': ['preventing'],\n",
       " 'prerequisite': ['requirement'],\n",
       " 'prerequisites': ['requirements'],\n",
       " 'proceed': ['continue'],\n",
       " 'proceeded': ['continued'],\n",
       " 'proceeding': ['continuing'],\n",
       " 'proceeds': ['continues'],\n",
       " 'procure': ['get', 'find'],\n",
       " 'procured': ['got', 'found'],\n",
       " 'procures': ['gets', 'finds'],\n",
       " 'procuring': ['finding', 'getting'],\n",
       " 'proficiencies': ['skills'],\n",
       " 'proficiency': ['skill'],\n",
       " 'promulgate': ['promote'],\n",
       " 'promulgated': ['promoted'],\n",
       " 'promulgates': ['promotes'],\n",
       " 'promulgating': ['promoting'],\n",
       " 'provide': ['supply', 'give'],\n",
       " 'provided': ['gave', 'given', 'supplied'],\n",
       " 'provides': ['supplies', 'gives'],\n",
       " 'providing': ['giving', 'supplying'],\n",
       " 'proviso': ['condition'],\n",
       " 'provisos': ['conditions'],\n",
       " 'purchase': ['buy'],\n",
       " 'purchased': ['bought'],\n",
       " 'purchases': ['buys'],\n",
       " 'purchasing': ['buying'],\n",
       " 'purported': ['supposed', 'apparent'],\n",
       " 'purportedly': ['supposedly', 'apparently'],\n",
       " 'regulation': ['rule'],\n",
       " 'regulations': ['rules'],\n",
       " 'relocate': ['move'],\n",
       " 'relocated': ['moved'],\n",
       " 'relocates': ['moves'],\n",
       " 'relocating': ['moving'],\n",
       " 'remain': ['stay'],\n",
       " 'remainder': ['rest'],\n",
       " 'remaindered': ['rested'],\n",
       " 'remaindering': ['resting'],\n",
       " 'remainders': ['rests'],\n",
       " 'remained': ['stayed'],\n",
       " 'remaining': ['staying'],\n",
       " 'remains': ['stays'],\n",
       " 'renumeration': ['pay', 'payment'],\n",
       " 'replica': ['copy'],\n",
       " 'replicas': ['copies'],\n",
       " 'replicate': ['copy'],\n",
       " 'replicated': ['copied'],\n",
       " 'replicates': ['copies'],\n",
       " 'replicating': ['copying'],\n",
       " 'replication': ['copy'],\n",
       " 'replications': ['copies'],\n",
       " 'require': ['need'],\n",
       " 'required': ['needed'],\n",
       " 'requires': ['needs'],\n",
       " 'requiring': ['needing'],\n",
       " 'reside': ['live'],\n",
       " 'resided': ['lived'],\n",
       " 'resides': ['lives'],\n",
       " 'residing': ['living'],\n",
       " 'respiration': ['breath', 'breathing'],\n",
       " 'respirations': ['breaths'],\n",
       " 'respire': ['breathe'],\n",
       " 'respired': ['breathed'],\n",
       " 'respires': ['breathes'],\n",
       " 'respiring': ['breathing'],\n",
       " 'respond': ['answer'],\n",
       " 'responded': ['answered'],\n",
       " 'responding': ['answering'],\n",
       " 'responds': ['answers'],\n",
       " 'response': ['answer'],\n",
       " 'responses': ['answers'],\n",
       " 'restrict': ['limit'],\n",
       " 'restricted': ['limited'],\n",
       " 'restricting': ['limiting'],\n",
       " 'restriction': ['limit'],\n",
       " 'restrictions': ['limits'],\n",
       " 'restricts': ['limits'],\n",
       " 'retain': ['keep'],\n",
       " 'retained': ['kept'],\n",
       " 'retaining': ['keeping'],\n",
       " 'retains': ['keeps'],\n",
       " 'selection': ['choice'],\n",
       " 'selections': ['choices'],\n",
       " 'shall': ['will'],\n",
       " 'solace': ['comfort'],\n",
       " 'solaced': ['comforted'],\n",
       " 'solaces': ['comforts'],\n",
       " 'solacing': ['comforting'],\n",
       " 'solicit': ['ask for'],\n",
       " 'solicited': ['asked for'],\n",
       " 'soliciting': ['asking for'],\n",
       " 'solicits': ['asks for'],\n",
       " 'specification': ['description'],\n",
       " 'specifications': ['descriptions'],\n",
       " 'specified': ['described', 'stated'],\n",
       " 'specifies': ['states', 'describes'],\n",
       " 'specify': ['describe', 'state'],\n",
       " 'specifying': ['stating', 'describing'],\n",
       " 'stipulate': ['state'],\n",
       " 'stipulated': ['stated'],\n",
       " 'stipulates': ['states'],\n",
       " 'stipulating': ['stating'],\n",
       " 'strategize': ['plan'],\n",
       " 'strategized': ['planned'],\n",
       " 'strategizes': ['plans'],\n",
       " 'strategizing': ['planning'],\n",
       " 'subsequent': ['later', 'next'],\n",
       " 'substantial': ['large'],\n",
       " 'substitute': ['swap', 'replacement'],\n",
       " 'substituted': ['swapped'],\n",
       " 'substitutes': ['replacements', 'swaps'],\n",
       " 'substituting': ['swapping'],\n",
       " 'swain': ['youth'],\n",
       " 'swains': ['youths'],\n",
       " 'synopses': ['summaries'],\n",
       " 'synopsis': ['summary'],\n",
       " 'technique': ['method', 'skill'],\n",
       " 'techniques': ['skills', 'methods'],\n",
       " 'terminate': ['end'],\n",
       " 'terminated': ['ended'],\n",
       " 'terminates': ['ends'],\n",
       " 'terminating': ['ending'],\n",
       " 'thee': ['you'],\n",
       " 'thence': ['so', 'then'],\n",
       " 'thenceforth': ['from then on'],\n",
       " 'thereafter': ['after that'],\n",
       " 'thereby': ['as such'],\n",
       " 'therefore': ['so', 'as such'],\n",
       " 'therein': ['there'],\n",
       " 'thereof': ['of that', 'of it'],\n",
       " 'thereon': ['of that', 'of it'],\n",
       " 'thereto': ['to that', 'to it'],\n",
       " 'theretofore': ['previously'],\n",
       " 'thereunto': ['to that', 'to it'],\n",
       " 'thereupon': ['then'],\n",
       " 'therewith': ['soon after'],\n",
       " 'thither': ['there'],\n",
       " 'thou': ['you'],\n",
       " 'thy': ['your'],\n",
       " 'transformation': ['change'],\n",
       " 'transformations': ['changes'],\n",
       " 'twain': ['two'],\n",
       " 'twixt': ['between'],\n",
       " 'undermine': ['hurt'],\n",
       " 'undermined': ['hurt'],\n",
       " 'undermines': ['hurts'],\n",
       " 'undermining': ['hurting'],\n",
       " 'unto': ['to'],\n",
       " 'upon': ['on'],\n",
       " 'utilize': ['use'],\n",
       " 'utilized': ['used'],\n",
       " 'utilizes': ['uses'],\n",
       " 'utilizing': ['using'],\n",
       " 'validate': ['check', 'confirm'],\n",
       " 'validated': ['confirmed', 'checked'],\n",
       " 'validates': ['checks', 'confirms'],\n",
       " 'validating': ['checking', 'confirming'],\n",
       " 'validation': ['confirmation'],\n",
       " 'validations': ['confirmations'],\n",
       " 'verification': ['confirmation'],\n",
       " 'verifications': ['confirmations'],\n",
       " 'verified': ['confirmed', 'checked'],\n",
       " 'verifies': ['checks', 'confirms'],\n",
       " 'verify': ['check', 'confirm'],\n",
       " 'verifying': ['checking', 'confirming'],\n",
       " 'verily': ['definitely'],\n",
       " 'vocalize': ['talk', 'say'],\n",
       " 'vocalized': ['said', 'talked'],\n",
       " 'vocalizes': ['says', 'talks'],\n",
       " 'vocalizing': ['talking', 'saying'],\n",
       " 'vouchsafe': ['reveal'],\n",
       " 'vouchsafed': ['revealed'],\n",
       " 'vouchsafes': ['reveals'],\n",
       " 'vouchsafing': ['revealing'],\n",
       " 'was functional': ['worked'],\n",
       " 'whatsoever': ['at all'],\n",
       " 'whence': ['from what', 'from which'],\n",
       " 'whensoever': ['whenever'],\n",
       " 'wherefore': ['why'],\n",
       " 'whereof': ['of what', 'of which'],\n",
       " 'whereon': ['on which'],\n",
       " 'wherewith': ['with which'],\n",
       " 'whilst': ['while'],\n",
       " 'whither': ['where'],\n",
       " 'whomsoever': ['whomever'],\n",
       " 'whosoever': ['whoever'],\n",
       " 'withal': ['also', 'as well'],\n",
       " 'wonted': ['usual'],\n",
       " 'wrought': ['worked', 'made']}"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for item in acro:\n",
    "    acro[item] = list(acro[item])\n",
    "print(len(acro))\n",
    "acro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/acrolinx.json', 'w') as f:\n",
    "    json.dump(acro, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find phrases containing words in dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the words are collected - and only the words, not the phrases (main words are taken from phrases) - to make a master list of known formal words. Then the sentences are processed and syntactic phrases with those words are marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_formal_words = ['hark', 'harking', 'harks', 'conjures', 'aggregate', 'functional', 'conjuring',\n",
    "           'abundance', 'conjure', 'attest', 'abeyance', 'harked', 'conjured', 'attests', \n",
    "           'attesting', 'attested', 'accompanied', 'accompany', 'accompanying', 'accompanies',\n",
    "                   'access', 'eke', 'ekes', 'eked', 'eking', 'apropos', 'recipients', 'recipient',\n",
    "                   'derive', 'derived', 'deriving', 'derives', 'allocate', 'allocating', 'allocates',\n",
    "                   'allocated', 'individual', 'individuals']\n",
    "\n",
    "for item in acro.keys():\n",
    "    if ' ' not in item:\n",
    "        all_formal_words.append(item)\n",
    "        \n",
    "for item in dc.keys():\n",
    "    for inflect in [x[0] for x in getAllInflections(item).values()]:\n",
    "        all_formal_words.append(item)\n",
    "        \n",
    "all_formal_words = list(set(all_formal_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_formal_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/list-formal-words-only.pkl', 'wb') as f:\n",
    "    pickle.dump(all_formal_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_phrases(sent):\n",
    "    \n",
    "    doc = Doc(nlp.vocab, words=sent)\n",
    "    nlp.tagger(doc)\n",
    "    nlp.parser(doc)\n",
    "    \n",
    "    indices = []\n",
    "    for word in all_formal_words:\n",
    "        phr = find_phrase(doc, word)\n",
    "        if phr != None:\n",
    "            for idx in phr:\n",
    "                indices.append(idx)\n",
    "    indices = list(set(indices))\n",
    "                \n",
    "    arr = [0] * len(sent)\n",
    "    for idx in indices:\n",
    "        arr[idx] = 1\n",
    "\n",
    "    return arr\n",
    "\n",
    "def check_phrase(tokens, word):\n",
    "    if len(tokens) > 10:\n",
    "        words = [tok.text for tok in tokens]\n",
    "        idx = words.index(word)\n",
    "        start = idx - 5 if idx > 4 else 0\n",
    "        end = idx + 5 if len(words) > idx + 4 else len(words) - 1\n",
    "        tokens = tokens[start:end]\n",
    "            \n",
    "    try:\n",
    "        assert word in [tok.text for tok in tokens], 'word got lost?'\n",
    "    except AssertionError:\n",
    "        return None\n",
    "    return [tok.i for tok in tokens]\n",
    "\n",
    "def find_phrase(doc, word):\n",
    "    # sent = list of str (words)\n",
    "    # word = str\n",
    "    \n",
    "    if word not in doc.text:\n",
    "        return None\n",
    "    \n",
    "    # if it's in a noun phrase, then return the noun phrase\n",
    "    for np in doc.noun_chunks: # use np instead of np.text\n",
    "        if word in [tok.text for tok in np]:\n",
    "            return check_phrase([tok for tok in np], word)\n",
    "\n",
    "    for w in doc:\n",
    "        if str(w.text) == word:\n",
    "            if w.dep_ == 'ROOT': # main verb clause: returns with object\n",
    "                phrase_idx = [w.i]\n",
    "                for right in w.rights:\n",
    "                    if right.dep_ in ('punct', 'advcl'):\n",
    "                        break\n",
    "                    phrase_idx = phrase_idx + [tok.i for tok in right.subtree]\n",
    "                if len(phrase_idx) > 1:\n",
    "                    return check_phrase([tok for tok in doc[min(phrase_idx) : max(phrase_idx) + 1]], word)\n",
    "                # no object was found? check if next left text is subj, return that\n",
    "                if len(list(w.lefts)) > 0:\n",
    "                    left = list(w.lefts)[-1]\n",
    "                    if left.dep_ == 'nsubj':\n",
    "                        phrase_idx = [tok.i for tok in left.subtree] + phrase_idx\n",
    "                return check_phrase([tok for tok in doc[min(phrase_idx) : max(phrase_idx) + 1]], word)\n",
    "            return check_phrase([tok for tok in w.subtree], word)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tSubmitted\n",
      "0\tby\n",
      "0\t]\n"
     ]
    }
   ],
   "source": [
    "test_int = 3818245\n",
    "ex_arr = arrays[test_int]\n",
    "for idx in range(len(sents_df.sent[test_int])):\n",
    "    print(str(ex_arr[idx]) + '\\t' + sents_df.sent[test_int][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe5807dd97f44b99ddfb092c8ba65be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3818246), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert len(arrays) == len(present)\n",
    "\n",
    "for idx, sent in tqdm(sents_df.sent.iteritems(), total = len(sents_df)):\n",
    "    if idx < len(arrays):\n",
    "        continue\n",
    "    arr = find_all_phrases(sent)\n",
    "    arrays.append(arr)\n",
    "    \n",
    "    if sum(arr) > 0:\n",
    "        present.append(True)\n",
    "    else:\n",
    "        present.append(False)\n",
    "        \n",
    "    if idx % 100000 == 0 and idx > 0:\n",
    "        with open('data/lexical_repl/arrays' + str(idx) + '.pkl', 'wb') as f:\n",
    "            pickle.dump(arrays, f)\n",
    "        with open('data/lexical_repl/present' + str(idx) + '.pkl', 'wb') as f:\n",
    "            pickle.dump(present, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sents_df) == len(arrays) == len(present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/sents-df-masks.pkl', 'wb') as f:\n",
    "    pickle.dump(arrays, f)\n",
    "with open('data/lexical_repl/sents-df-masks-presence-bool.pkl', 'wb') as f:\n",
    "    pickle.dump(present, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create mini-set with restricted number of occurrences per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "      <th>masks</th>\n",
       "      <th>words</th>\n",
       "      <th>phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[investigate]</td>\n",
       "      <td>[[to, investigate, reports, of, possible, ``]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[The, grand, jury, commented, on, a, number, o...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[operated, purchasing]</td>\n",
       "      <td>[[purchasing], [well, operated, and, follow]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[However, ,, the, jury, said, it, believes, ``...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[administration]</td>\n",
       "      <td>[[administration]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[It, urged, that, the, next, Legislature, ``, ...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[provide]</td>\n",
       "      <td>[[that, the, next, Legislature, ``, provide, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[The, jury, also, commented, on, the, Fulton, ...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[administrators]</td>\n",
       "      <td>[[administrators]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sent source description  \\\n",
       "2   [The, September-October, term, jury, had, been...  brown        None   \n",
       "6   [The, grand, jury, commented, on, a, number, o...  brown        None   \n",
       "8   [However, ,, the, jury, said, it, believes, ``...  brown        None   \n",
       "12  [It, urged, that, the, next, Legislature, ``, ...  brown        None   \n",
       "18  [The, jury, also, commented, on, the, Fulton, ...  brown        None   \n",
       "\n",
       "                                                masks                   words  \\\n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...           [investigate]   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [operated, purchasing]   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        [administration]   \n",
       "12  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...               [provide]   \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        [administrators]   \n",
       "\n",
       "                                              phrases  \n",
       "2      [[to, investigate, reports, of, possible, ``]]  \n",
       "6       [[purchasing], [well, operated, and, follow]]  \n",
       "8                                  [[administration]]  \n",
       "12  [[that, the, next, Legislature, ``, provide, e...  \n",
       "18                                 [[administrators]]  "
      ]
     },
     "execution_count": 1097,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any([True, True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cca86918954087a435278ff5a1329c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=525114), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = defaultdict(lambda: 0)\n",
    "restricted = []\n",
    "\n",
    "def check_word(word):\n",
    "    if counts[word] >= 10:\n",
    "        counts[word] += 1\n",
    "        return False\n",
    "    else:\n",
    "        counts[word] += 1\n",
    "        return True\n",
    "\n",
    "# shuffle to get balance of data\n",
    "for idx, row in tqdm(sents_df.sample(frac=1).iterrows(), total = len(sents_df)):\n",
    "    checks = []\n",
    "    for word in row.words:\n",
    "        checks.append(check_word(word))\n",
    "    if any(checks):\n",
    "        restricted.append(True)\n",
    "    else:\n",
    "        restricted.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'abeyance': 1,\n",
       "             'abundance': 9,\n",
       "             'accelerate': 2,\n",
       "             'accelerated': 9,\n",
       "             'accelerating': 6,\n",
       "             'access': 65,\n",
       "             'accessibility': 2,\n",
       "             'accompanied': 30,\n",
       "             'accompany': 5,\n",
       "             'accompanying': 13,\n",
       "             'accordingly': 9,\n",
       "             'accrue': 1,\n",
       "             'accrued': 3,\n",
       "             'accrues': 1,\n",
       "             'accruing': 3,\n",
       "             'accurate': 32,\n",
       "             'acknowledge': 15,\n",
       "             'acknowledged': 20,\n",
       "             'acknowledges': 5,\n",
       "             'acknowledging': 2,\n",
       "             'acknowledgment': 1,\n",
       "             'acquiesce': 2,\n",
       "             'acquiesced': 1,\n",
       "             'acquisition': 13,\n",
       "             'activated': 1,\n",
       "             'activating': 1,\n",
       "             'activation': 3,\n",
       "             'adjustment': 20,\n",
       "             'adjustments': 11,\n",
       "             'administration': 85,\n",
       "             'administrative': 37,\n",
       "             'administrator': 12,\n",
       "             'administrators': 8,\n",
       "             'admissible': 3,\n",
       "             'aforementioned': 1,\n",
       "             'aforesaid': 1,\n",
       "             'agent': 39,\n",
       "             'aggregate': 10,\n",
       "             'aggregates': 1,\n",
       "             'alleged': 36,\n",
       "             'alleviate': 1,\n",
       "             'alleviating': 2,\n",
       "             'allocate': 4,\n",
       "             'allocated': 10,\n",
       "             'allocating': 1,\n",
       "             'allocation': 11,\n",
       "             'alternate': 6,\n",
       "             'alternative': 62,\n",
       "             'alternatively': 4,\n",
       "             'alternatives': 17,\n",
       "             'ameliorating': 1,\n",
       "             'amid': 9,\n",
       "             'amidst': 4,\n",
       "             'amongst': 21,\n",
       "             'analyze': 5,\n",
       "             'anew': 2,\n",
       "             'anomalous': 1,\n",
       "             'anticipate': 8,\n",
       "             'anticipated': 16,\n",
       "             'anticipates': 1,\n",
       "             'anticipating': 1,\n",
       "             'apologized': 2,\n",
       "             'apparent': 45,\n",
       "             'applicability': 2,\n",
       "             'application': 46,\n",
       "             'apprehended': 1,\n",
       "             'appropriate': 63,\n",
       "             'architecture': 11,\n",
       "             'articulate': 8,\n",
       "             'articulated': 3,\n",
       "             'articulates': 1,\n",
       "             'articulating': 2,\n",
       "             'ascertain': 3,\n",
       "             'ascertained': 1,\n",
       "             'ascertaining': 1,\n",
       "             'assert': 12,\n",
       "             'asserted': 11,\n",
       "             'asserting': 1,\n",
       "             'assertion': 5,\n",
       "             'assertions': 4,\n",
       "             'asserts': 2,\n",
       "             'assess': 9,\n",
       "             'assessed': 8,\n",
       "             'assesses': 1,\n",
       "             'assessing': 9,\n",
       "             'assessment': 37,\n",
       "             'assessments': 8,\n",
       "             'asset': 9,\n",
       "             'assets': 25,\n",
       "             'assign': 6,\n",
       "             'assigned': 15,\n",
       "             'assigning': 3,\n",
       "             'assigns': 1,\n",
       "             'associate': 10,\n",
       "             'attain': 6,\n",
       "             'attained': 4,\n",
       "             'attaining': 2,\n",
       "             'attempt': 97,\n",
       "             'attest': 1,\n",
       "             'attested': 5,\n",
       "             'attribute': 3,\n",
       "             'audit': 9,\n",
       "             'audited': 5,\n",
       "             'auditing': 5,\n",
       "             'audits': 1,\n",
       "             'aught': 3,\n",
       "             'authorizations': 1,\n",
       "             'authorize': 2,\n",
       "             'authorized': 18,\n",
       "             'authorizes': 1,\n",
       "             'authorizing': 2,\n",
       "             'aye': 52,\n",
       "             'ayes': 1,\n",
       "             'becometh': 1,\n",
       "             'belated': 3,\n",
       "             'bestow': 3,\n",
       "             'beverage': 3,\n",
       "             'beverages': 2,\n",
       "             'bind': 2,\n",
       "             'binding': 13,\n",
       "             'capabilities': 10,\n",
       "             'capability': 8,\n",
       "             'capacity': 53,\n",
       "             'caveat': 1,\n",
       "             'cease': 10,\n",
       "             'certainty': 13,\n",
       "             'charm': 21,\n",
       "             'charmed': 2,\n",
       "             'charming': 16,\n",
       "             'charms': 1,\n",
       "             'climate': 26,\n",
       "             'commence': 2,\n",
       "             'commenced': 3,\n",
       "             'commences': 3,\n",
       "             'commencing': 7,\n",
       "             'component': 20,\n",
       "             'components': 30,\n",
       "             'comprise': 5,\n",
       "             'comprised': 8,\n",
       "             'comprises': 5,\n",
       "             'comprising': 5,\n",
       "             'compute': 3,\n",
       "             'computed': 2,\n",
       "             'computes': 1,\n",
       "             'computing': 5,\n",
       "             'conceal': 5,\n",
       "             'concealed': 7,\n",
       "             'concealing': 2,\n",
       "             'conceals': 2,\n",
       "             'concurrent': 2,\n",
       "             'condition': 71,\n",
       "             'configuration': 6,\n",
       "             'configurations': 2,\n",
       "             'conjured': 1,\n",
       "             'conjures': 2,\n",
       "             'conjuring': 1,\n",
       "             'consensus': 9,\n",
       "             'consolidate': 3,\n",
       "             'constitute': 13,\n",
       "             'contain': 30,\n",
       "             'contained': 42,\n",
       "             'containing': 32,\n",
       "             'contains': 29,\n",
       "             'cornerstone': 1,\n",
       "             'criteria': 15,\n",
       "             'criterion': 6,\n",
       "             'currently': 50,\n",
       "             'daunting': 1,\n",
       "             'decrease': 14,\n",
       "             'decreased': 2,\n",
       "             'decreases': 4,\n",
       "             'decreasing': 2,\n",
       "             'deem': 2,\n",
       "             'deemed': 11,\n",
       "             'deeming': 1,\n",
       "             'deficiencies': 4,\n",
       "             'deficiency': 8,\n",
       "             'degradation': 3,\n",
       "             'delegate': 6,\n",
       "             'delegated': 1,\n",
       "             'delegates': 16,\n",
       "             'delineate': 1,\n",
       "             'delineating': 1,\n",
       "             'depart': 5,\n",
       "             'departed': 8,\n",
       "             'departing': 7,\n",
       "             'departs': 1,\n",
       "             'departure': 26,\n",
       "             'departures': 4,\n",
       "             'depict': 2,\n",
       "             'depicted': 4,\n",
       "             'depicting': 4,\n",
       "             'derive': 4,\n",
       "             'derived': 32,\n",
       "             'derives': 5,\n",
       "             'deriving': 2,\n",
       "             'desire': 41,\n",
       "             'desired': 29,\n",
       "             'desires': 13,\n",
       "             'desiring': 1,\n",
       "             'determine': 47,\n",
       "             'determined': 89,\n",
       "             'determines': 6,\n",
       "             'determining': 14,\n",
       "             'diagnostic': 6,\n",
       "             'diagnostics': 1,\n",
       "             'disclose': 6,\n",
       "             'disclosed': 17,\n",
       "             'discloses': 1,\n",
       "             'discontinue': 1,\n",
       "             'discontinued': 6,\n",
       "             'discover': 33,\n",
       "             'discovered': 67,\n",
       "             'discovering': 8,\n",
       "             'discovers': 2,\n",
       "             'display': 55,\n",
       "             'disseminate': 2,\n",
       "             'disseminated': 2,\n",
       "             'distinguish': 19,\n",
       "             'domain': 7,\n",
       "             'domains': 2,\n",
       "             'doth': 1,\n",
       "             'duration': 7,\n",
       "             'eke': 1,\n",
       "             'eked': 1,\n",
       "             'elicit': 5,\n",
       "             'elicited': 5,\n",
       "             'elucidating': 1,\n",
       "             'embodied': 9,\n",
       "             'embodies': 1,\n",
       "             'embodiment': 5,\n",
       "             'embody': 1,\n",
       "             'embodying': 2,\n",
       "             'enchant': 1,\n",
       "             'encompass': 1,\n",
       "             'encompasses': 1,\n",
       "             'encounter': 17,\n",
       "             'encountered': 13,\n",
       "             'encountering': 1,\n",
       "             'encounters': 3,\n",
       "             'endeavor': 4,\n",
       "             'endeavors': 1,\n",
       "             'endorse': 7,\n",
       "             'endorsed': 9,\n",
       "             'endorses': 1,\n",
       "             'endorsing': 1,\n",
       "             'enforce': 6,\n",
       "             'enforced': 14,\n",
       "             'enforces': 2,\n",
       "             'enforcing': 2,\n",
       "             'enrichment': 2,\n",
       "             'ensure': 52,\n",
       "             'ensured': 7,\n",
       "             'ensures': 4,\n",
       "             'ensuring': 15,\n",
       "             'entail': 4,\n",
       "             'entailed': 1,\n",
       "             'entailing': 1,\n",
       "             'entails': 7,\n",
       "             'entities': 7,\n",
       "             'entity': 8,\n",
       "             'enumerated': 1,\n",
       "             'enunciate': 1,\n",
       "             'equitable': 3,\n",
       "             'equivalent': 33,\n",
       "             'ere': 2,\n",
       "             'establish': 48,\n",
       "             'established': 75,\n",
       "             'establishing': 16,\n",
       "             'etc': 30,\n",
       "             'evidenced': 5,\n",
       "             'evoke': 5,\n",
       "             'evoked': 5,\n",
       "             'evokes': 2,\n",
       "             'exceed': 11,\n",
       "             'exceeded': 4,\n",
       "             'exceeding': 6,\n",
       "             'exceeds': 4,\n",
       "             'exclude': 8,\n",
       "             'excluded': 10,\n",
       "             'excludes': 3,\n",
       "             'excluding': 7,\n",
       "             'exclusion': 6,\n",
       "             'execution': 6,\n",
       "             'exemplified': 2,\n",
       "             'exemplify': 1,\n",
       "             'exhibit': 14,\n",
       "             'exhibited': 8,\n",
       "             'exhibiting': 2,\n",
       "             'exhibits': 8,\n",
       "             'expedite': 1,\n",
       "             'expeditious': 2,\n",
       "             'expend': 1,\n",
       "             'expended': 3,\n",
       "             'expire': 2,\n",
       "             'expired': 1,\n",
       "             'expires': 2,\n",
       "             'explode': 4,\n",
       "             'expose': 13,\n",
       "             'exposed': 27,\n",
       "             'exposes': 1,\n",
       "             'exposing': 5,\n",
       "             'external': 22,\n",
       "             'extract': 9,\n",
       "             'extraction': 2,\n",
       "             'fabricated': 1,\n",
       "             'fabricating': 1,\n",
       "             'facilitate': 8,\n",
       "             'facilitated': 1,\n",
       "             'facilitates': 1,\n",
       "             'facilitating': 3,\n",
       "             'farewell': 9,\n",
       "             'farewells': 1,\n",
       "             'finalized': 1,\n",
       "             'foregoing': 3,\n",
       "             'forfeit': 2,\n",
       "             'forfeited': 1,\n",
       "             'forthright': 2,\n",
       "             'fortnightly': 4,\n",
       "             'framework': 11,\n",
       "             'function': 50,\n",
       "             'functional': 20,\n",
       "             'generate': 5,\n",
       "             'generated': 13,\n",
       "             'generates': 6,\n",
       "             'generating': 5,\n",
       "             'govern': 4,\n",
       "             'governed': 10,\n",
       "             'governing': 16,\n",
       "             'governs': 2,\n",
       "             'grant': 46,\n",
       "             'guidance': 30,\n",
       "             'harks': 1,\n",
       "             'hence': 26,\n",
       "             'henceforth': 2,\n",
       "             'hereafter': 4,\n",
       "             'hereby': 1,\n",
       "             'heretofore': 4,\n",
       "             'hereunto': 2,\n",
       "             'hither': 1,\n",
       "             'hub': 1,\n",
       "             'identified': 48,\n",
       "             'identifies': 12,\n",
       "             'identify': 39,\n",
       "             'identifying': 6,\n",
       "             'implicit': 11,\n",
       "             'inception': 2,\n",
       "             'increase': 172,\n",
       "             'increased': 104,\n",
       "             'increases': 50,\n",
       "             'increasing': 64,\n",
       "             'increment': 1,\n",
       "             'indicator': 10,\n",
       "             'indicators': 8,\n",
       "             'individual': 170,\n",
       "             'individuals': 67,\n",
       "             'indubitably': 1,\n",
       "             'inexpensive': 3,\n",
       "             'initial': 58,\n",
       "             'initiate': 5,\n",
       "             'initiated': 13,\n",
       "             'initiates': 2,\n",
       "             'initiating': 2,\n",
       "             'initiative': 35,\n",
       "             'inquire': 3,\n",
       "             'inquired': 8,\n",
       "             'inquiring': 2,\n",
       "             'internal': 38,\n",
       "             'investigate': 15,\n",
       "             'invoke': 3,\n",
       "             'invoked': 3,\n",
       "             'invokes': 1,\n",
       "             'invoking': 3,\n",
       "             'irrespective': 8,\n",
       "             'magnitude': 19,\n",
       "             'magnitudes': 1,\n",
       "             'maintain': 45,\n",
       "             'maintained': 35,\n",
       "             'maintaining': 20,\n",
       "             'maintains': 10,\n",
       "             'maintenance': 41,\n",
       "             'manifest': 6,\n",
       "             'manifesting': 1,\n",
       "             'methinks': 1,\n",
       "             'modification': 5,\n",
       "             'modifications': 6,\n",
       "             'modified': 12,\n",
       "             'modify': 6,\n",
       "             'modifying': 2,\n",
       "             'monitor': 11,\n",
       "             'moreover': 8,\n",
       "             'morrow': 1,\n",
       "             'multiple': 28,\n",
       "             'necessitate': 3,\n",
       "             'necessitated': 3,\n",
       "             'necessitates': 1,\n",
       "             'necessitating': 1,\n",
       "             'nevertheless': 23,\n",
       "             'notwithstanding': 2,\n",
       "             'numerous': 29,\n",
       "             'objective': 51,\n",
       "             'obtain': 36,\n",
       "             'obtained': 54,\n",
       "             'obtaining': 12,\n",
       "             'obtains': 2,\n",
       "             'omit': 2,\n",
       "             'omits': 1,\n",
       "             'omitted': 3,\n",
       "             'omitting': 2,\n",
       "             'operate': 41,\n",
       "             'operated': 18,\n",
       "             'operates': 25,\n",
       "             'operating': 54,\n",
       "             'operation': 129,\n",
       "             'operator': 16,\n",
       "             'operators': 14,\n",
       "             'oppose': 14,\n",
       "             'opposed': 41,\n",
       "             'opposes': 2,\n",
       "             'opposing': 9,\n",
       "             'optimum': 8,\n",
       "             'orientate': 1,\n",
       "             'particulars': 2,\n",
       "             'permit': 37,\n",
       "             'permits': 18,\n",
       "             'permitted': 29,\n",
       "             'permitting': 6,\n",
       "             'portray': 5,\n",
       "             'portrayed': 6,\n",
       "             'portraying': 2,\n",
       "             'portrays': 4,\n",
       "             'possess': 17,\n",
       "             'possessed': 15,\n",
       "             'possesses': 5,\n",
       "             'possessing': 8,\n",
       "             'potentialities': 1,\n",
       "             'potentiality': 2,\n",
       "             'preclude': 4,\n",
       "             'precluded': 1,\n",
       "             'prerequisite': 1,\n",
       "             'prioritize': 1,\n",
       "             'proceed': 13,\n",
       "             'proceeded': 14,\n",
       "             'proceeding': 10,\n",
       "             'proceeds': 13,\n",
       "             'procure': 2,\n",
       "             'proficiency': 3,\n",
       "             'promulgated': 3,\n",
       "             'promulgating': 1,\n",
       "             'provide': 196,\n",
       "             'provided': 140,\n",
       "             'provider': 2,\n",
       "             'provides': 65,\n",
       "             'providing': 55,\n",
       "             'provision': 39,\n",
       "             'proviso': 1,\n",
       "             'purchase': 46,\n",
       "             'purchased': 7,\n",
       "             'purchases': 5,\n",
       "             'purchasing': 10,\n",
       "             'purported': 2,\n",
       "             'recipient': 6,\n",
       "             'recipients': 4,\n",
       "             'reflect': 26,\n",
       "             'regardless': 13,\n",
       "             'register': 23,\n",
       "             'regulation': 14,\n",
       "             'regulations': 30,\n",
       "             'release': 46,\n",
       "             'relocate': 2,\n",
       "             'relocated': 1,\n",
       "             'relocating': 1,\n",
       "             'remain': 98,\n",
       "             'remainder': 17,\n",
       "             'remainders': 1,\n",
       "             'remained': 85,\n",
       "             'remaining': 41,\n",
       "             'remains': 80,\n",
       "             'render': 6,\n",
       "             'rendering': 4,\n",
       "             'replica': 8,\n",
       "             'replicas': 3,\n",
       "             'replicate': 2,\n",
       "             'replication': 1,\n",
       "             'request': 41,\n",
       "             'require': 45,\n",
       "             'required': 114,\n",
       "             'requires': 42,\n",
       "             'requiring': 14,\n",
       "             'reside': 1,\n",
       "             'residence': 19,\n",
       "             'resides': 2,\n",
       "             'residing': 2,\n",
       "             'respiration': 1,\n",
       "             'respond': 18,\n",
       "             'responded': 19,\n",
       "             'responding': 8,\n",
       "             'responds': 4,\n",
       "             'response': 87,\n",
       "             'responses': 17,\n",
       "             'restrict': 17,\n",
       "             'restricted': 25,\n",
       "             'restricting': 1,\n",
       "             'restriction': 9,\n",
       "             'restrictions': 20,\n",
       "             'restricts': 4,\n",
       "             'retain': 17,\n",
       "             'retained': 21,\n",
       "             'retaining': 7,\n",
       "             'retains': 8,\n",
       "             'select': 18,\n",
       "             'selection': 47,\n",
       "             'selections': 6,\n",
       "             'shall': 138,\n",
       "             'solace': 5,\n",
       "             'solaced': 1,\n",
       "             'solicit': 2,\n",
       "             'soliciting': 1,\n",
       "             'solicits': 1,\n",
       "             'specification': 9,\n",
       "             'specifications': 3,\n",
       "             'specified': 18,\n",
       "             'specifies': 1,\n",
       "             'specify': 6,\n",
       "             'specifying': 1,\n",
       "             'stipulate': 1,\n",
       "             'stipulated': 1,\n",
       "             'stipulates': 1,\n",
       "             'subsequent': 17,\n",
       "             'substantial': 53,\n",
       "             'substitute': 14,\n",
       "             'substituted': 9,\n",
       "             'substitutes': 6,\n",
       "             'substituting': 3,\n",
       "             'synopsis': 1,\n",
       "             'technique': 40,\n",
       "             'techniques': 71,\n",
       "             'terminate': 4,\n",
       "             'terminated': 4,\n",
       "             'terminating': 1,\n",
       "             'thee': 11,\n",
       "             'thence': 4,\n",
       "             'thenceforth': 1,\n",
       "             'thereafter': 13,\n",
       "             'thereby': 18,\n",
       "             'therefore': 137,\n",
       "             'therein': 4,\n",
       "             'thereof': 3,\n",
       "             'thereto': 3,\n",
       "             'thereupon': 2,\n",
       "             'therewith': 2,\n",
       "             'thou': 7,\n",
       "             'thus': 106,\n",
       "             'thy': 4,\n",
       "             'transfer': 47,\n",
       "             'transformation': 13,\n",
       "             'trigger': 5,\n",
       "             'undermine': 6,\n",
       "             'undermined': 4,\n",
       "             'undermining': 4,\n",
       "             'unto': 10,\n",
       "             'upon': 257,\n",
       "             'upsurge': 2,\n",
       "             'utilization': 3,\n",
       "             'utilize': 4,\n",
       "             'utilized': 5,\n",
       "             'utilizes': 3,\n",
       "             'utilizing': 3,\n",
       "             'validate': 2,\n",
       "             'validated': 2,\n",
       "             'validation': 1,\n",
       "             'variable': 23,\n",
       "             'verification': 4,\n",
       "             'verified': 1,\n",
       "             'verify': 4,\n",
       "             'warrant': 21,\n",
       "             'whatsoever': 8,\n",
       "             'whence': 1,\n",
       "             'whereof': 3,\n",
       "             'whereon': 1,\n",
       "             'whilst': 16,\n",
       "             'whosoever': 1,\n",
       "             'wonted': 1,\n",
       "             'wrought': 2,\n",
       "             'zone': 18})"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = defaultdict(lambda: 0)\n",
    "for idx, l in sents_df[restricted].words.iteritems():\n",
    "    for item in l:\n",
    "        word_counts[item] += 1\n",
    "word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "      <th>masks</th>\n",
       "      <th>words</th>\n",
       "      <th>phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "      <td>[investigate]</td>\n",
       "      <td>[[to, investigate, reports, of, possible, ``]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[The, grand, jury, commented, on, a, number, o...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[operated, purchasing]</td>\n",
       "      <td>[[purchasing], [well, operated, and, follow]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[However, ,, the, jury, said, it, believes, ``...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[administration]</td>\n",
       "      <td>[[administration]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[It, urged, that, the, next, Legislature, ``, ...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[provide]</td>\n",
       "      <td>[[that, the, next, Legislature, ``, provide, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[The, jury, also, commented, on, the, Fulton, ...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[administrators]</td>\n",
       "      <td>[[administrators]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sent source description  \\\n",
       "2   [The, September-October, term, jury, had, been...  brown        None   \n",
       "6   [The, grand, jury, commented, on, a, number, o...  brown        None   \n",
       "8   [However, ,, the, jury, said, it, believes, ``...  brown        None   \n",
       "12  [It, urged, that, the, next, Legislature, ``, ...  brown        None   \n",
       "18  [The, jury, also, commented, on, the, Fulton, ...  brown        None   \n",
       "\n",
       "                                                masks                   words  \\\n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...           [investigate]   \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [operated, purchasing]   \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        [administration]   \n",
       "12  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...               [provide]   \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        [administrators]   \n",
       "\n",
       "                                              phrases  \n",
       "2      [[to, investigate, reports, of, possible, ``]]  \n",
       "6       [[purchasing], [well, operated, and, follow]]  \n",
       "8                                  [[administration]]  \n",
       "12  [[that, the, next, Legislature, ``, provide, e...  \n",
       "18                                 [[administrators]]  "
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(sents_df[restricted]))\n",
    "sents_df[restricted].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_df[restricted].to_pickle('data/lexical_repl/sents-df-restricted.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now marked, the phrases are extracted from the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_df = pd.read_pickle('data/lexical_repl/sents-df-with-frags.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "      <th>masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, September-October, term, jury, had, been...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[The, grand, jury, commented, on, a, number, o...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[However, ,, the, jury, said, it, believes, ``...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[It, urged, that, the, next, Legislature, ``, ...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[The, jury, also, commented, on, the, Fulton, ...</td>\n",
       "      <td>brown</td>\n",
       "      <td>None</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sent source description  \\\n",
       "2   [The, September-October, term, jury, had, been...  brown        None   \n",
       "6   [The, grand, jury, commented, on, a, number, o...  brown        None   \n",
       "8   [However, ,, the, jury, said, it, believes, ``...  brown        None   \n",
       "12  [It, urged, that, the, next, Legislature, ``, ...  brown        None   \n",
       "18  [The, jury, also, commented, on, the, Fulton, ...  brown        None   \n",
       "\n",
       "                                                masks  \n",
       "2   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, ...  \n",
       "6   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "8   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "12  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, ...  \n",
       "18  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 1059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12530f2aeffc4248b91637e95c7e7b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=525114), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "relevant_words = []\n",
    "phrases = []\n",
    "\n",
    "replace = defaultdict(list)\n",
    "\n",
    "for idx, row in tqdm(sents_df.iterrows(), total = len(sents_df)):\n",
    "    \n",
    "    current_phrases = []\n",
    "    on_phrase = False\n",
    "    phrase = []\n",
    "    for i in range(len(row.masks)):\n",
    "        if row.masks[i]:\n",
    "            phrase.append(row.sent[i])\n",
    "            if not on_phrase:\n",
    "                on_phrase = True\n",
    "        if not row.masks[i]:\n",
    "            if on_phrase:\n",
    "                on_phrase = False\n",
    "                current_phrases.append(phrase)\n",
    "                phrase = []\n",
    "                \n",
    "    current_words = []\n",
    "    for p in current_phrases:\n",
    "        for w in all_formal_words:\n",
    "            if w in p:\n",
    "                current_words.append(w)\n",
    "                replace[w].append(p)\n",
    "                continue\n",
    "    current_words = list(set(current_words))\n",
    "    \n",
    "    relevant_words.append(current_words)\n",
    "    phrases.append(current_phrases)\n",
    "    \n",
    "sents_df['words'] = relevant_words\n",
    "sents_df['phrases'] = phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_df.to_pickle('data/lexical_repl/sents-df-with-frags-detail.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in replace:\n",
    "    x = set()\n",
    "    for item in replace[key]:\n",
    "        x.add(tuple(item))\n",
    "    replace[key] = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dictionary of words and phrases into df\n",
    "\n",
    "phrase = []\n",
    "word = []\n",
    "\n",
    "for key in replace:\n",
    "    for val in replace[key]:\n",
    "        phrase.append(val)\n",
    "        word.append(key)\n",
    "        \n",
    "repl_df = pd.DataFrame()\n",
    "repl_df['word'] = word\n",
    "repl_df['orig'] = phrase\n",
    "repl_df['repl'] = [None]*len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orig</th>\n",
       "      <th>repl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internal</td>\n",
       "      <td>(the, bank, 's, still-sloppy, internal, controls)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>internal</td>\n",
       "      <td>(external, and, internal)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>internal</td>\n",
       "      <td>((, internal, leaf, crowns)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>internal</td>\n",
       "      <td>(one, internal, pocket)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>internal</td>\n",
       "      <td>(the, internal, variations)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word                                               orig  repl\n",
       "0  internal  (the, bank, 's, still-sloppy, internal, controls)  None\n",
       "1  internal                          (external, and, internal)  None\n",
       "2  internal                        ((, internal, leaf, crowns)  None\n",
       "3  internal                            (one, internal, pocket)  None\n",
       "4  internal                        (the, internal, variations)  None"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_df.to_pickle('data/lexical_repl/repl_df.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# semi-automatically provide translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, in a similar process as before, I replace the formal words in the extracted phrases with their defined informal replacement. I at least make sure to evaluate, at least briefly, each word to make sure it can be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_df = pd.read_pickle('data/lexical_repl/repl_df.zip')\n",
    "repl_df = repl_df.drop_duplicates(subset = 'orig', keep = False)\n",
    "with open('data/lexical_repl/words_dict.pkl', 'rb') as f:\n",
    "    dc = pickle.load(f)\n",
    "with open('data/lexical_repl/acrolinx.json', 'r') as f:\n",
    "    acro = json.load(f)\n",
    "with open('data/lexical_repl/list-formal-words-only.pkl', 'rb') as f:\n",
    "    form = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(word, replace, phrase):\n",
    "    phrase = list(phrase)\n",
    "    new_phrase = [replace if x == word else x for x in phrase]\n",
    "    new_phrase = ' '.join(new_phrase)\n",
    "    new_phrase = word_tokenize(new_phrase)\n",
    "    return new_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa0518751744b5a90c24d6b9dd10768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=369487), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#remaining = set()\n",
    "\n",
    "for idx, row in tqdm(repl_df.iterrows(), total = len(repl_df)):\n",
    "    if repl_df.at[idx, 'repl'] != None:\n",
    "        continue\n",
    "    #remaining.add(row.word)\n",
    "    if row.word in acro:\n",
    "        ind = row.orig.index(row.word)\n",
    "        pos = nltk.pos_tag(list(row.orig))[ind][1]\n",
    "        repl_pos = []\n",
    "        for item in acro[row.word]:\n",
    "            temp_pos = nltk.pos_tag(word_tokenize(item))[0]\n",
    "            if temp_pos[1] == pos:\n",
    "                repl_pos.append(temp_pos[0])\n",
    "        if len(repl_pos) > 1:\n",
    "            w = sample(repl_pos, 1)[0]\n",
    "        elif len(repl_pos) == 1:\n",
    "            w = repl_pos[0]\n",
    "        else:\n",
    "            w = sample(acro[row.word], 1)[0]\n",
    "        repl_df.at[idx, 'repl'] = replace(row.word, w, row.orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repl_df = repl_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>orig</th>\n",
       "      <th>repl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>internal</td>\n",
       "      <td>(the, bank, 's, still-sloppy, internal, controls)</td>\n",
       "      <td>[the, bank, 's, still-sloppy, inside, controls]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>internal</td>\n",
       "      <td>((, internal, leaf, crowns)</td>\n",
       "      <td>[(, inside, leaf, crowns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>internal</td>\n",
       "      <td>(one, internal, pocket)</td>\n",
       "      <td>[one, inside, pocket]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>internal</td>\n",
       "      <td>(the, internal, variations)</td>\n",
       "      <td>[the, inside, variations]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>internal</td>\n",
       "      <td>(Yugoslavia, 's, internal, common, market)</td>\n",
       "      <td>[Yugoslavia, 's, inside, common, market]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word                                               orig  \\\n",
       "0  internal  (the, bank, 's, still-sloppy, internal, controls)   \n",
       "2  internal                        ((, internal, leaf, crowns)   \n",
       "3  internal                            (one, internal, pocket)   \n",
       "4  internal                        (the, internal, variations)   \n",
       "5  internal         (Yugoslavia, 's, internal, common, market)   \n",
       "\n",
       "                                              repl  \n",
       "0  [the, bank, 's, still-sloppy, inside, controls]  \n",
       "2                        [(, inside, leaf, crowns]  \n",
       "3                            [one, inside, pocket]  \n",
       "4                        [the, inside, variations]  \n",
       "5         [Yugoslavia, 's, inside, common, market]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62babf6cb31649868b0a556816124d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=306715), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "repl_dict = {}\n",
    "for idx, row in tqdm(repl_df.iterrows(), total = len(repl_df)):\n",
    "    repl_dict[' '.join(row.orig)] = ' '.join(row.repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl/repl_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(repl_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_df.to_pickle('data/lexical_repl/repl_df.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare for NMT\n",
    "\n",
    "orig_data = [list(x) for x in list(repl_df.dropna().orig)]\n",
    "repl_data = list(repl_df.dropna().repl)\n",
    "assert len(orig_data) == len(repl_data)\n",
    "\n",
    "orig_train, orig_test, repl_train, repl_test = train_test_split(orig_data, \n",
    "                                                                repl_data, \n",
    "                                                                test_size = .1,\n",
    "                                                               random_state = 47)\n",
    "orig_train, orig_val, repl_train, repl_val = train_test_split(orig_train,\n",
    "                                                             repl_train,\n",
    "                                                             test_size = .2,\n",
    "                                                             random_state = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/lexical_repl_models/src-train.txt', 'w') as f:\n",
    "    for x in orig_train:\n",
    "        f.write(' '.join(x) + '\\n')\n",
    "    \n",
    "with open('data/lexical_repl_models/src-val.txt', 'w') as f:\n",
    "    for x in orig_val:\n",
    "        f.write(' '.join(x) + '\\n')\n",
    "    \n",
    "with open('data/lexical_repl_models/src-test.txt', 'w') as f:\n",
    "    for x in orig_test:\n",
    "        f.write(' '.join(x) + '\\n')\n",
    "    \n",
    "with open('data/lexical_repl_models/tgt-train.txt', 'w') as f:\n",
    "    for x in repl_train:\n",
    "        f.write(' '.join(x) + '\\n')\n",
    "    \n",
    "with open('data/lexical_repl_models/tgt-val.txt', 'w') as f:\n",
    "    for x in repl_val:\n",
    "        f.write(' '.join(x) + '\\n')\n",
    "    \n",
    "with open('data/lexical_repl_models/tgt-test.txt', 'w') as f:\n",
    "    for x in repl_test:\n",
    "        f.write(' '.join(x) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unused: more detailed replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_do.remove('abeyance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abominate',\n",
       " 'abominated',\n",
       " 'abundance',\n",
       " 'accelerate',\n",
       " 'accelerated',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accordingly',\n",
       " 'accrue',\n",
       " 'accrued',\n",
       " 'accrues',\n",
       " 'accruing',\n",
       " 'accurate',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acquiesce',\n",
       " 'acquiesced',\n",
       " 'acquiesces',\n",
       " 'acquiescing',\n",
       " 'acquisition',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'activations',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'administrators',\n",
       " 'admissible',\n",
       " 'aforementioned',\n",
       " 'aforesaid',\n",
       " 'agent',\n",
       " 'aggregate',\n",
       " 'aggregated',\n",
       " 'aggregates',\n",
       " 'aggregating',\n",
       " 'aggregation',\n",
       " 'aggregations',\n",
       " 'alleged',\n",
       " 'alleviate',\n",
       " 'alleviated',\n",
       " 'alleviates',\n",
       " 'alleviating',\n",
       " 'allocate',\n",
       " 'allocated',\n",
       " 'allocates',\n",
       " 'allocating',\n",
       " 'allocation',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'ameliorate',\n",
       " 'ameliorated',\n",
       " 'ameliorates',\n",
       " 'ameliorating',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amongst',\n",
       " 'analyze',\n",
       " 'analyzer',\n",
       " 'anew',\n",
       " 'anomalous',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipates',\n",
       " 'anticipating',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apparent',\n",
       " 'applicability',\n",
       " 'application',\n",
       " 'apprehend',\n",
       " 'apprehended',\n",
       " 'apprehending',\n",
       " 'apprehends',\n",
       " 'appropriate',\n",
       " 'apropos',\n",
       " 'architecture',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'articulates',\n",
       " 'articulating',\n",
       " 'ascertain',\n",
       " 'ascertained',\n",
       " 'ascertaining',\n",
       " 'ascertains',\n",
       " 'assert',\n",
       " 'asserted',\n",
       " 'asserting',\n",
       " 'assertion',\n",
       " 'assertions',\n",
       " 'asserts',\n",
       " 'assess',\n",
       " 'assessed',\n",
       " 'assesses',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'assessments',\n",
       " 'asset',\n",
       " 'assets',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assigning',\n",
       " 'assigns',\n",
       " 'associate',\n",
       " 'attain',\n",
       " 'attained',\n",
       " 'attaining',\n",
       " 'attains',\n",
       " 'attempt',\n",
       " 'attest',\n",
       " 'attested',\n",
       " 'attesting',\n",
       " 'attests',\n",
       " 'attribute',\n",
       " 'audit',\n",
       " 'audited',\n",
       " 'auditing',\n",
       " 'audits',\n",
       " 'aught',\n",
       " 'authorization',\n",
       " 'authorizations',\n",
       " 'authorize',\n",
       " 'authorized',\n",
       " 'authorizes',\n",
       " 'authorizing',\n",
       " 'aver',\n",
       " 'averred',\n",
       " 'avers',\n",
       " 'aye',\n",
       " 'ayes',\n",
       " 'becometh',\n",
       " 'belated',\n",
       " 'beseech',\n",
       " 'beseeched',\n",
       " 'beseeches',\n",
       " 'beseeching',\n",
       " 'besought',\n",
       " 'bestow',\n",
       " 'betwixt',\n",
       " 'beverage',\n",
       " 'beverages',\n",
       " 'bind',\n",
       " 'binding',\n",
       " 'capabilities',\n",
       " 'capability',\n",
       " 'capacity',\n",
       " 'carnivore',\n",
       " 'caveat',\n",
       " 'caveats',\n",
       " 'cease',\n",
       " 'certainty',\n",
       " 'charm',\n",
       " 'charmed',\n",
       " 'charming',\n",
       " 'charms',\n",
       " 'climate',\n",
       " 'cogitate',\n",
       " 'cogitated',\n",
       " 'cogitating',\n",
       " 'comestibles',\n",
       " 'commence',\n",
       " 'commenced',\n",
       " 'commences',\n",
       " 'commencing',\n",
       " 'compliant',\n",
       " 'component',\n",
       " 'components',\n",
       " 'comprise',\n",
       " 'comprised',\n",
       " 'comprises',\n",
       " 'comprising',\n",
       " 'compute',\n",
       " 'computed',\n",
       " 'computes',\n",
       " 'computing',\n",
       " 'conceal',\n",
       " 'concealed',\n",
       " 'concealing',\n",
       " 'conceals',\n",
       " 'concurrent',\n",
       " 'condition',\n",
       " 'configuration',\n",
       " 'configurations',\n",
       " 'conjure',\n",
       " 'conjured',\n",
       " 'conjures',\n",
       " 'conjuring',\n",
       " 'consensus',\n",
       " 'consensuses',\n",
       " 'consolidate',\n",
       " 'constitute',\n",
       " 'contain',\n",
       " 'contained',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'contra',\n",
       " 'convene',\n",
       " 'cornerstone',\n",
       " 'criteria',\n",
       " 'criterion',\n",
       " 'currently',\n",
       " 'daunting',\n",
       " 'deactivate',\n",
       " 'decrease',\n",
       " 'decreased',\n",
       " 'decreases',\n",
       " 'decreasing',\n",
       " 'deem',\n",
       " 'deemed',\n",
       " 'deeming',\n",
       " 'deems',\n",
       " 'deficiencies',\n",
       " 'deficiency',\n",
       " 'degradation',\n",
       " 'degradations',\n",
       " 'delegate',\n",
       " 'delegated',\n",
       " 'delegates',\n",
       " 'delegating',\n",
       " 'deletion',\n",
       " 'deletions',\n",
       " 'delineate',\n",
       " 'delineated',\n",
       " 'delineates',\n",
       " 'delineating',\n",
       " 'depart',\n",
       " 'departed',\n",
       " 'departing',\n",
       " 'departs',\n",
       " 'departure',\n",
       " 'departures',\n",
       " 'depict',\n",
       " 'depicted',\n",
       " 'depicting',\n",
       " 'depicts',\n",
       " 'derive',\n",
       " 'derived',\n",
       " 'derives',\n",
       " 'deriving',\n",
       " 'designate',\n",
       " 'desire',\n",
       " 'desired',\n",
       " 'desires',\n",
       " 'desiring',\n",
       " 'determine',\n",
       " 'determined',\n",
       " 'determines',\n",
       " 'determining',\n",
       " 'diagnostic',\n",
       " 'diagnostics',\n",
       " 'disclose',\n",
       " 'disclosed',\n",
       " 'discloses',\n",
       " 'disclosing',\n",
       " 'discontinue',\n",
       " 'discontinued',\n",
       " 'discontinues',\n",
       " 'discontinuing',\n",
       " 'discover',\n",
       " 'discovered',\n",
       " 'discovering',\n",
       " 'discovers',\n",
       " 'display',\n",
       " 'disseminate',\n",
       " 'disseminated',\n",
       " 'disseminates',\n",
       " 'disseminating',\n",
       " 'distinguish',\n",
       " 'domain',\n",
       " 'domains',\n",
       " 'doth',\n",
       " 'duration',\n",
       " 'durations',\n",
       " 'eke',\n",
       " 'eked',\n",
       " 'ekes',\n",
       " 'eking',\n",
       " 'elicit',\n",
       " 'elicited',\n",
       " 'eliciting',\n",
       " 'elicits',\n",
       " 'elucidate',\n",
       " 'elucidated',\n",
       " 'elucidates',\n",
       " 'elucidating',\n",
       " 'embodied',\n",
       " 'embodies',\n",
       " 'embodiment',\n",
       " 'embodiments',\n",
       " 'embody',\n",
       " 'embodying',\n",
       " 'emolument',\n",
       " 'emoluments',\n",
       " 'enchant',\n",
       " 'encompass',\n",
       " 'encompassed',\n",
       " 'encompasses',\n",
       " 'encompassing',\n",
       " 'encounter',\n",
       " 'encountered',\n",
       " 'encountering',\n",
       " 'encounters',\n",
       " 'endeavor',\n",
       " 'endeavored',\n",
       " 'endeavoring',\n",
       " 'endeavors',\n",
       " 'endorse',\n",
       " 'endorsed',\n",
       " 'endorses',\n",
       " 'endorsing',\n",
       " 'endpoint',\n",
       " 'enforce',\n",
       " 'enforced',\n",
       " 'enforces',\n",
       " 'enforcing',\n",
       " 'enkindle',\n",
       " 'enrichment',\n",
       " 'ensure',\n",
       " 'ensured',\n",
       " 'ensures',\n",
       " 'ensuring',\n",
       " 'entail',\n",
       " 'entailed',\n",
       " 'entailing',\n",
       " 'entails',\n",
       " 'entities',\n",
       " 'entity',\n",
       " 'enumerate',\n",
       " 'enumerated',\n",
       " 'enumerates',\n",
       " 'enumerating',\n",
       " 'enunciate',\n",
       " 'enunciated',\n",
       " 'enunciates',\n",
       " 'enunciating',\n",
       " 'equitable',\n",
       " 'equivalent',\n",
       " 'ere',\n",
       " 'ergo',\n",
       " 'establish',\n",
       " 'established',\n",
       " 'establishes',\n",
       " 'establishing',\n",
       " 'etc',\n",
       " 'evidenced',\n",
       " 'evince',\n",
       " 'evinced',\n",
       " 'evinces',\n",
       " 'evincing',\n",
       " 'evoke',\n",
       " 'evoked',\n",
       " 'evokes',\n",
       " 'evoking',\n",
       " 'exceed',\n",
       " 'exceeded',\n",
       " 'exceeding',\n",
       " 'exceeds',\n",
       " 'exclude',\n",
       " 'excluded',\n",
       " 'excludes',\n",
       " 'excluding',\n",
       " 'exclusion',\n",
       " 'execution',\n",
       " 'exemplified',\n",
       " 'exemplifies',\n",
       " 'exemplify',\n",
       " 'exemplifying',\n",
       " 'exhibit',\n",
       " 'exhibited',\n",
       " 'exhibiting',\n",
       " 'exhibits',\n",
       " 'expedite',\n",
       " 'expedited',\n",
       " 'expediting',\n",
       " 'expeditious',\n",
       " 'expend',\n",
       " 'expended',\n",
       " 'expending',\n",
       " 'expends',\n",
       " 'expiration',\n",
       " 'expire',\n",
       " 'expired',\n",
       " 'expires',\n",
       " 'expiring',\n",
       " 'explode',\n",
       " 'expose',\n",
       " 'exposed',\n",
       " 'exposes',\n",
       " 'exposing',\n",
       " 'external',\n",
       " 'extract',\n",
       " 'extraction',\n",
       " 'fabricate',\n",
       " 'fabricated',\n",
       " 'fabricates',\n",
       " 'fabricating',\n",
       " 'facilitate',\n",
       " 'facilitated',\n",
       " 'facilitates',\n",
       " 'facilitating',\n",
       " 'fain',\n",
       " 'farewell',\n",
       " 'farewells',\n",
       " 'finalize',\n",
       " 'finalized',\n",
       " 'finalizes',\n",
       " 'finalizing',\n",
       " 'foregoing',\n",
       " 'forfeit',\n",
       " 'forfeited',\n",
       " 'forfeiting',\n",
       " 'forfeits',\n",
       " 'forsooth',\n",
       " 'forthright',\n",
       " 'forthwith',\n",
       " 'fortnightly',\n",
       " 'framework',\n",
       " 'frameworks',\n",
       " 'function',\n",
       " 'functional',\n",
       " 'generate',\n",
       " 'generated',\n",
       " 'generates',\n",
       " 'generating',\n",
       " 'govern',\n",
       " 'governed',\n",
       " 'governing',\n",
       " 'governs',\n",
       " 'grant',\n",
       " 'guidance',\n",
       " 'hark',\n",
       " 'harked',\n",
       " 'harking',\n",
       " 'harks',\n",
       " 'hath',\n",
       " 'hence',\n",
       " 'henceforth',\n",
       " 'henceforward',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereinafter',\n",
       " 'hereof',\n",
       " 'heretofore',\n",
       " 'hereunder',\n",
       " 'hereunto',\n",
       " 'hither',\n",
       " 'hub',\n",
       " 'identified',\n",
       " 'identifies',\n",
       " 'identify',\n",
       " 'identifying',\n",
       " 'impervious',\n",
       " 'implicit',\n",
       " 'inasmuch',\n",
       " 'inception',\n",
       " 'inceptions',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'increases',\n",
       " 'increasing',\n",
       " 'increment',\n",
       " 'incremented',\n",
       " 'increments',\n",
       " 'indicator',\n",
       " 'indicators',\n",
       " 'individual',\n",
       " 'individuals',\n",
       " 'indubitably',\n",
       " 'inexpensive',\n",
       " 'ingestion',\n",
       " 'initial',\n",
       " 'initialized',\n",
       " 'initiate',\n",
       " 'initiated',\n",
       " 'initiates',\n",
       " 'initiating',\n",
       " 'initiative',\n",
       " 'initiator',\n",
       " 'inquire',\n",
       " 'inquired',\n",
       " 'inquires',\n",
       " 'inquiring',\n",
       " 'instill',\n",
       " 'instilled',\n",
       " 'instilling',\n",
       " 'instills',\n",
       " 'internal',\n",
       " 'investigate',\n",
       " 'invoke',\n",
       " 'invoked',\n",
       " 'invokes',\n",
       " 'invoking',\n",
       " 'irrespective',\n",
       " 'magnitude',\n",
       " 'magnitudes',\n",
       " 'maintain',\n",
       " 'maintained',\n",
       " 'maintaining',\n",
       " 'maintains',\n",
       " 'maintenance',\n",
       " 'manifest',\n",
       " 'manifested',\n",
       " 'manifesting',\n",
       " 'manifests',\n",
       " 'masticate',\n",
       " 'masticated',\n",
       " 'masticates',\n",
       " 'masticating',\n",
       " 'methinks',\n",
       " 'mitigation',\n",
       " 'modification',\n",
       " 'modifications',\n",
       " 'modified',\n",
       " 'modifies',\n",
       " 'modify',\n",
       " 'modifying',\n",
       " 'monitor',\n",
       " 'moreover',\n",
       " 'morrow',\n",
       " 'multiple',\n",
       " 'nary',\n",
       " 'necessitate',\n",
       " 'necessitated',\n",
       " 'necessitates',\n",
       " 'necessitating',\n",
       " 'nevertheless',\n",
       " 'notwithstanding',\n",
       " 'numerous',\n",
       " 'objective',\n",
       " 'obtain',\n",
       " 'obtained',\n",
       " 'obtaining',\n",
       " 'obtains',\n",
       " 'omit',\n",
       " 'omits',\n",
       " 'omitted',\n",
       " 'omitting',\n",
       " 'operate',\n",
       " 'operated',\n",
       " 'operates',\n",
       " 'operating',\n",
       " 'operation',\n",
       " 'operator',\n",
       " 'operators',\n",
       " 'oppose',\n",
       " 'opposed',\n",
       " 'opposes',\n",
       " 'opposing',\n",
       " 'optimum',\n",
       " 'orientate',\n",
       " 'particulars',\n",
       " 'penurious',\n",
       " 'perchance',\n",
       " 'permit',\n",
       " 'permits',\n",
       " 'permitted',\n",
       " 'permitting',\n",
       " 'perspire',\n",
       " 'perspired',\n",
       " 'perspiring',\n",
       " 'peruse',\n",
       " 'perused',\n",
       " 'peruses',\n",
       " 'perusing',\n",
       " 'portray',\n",
       " 'portrayed',\n",
       " 'portraying',\n",
       " 'portrays',\n",
       " 'posit',\n",
       " 'posited',\n",
       " 'positing',\n",
       " 'posits',\n",
       " 'possess',\n",
       " 'possessed',\n",
       " 'possesses',\n",
       " 'possessing',\n",
       " 'potentialities',\n",
       " 'potentiality',\n",
       " 'preclude',\n",
       " 'precluded',\n",
       " 'precludes',\n",
       " 'precluding',\n",
       " 'prerequisite',\n",
       " 'prerequisites',\n",
       " 'prioritize',\n",
       " 'proceed',\n",
       " 'proceeded',\n",
       " 'proceeding',\n",
       " 'proceeds',\n",
       " 'procure',\n",
       " 'procured',\n",
       " 'procures',\n",
       " 'procuring',\n",
       " 'proficiencies',\n",
       " 'proficiency',\n",
       " 'promulgate',\n",
       " 'promulgated',\n",
       " 'promulgates',\n",
       " 'promulgating',\n",
       " 'provide',\n",
       " 'provided',\n",
       " 'provider',\n",
       " 'provides',\n",
       " 'providing',\n",
       " 'provision',\n",
       " 'proviso',\n",
       " 'provisos',\n",
       " 'purchase',\n",
       " 'purchased',\n",
       " 'purchases',\n",
       " 'purchasing',\n",
       " 'purported',\n",
       " 'purportedly',\n",
       " 'recipient',\n",
       " 'recipients',\n",
       " 'reflect',\n",
       " 'regardless',\n",
       " 'register',\n",
       " 'regulation',\n",
       " 'regulations',\n",
       " 'release',\n",
       " 'relocate',\n",
       " 'relocated',\n",
       " 'relocates',\n",
       " 'relocating',\n",
       " 'remain',\n",
       " 'remainder',\n",
       " 'remaindered',\n",
       " 'remaindering',\n",
       " 'remainders',\n",
       " 'remained',\n",
       " 'remaining',\n",
       " 'remains',\n",
       " 'remediation',\n",
       " 'remuneration',\n",
       " 'render',\n",
       " 'rendering',\n",
       " 'replica',\n",
       " 'replicas',\n",
       " 'replicate',\n",
       " 'replicated',\n",
       " 'replicates',\n",
       " 'replicating',\n",
       " 'replication',\n",
       " 'replications',\n",
       " 'request',\n",
       " 'require',\n",
       " 'required',\n",
       " 'requires',\n",
       " 'requiring',\n",
       " 'reside',\n",
       " 'resided',\n",
       " 'residence',\n",
       " 'resides',\n",
       " 'residing',\n",
       " 'respiration',\n",
       " 'respirations',\n",
       " 'respire',\n",
       " 'respired',\n",
       " 'respires',\n",
       " 'respiring',\n",
       " 'respond',\n",
       " 'responded',\n",
       " 'responding',\n",
       " 'responds',\n",
       " 'response',\n",
       " 'responses',\n",
       " 'restrict',\n",
       " 'restricted',\n",
       " 'restricting',\n",
       " 'restriction',\n",
       " 'restrictions',\n",
       " 'restricts',\n",
       " 'retain',\n",
       " 'retained',\n",
       " 'retaining',\n",
       " 'retains',\n",
       " 'select',\n",
       " 'selection',\n",
       " 'selections',\n",
       " 'shall',\n",
       " 'solace',\n",
       " 'solaced',\n",
       " 'solaces',\n",
       " 'solicit',\n",
       " 'solicited',\n",
       " 'soliciting',\n",
       " 'solicits',\n",
       " 'specification',\n",
       " 'specifications',\n",
       " 'specified',\n",
       " 'specifies',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'stipulate',\n",
       " 'stipulated',\n",
       " 'stipulates',\n",
       " 'stipulating',\n",
       " 'strategize',\n",
       " 'strategizing',\n",
       " 'subsequent',\n",
       " 'substantial',\n",
       " 'substitute',\n",
       " 'substituted',\n",
       " 'substitutes',\n",
       " 'substituting',\n",
       " 'swain',\n",
       " 'swains',\n",
       " 'synopses',\n",
       " 'synopsis',\n",
       " 'technique',\n",
       " 'techniques',\n",
       " 'terminate',\n",
       " 'terminated',\n",
       " 'terminates',\n",
       " 'terminating',\n",
       " 'thee',\n",
       " 'thence',\n",
       " 'thenceforth',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereof',\n",
       " 'thereon',\n",
       " 'thereto',\n",
       " 'theretofore',\n",
       " 'thereunto',\n",
       " 'thereupon',\n",
       " 'therewith',\n",
       " 'thither',\n",
       " 'thou',\n",
       " 'thus',\n",
       " 'thy',\n",
       " 'transfer',\n",
       " 'transformation',\n",
       " 'transformations',\n",
       " 'trigger',\n",
       " 'twain',\n",
       " 'twixt',\n",
       " 'undermine',\n",
       " 'undermined',\n",
       " 'undermines',\n",
       " 'undermining',\n",
       " 'unto',\n",
       " 'upon',\n",
       " 'upsurge',\n",
       " 'utilization',\n",
       " 'utilize',\n",
       " 'utilized',\n",
       " 'utilizes',\n",
       " 'utilizing',\n",
       " 'validate',\n",
       " 'validated',\n",
       " 'validates',\n",
       " 'validating',\n",
       " 'validation',\n",
       " 'validations',\n",
       " 'variable',\n",
       " 'verification',\n",
       " 'verifications',\n",
       " 'verified',\n",
       " 'verifies',\n",
       " 'verify',\n",
       " 'verifying',\n",
       " 'verily',\n",
       " 'vocalize',\n",
       " 'vocalized',\n",
       " 'vocalizing',\n",
       " 'vouchsafe',\n",
       " 'vouchsafed',\n",
       " 'vouchsafes',\n",
       " 'vouchsafing',\n",
       " 'warrant',\n",
       " 'whatsoever',\n",
       " 'whence',\n",
       " 'whensoever',\n",
       " 'wherefore',\n",
       " 'whereof',\n",
       " 'whereon',\n",
       " 'wherewith',\n",
       " 'whilst',\n",
       " 'whither',\n",
       " 'whomsoever',\n",
       " 'whosoever',\n",
       " 'withal',\n",
       " 'wonted',\n",
       " 'wrought',\n",
       " 'zone']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'accelerate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate\n",
      "acro ['speed up']\n"
     ]
    }
   ],
   "source": [
    "print(word)\n",
    "if word in dc:\n",
    "    print(dc[word])\n",
    "if word in acro:\n",
    "    print('acro ' + str(acro[word]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(phrase):\n",
    "    phrase = list(phrase)\n",
    "    return ['speed' if x == word else x for x in phrase] + 'up'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_these = [52452,52453,52457,52459,52460,52461,52467,52472,52473,\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2d09928c56467d9d2cb1c10528b06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=227), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52452\n",
      "('to', 'accelerate', 'the', 'introduction', 'of', 'an', 'appraisal', 'scheme', 'for', 'teachers')\n",
      "\n",
      "52453\n",
      "('to', 'accelerate', 'them')\n",
      "\n",
      "52454\n",
      "('to', 'accelerate', 'the', 'harmonious', 'development', 'of')\n",
      "\n",
      "52456\n",
      "('accelerate', 'the', 'tests', 'if', 'the')\n",
      "\n",
      "52457\n",
      "(')', 'accelerate')\n",
      "\n",
      "52458\n",
      "('to', 'accelerate', 'in', 'order', 'to', 'meet')\n",
      "\n",
      "52459\n",
      "('to', 'accelerate', 'boxing', \"'s\", 'decline')\n",
      "\n",
      "52460\n",
      "('to', 'accelerate', 'our', 'programmes', 'for', 'reducing', 'costs', 'and', 'raising', 'productivity')\n",
      "\n",
      "52461\n",
      "('to', 'accelerate', 'the', 'development', 'and', 'deployment', 'of', 'low-carbon')\n",
      "\n",
      "52463\n",
      "('effect', ',', 'global', 'warming', 'will', 'accelerate', 'sharply', ',', 'with', 'unpredictable')\n",
      "\n",
      "52464\n",
      "('accelerate', 'harder')\n",
      "\n",
      "52465\n",
      "('to', 'accelerate', 'water', 'or', 'air', 'past')\n",
      "\n",
      "52466\n",
      "('to', 'accelerate', 'and', 'involved', 'quite', 'different', 'factors')\n",
      "\n",
      "52467\n",
      "('turbulence', 'and', 'accelerate', 'movement')\n",
      "\n",
      "52468\n",
      "('to', 'accelerate', 'and', 'beat', 'only', 'one')\n",
      "\n",
      "52469\n",
      "('the', 'machine', 'will', 'accelerate', 'up', 'to', 'a', 'speed')\n",
      "\n",
      "52470\n",
      "('to', 'accelerate', 'the', 'process', ',', 'despite')\n",
      "\n",
      "52471\n",
      "('that', 'privatisation', 'would', 'accelerate', 'that', 'achievement', ',')\n",
      "\n",
      "52472\n",
      "('to', 'accelerate', 'the', 'introduction', 'of', 'democracy')\n",
      "\n",
      "52473\n",
      "('to', 'accelerate', 'the', 'process', 'of', 'peace')\n",
      "\n",
      "52474\n",
      "('to', 'accelerate', 'the', 'drafting', 'of', 'a')\n",
      "\n",
      "52476\n",
      "('The', 'Balkan', 'crisis', 'will', 'accelerate', 'China', \"'s\", 'military', 'modernization', 'drive')\n",
      "\n",
      "52477\n",
      "('1979–80', 'accelerate', 'job', 'losses')\n",
      "\n",
      "52478\n",
      "('to', 'accelerate', 'learning', 'and', 'growth', 'of')\n",
      "\n",
      "52479\n",
      "('to', 'accelerate', 'hard')\n",
      "\n",
      "52480\n",
      "('to', 'accelerate', 'the', 'rundown', 'of', 'the', 'large', 'mental', 'handicap', 'hospitals')\n",
      "\n",
      "52481\n",
      "('that', 'the', 'car', 'should', 'accelerate', 'to', 'a', 'speed', 'of')\n",
      "\n",
      "52482\n",
      "('to', 'accelerate', 'the', 'rate', 'of', 'investment')\n",
      "\n",
      "52483\n",
      "('accelerate', 'less', 'rapidly', 'than', 'if', 'there', 'were', 'one', 'log')\n",
      "\n",
      "52484\n",
      "('to', 'accelerate', 'the', 'expansion', 'of', 'secure')\n",
      "\n",
      "52486\n",
      "('that', 'both', 'egg', 'production', 'and', 'mating', 'could', 'accelerate', 'ageing')\n",
      "\n",
      "52487\n",
      "('accelerate', 'reaching', 'exam', 'standard', 'by', 'existing', 'trainee', 'teachers')\n",
      "\n",
      "52488\n",
      "('to', 'accelerate', 'temperature', 'effects', 'by', 'storage', 'at', 'sill', 'higher', 'temperatures')\n",
      "\n",
      "52489\n",
      "('to', 'accelerate', 'smoothly')\n",
      "\n",
      "52490\n",
      "('to', 'accelerate', 'new', 'building')\n",
      "\n",
      "52491\n",
      "('rate', 'of', 'global', 'warming', 'might', 'accelerate', 'due', 'to', 'hitherto', 'unforeseen')\n",
      "\n",
      "52492\n",
      "('to', 'accelerate', 'reforms')\n",
      "\n",
      "52493\n",
      "('which', 'accelerate', 'the', 'process', 'of', 'ageing')\n",
      "\n",
      "52494\n",
      "('accelerate', 'the', 'load', 'inertia')\n",
      "\n",
      "52496\n",
      "('may', 'accelerate', 'repayment', 'of', 'the', 'sums')\n",
      "\n",
      "52497\n",
      "('your', 'help', 'and', 'endorsement', 'can', 'accelerate', 'a', 'career', 'too', 'quickly')\n",
      "\n",
      "52498\n",
      "('to', 'accelerate', 'the', 'process', 'of', 'retirement')\n",
      "\n",
      "52499\n",
      "('to', 'accelerate', 'the', 'rate', 'of', 'scientific', 'progress')\n",
      "\n",
      "52500\n",
      "('to', 'accelerate', 'every', 'particle', 'within', 'its')\n",
      "\n",
      "52501\n",
      "('accelerate', ',', 'turn')\n",
      "\n",
      "52503\n",
      "('accelerate', 'the', 'process')\n",
      "\n",
      "52504\n",
      "('to', 'accelerate', 'this', 'trend')\n",
      "\n",
      "52506\n",
      "('to', 'accelerate', 'convergence', 'on', 'the', 'basis')\n",
      "\n",
      "52507\n",
      "('To', 'accelerate', 'vaccine', 'development')\n",
      "\n",
      "52508\n",
      "('that', 'accelerate', 'the', 'development', 'of', 'melanoma')\n",
      "\n",
      "52509\n",
      "('to', 'accelerate', 'healing', 'of', 'gastroduodenal', 'ulcers')\n",
      "\n",
      "52510\n",
      "('to', 'accelerate', 'this', 'end')\n",
      "\n",
      "52511\n",
      "('pressure', 'on', 'public', 'spending', 'will', 'accelerate', 'the', 'move', 'to', 'greater')\n",
      "\n",
      "52513\n",
      "('that', 'accelerate', 'the', 'age-related', 'decay', 'in', 'the', 'heart', 'and', 'arteries')\n",
      "\n",
      "52514\n",
      "('when', 'you', 'accelerate', '—', 'when', 'you', 'go')\n",
      "\n",
      "52516\n",
      "('accelerate', 'more', 'slowly', 'at', 'green', 'lights')\n",
      "\n",
      "52517\n",
      "('to', 'accelerate', 'the', 'process')\n",
      "\n",
      "52518\n",
      "('to', 'accelerate', 'this', 'process', 'and', 'effectively')\n",
      "\n",
      "52520\n",
      "('to', 'accelerate', 'economic', 'liberalization')\n",
      "\n",
      "52521\n",
      "('than', 'it', 'can', 'accelerate')\n",
      "\n",
      "52522\n",
      "('to', 'accelerate', 'its', 'efforts', 'to', '``')\n",
      "\n",
      "52524\n",
      "('To', 'accelerate', 'a', 'body', 'with', 'the')\n",
      "\n",
      "52525\n",
      "('to', 'accelerate', 'promotion')\n",
      "\n",
      "52526\n",
      "('accelerate',)\n",
      "\n",
      "52527\n",
      "('to', 'accelerate', 'income', 'or', 'expense', 'recognition')\n",
      "\n",
      "52528\n",
      "('accelerate', 'or', 'supplement')\n",
      "\n",
      "52529\n",
      "('to', 'accelerate', 'to', 'a', 'high', 'speed')\n",
      "\n",
      "52530\n",
      "('that', 'the', 'closure', 'of', 'rural', 'schools', 'will', 'accelerate', 'depopulation')\n",
      "\n",
      "52531\n",
      "('To', 'accelerate', 'to', 'flying', 'speed')\n",
      "\n",
      "52532\n",
      "('that', 'can', 'accelerate', 'growth', 'in', 'human', 'understanding')\n",
      "\n",
      "52534\n",
      "('to', 'accelerate', 'the', 'loss', 'of', 'soil')\n",
      "\n",
      "52535\n",
      "('accelerate', 'bushy', 'growth')\n",
      "\n",
      "52536\n",
      "('it', 'must', 'accelerate', 'rapidly', 'to', 'a', 'high', 'speed')\n",
      "\n",
      "52537\n",
      "('accelerate', 'the', 'drift', 'towards', 'professionalism')\n",
      "\n",
      "52539\n",
      "('to', 'accelerate', 'the', 'arms', 'race', 'and', 'militarism', 'of', 'all', 'kinds')\n",
      "\n",
      "52543\n",
      "('to', 'accelerate', 'decision', 'making')\n",
      "\n",
      "52544\n",
      "('to', 'accelerate', 'the', 'motor', 'to', 'a')\n",
      "\n",
      "52546\n",
      "('to', 'accelerate', 'in', 'February', '1965', ',')\n",
      "\n",
      "52547\n",
      "('to', 'accelerate', 'any', 'material', 'object', 'up', 'to', 'and', 'beyond', 'light-speed')\n",
      "\n",
      "52548\n",
      "('to', 'accelerate', 'the', 'motor', 'over', 'several')\n",
      "\n",
      "52549\n",
      "('to', 'accelerate', 'in', 'the', 'last', 'decades', 'of', 'the', 'century')\n",
      "\n",
      "52551\n",
      "('accelerate', 'the', 'gradual', 'unwinding', 'of')\n",
      "\n",
      "52552\n",
      "('to', 'accelerate', 'their', 'privatization')\n",
      "\n",
      "52553\n",
      "('the', 'train', 'accelerate')\n",
      "\n",
      "52554\n",
      "('to', 'accelerate', 'as', 'the', 'dry', 'season', 'wears', 'on')\n",
      "\n",
      "52555\n",
      "('which', 'may', 'accelerate', 'change', 'in', 'a', 'predominantly', 'female', 'workforce')\n",
      "\n",
      "52556\n",
      "('accelerate', 'maybe')\n",
      "\n",
      "52557\n",
      "('accelerate', 'his', 'reincarnation', 'as', 'a', '38DD', 'bra')\n",
      "\n",
      "52558\n",
      "('to', 'accelerate', 'between', 'these', 'speeds', 'within', 'one', 'step', 'length')\n",
      "\n",
      "52559\n",
      "('all', 'likelihood', 'this', 'trend', 'will', 'accelerate', ',', 'as', 'both', 'the')\n",
      "\n",
      "52560\n",
      "('to', 'accelerate', 'government', 'land', 'sales', ',')\n",
      "\n",
      "52561\n",
      "('to', 'accelerate', 'the', 'electrons')\n",
      "\n",
      "52563\n",
      "('to', 'accelerate', 'the', 'development', 'of', 'marketable')\n",
      "\n",
      "52564\n",
      "('accelerate', 'this', 'trend', 'rapidly')\n",
      "\n",
      "52565\n",
      "('to', 'accelerate', 'recanalisation', 'and', 'prevent', 'reocclusion')\n",
      "\n",
      "52566\n",
      "('decay', 'accelerate')\n",
      "\n",
      "52567\n",
      "('to', 'accelerate', ',', 'decelerate', ',', 'or')\n",
      "\n",
      "52568\n",
      "('to', 'accelerate', 'the', 'rate', 'of', 'inflation')\n",
      "\n",
      "52570\n",
      "('to', 'accelerate', 'the', 'depoliticisation', 'of', 'our')\n",
      "\n",
      "52571\n",
      "('accelerate', 'the', 'return', 'to', 'vaginal', 'tautness')\n",
      "\n",
      "52573\n",
      "('the', 'accelerate', 'signal')\n",
      "\n",
      "52574\n",
      "('him', 'accelerate', 'very', ',', 'very', 'hard')\n",
      "\n",
      "52576\n",
      "('would', 'accelerate', 'global', 'warming', 'significantly')\n",
      "\n",
      "52577\n",
      "('accelerate', 'to', 'a', 'speed', 'the', 'skua', 'can', 'not', 'match')\n",
      "\n",
      "52578\n",
      "('accelerate', 'thyroglobulin', 'proteolysis')\n",
      "\n",
      "52579\n",
      "('accelerate', 'the', 'spread', 'of', 'resistant', 'strains')\n",
      "\n",
      "52580\n",
      "('to', 'accelerate', ',', 'with', 'investment', 'in')\n",
      "\n",
      "52582\n",
      "(',', 'the', 'engine', 'accelerate', 'and', 'the', 'tyres', 'slide')\n",
      "\n",
      "52583\n",
      "('to', 'accelerate', 'the', 'ions', 'in', 'the', 'beams')\n",
      "\n",
      "52584\n",
      "('to', 'accelerate', 'to', 'a', 'speed', 'close')\n",
      "\n",
      "52585\n",
      "('to', 'accelerate', 'in', 'the', 'mid', '1960s')\n",
      "\n",
      "52586\n",
      "('accelerate', 'and', 'decelerate')\n",
      "\n",
      "52587\n",
      "('to', 'accelerate', 'at', 'certain', 'positions', 'around', 'the', 'hemisphere')\n",
      "\n",
      "52588\n",
      "('accelerate', 'corrosion', 'of', 'metals', 'and')\n",
      "\n",
      "52589\n",
      "('to', 'accelerate', 'their', 'planned', 'programmes')\n",
      "\n",
      "52590\n",
      "('to', 'accelerate', 'any', 'changes', 'occurring', 'at', '‘', 'normal', '’', 'conditions')\n",
      "\n",
      "52591\n",
      "('to', 'accelerate', 'the', 'structural', 'reform', 'of')\n",
      "\n",
      "52593\n",
      "('to', 'accelerate', 'the', 'shuffle', 'off', 'this')\n",
      "\n",
      "52594\n",
      "('Maggie', \"'s\", 'heart', 'accelerate', 'wildly', 'and', 'her', 'cheeks')\n",
      "\n",
      "52595\n",
      "('accelerate', 'their', 'already', 'steady', 'selling', 'of', 'shares')\n",
      "\n",
      "52598\n",
      "('accelerate', 'those', 'payments', 'due', 'from', 'the', 'company')\n",
      "\n",
      "52599\n",
      "('to', 'accelerate', 'and', 'deepen', 'contacts', 'with', 'the', 'West')\n",
      "\n",
      "52600\n",
      "('accelerate', 'podzolisation', 'which', 'in', 'turn')\n",
      "\n",
      "52601\n",
      "('when', 'it', 'should', 'accelerate')\n",
      "\n",
      "52604\n",
      "('to', 'accelerate', 'and')\n",
      "\n",
      "52605\n",
      "('accelerate', 'quite', 'as', 'hard', 'as', 'you', 'might', 'expect')\n",
      "\n",
      "52606\n",
      "('accelerate', 'the', 'lack', 'of', 'insulin')\n",
      "\n",
      "52607\n",
      "('to', 'accelerate', 'the', 'development', 'of', 'certain', 'leukaemias')\n",
      "\n",
      "52608\n",
      "('the', 'hospitalization', 'itself', 'can', 'accelerate', 'confusion', 'and', 'frailty', 'among')\n",
      "\n",
      "52609\n",
      "('Information', 'Consulting', 'could', 'accelerate', 'the', 'process')\n",
      "\n",
      "52610\n",
      "('to', 'accelerate', 'earthquake', 'clean-up', 'efforts', 'and')\n",
      "\n",
      "52611\n",
      "('it', 'to', 'accelerate', 'in', 'that', 'direction')\n",
      "\n",
      "52612\n",
      "('to', 'accelerate', 'the', 'process', 'by', 'which')\n",
      "\n",
      "52613\n",
      "('to', 'accelerate', 'the', 'decision', 'on', 'who')\n",
      "\n",
      "52614\n",
      "('not', 'only', 'to', 'accelerate', 'privatisation', 'but', 'also', 'to')\n",
      "\n",
      "52615\n",
      "('a', 'matter', 'of', 'policy', ',', 'accelerate', 'their', 'loan', 'redemptions', 'so')\n",
      "\n",
      "52616\n",
      "('only', 'to', 'accelerate', 'changes', 'at', '‘', 'normal')\n",
      "\n",
      "52617\n",
      "('accelerate', 'differentiation', 'of', 'the', 'peasantry')\n",
      "\n",
      "52618\n",
      "('to', 'accelerate', 'development')\n",
      "\n",
      "52619\n",
      "('to', 'accelerate', 'the', 'market', 'penetration', 'of')\n",
      "\n",
      "52620\n",
      "('to', 'accelerate', 'these', 'efforts')\n",
      "\n",
      "52621\n",
      "('that', 'the', 'new', 'recruitment', 'would', 'accelerate', 'the', 'process')\n",
      "\n",
      "52622\n",
      "('then', 'to', 'accelerate', 'rapidly', 'the', 'Phillips', 'curve')\n",
      "\n",
      "52623\n",
      "('the', 'Gallup', 'survey', 'will', 'accelerate', 'the', 'progress', 'of', 'the')\n",
      "\n",
      "52627\n",
      "('to', 'accelerate')\n",
      "\n",
      "52628\n",
      "('to', 'accelerate', 'Charlton', \"'s\", 'slide', 'down', 'the', 'table', 'and')\n",
      "\n",
      "52631\n",
      "('accelerate', 'the', 'development', 'and', 'propagation')\n",
      "\n",
      "52632\n",
      "('that', 'accelerate', 'the', 'degeneration', 'by', 'annulling')\n",
      "\n",
      "52633\n",
      "('accelerate', 'changes')\n",
      "\n",
      "52634\n",
      "('how', 'hard', 'we', 'accelerate')\n",
      "\n",
      "52635\n",
      "('while', 'growth', 'will', 'accelerate')\n",
      "\n",
      "52636\n",
      "('to', 'accelerate', 'and', 'interpret')\n",
      "\n",
      "52637\n",
      "('to', 'accelerate', 'the', 'economic', 'reforms')\n",
      "\n",
      "52638\n",
      "('to', 'accelerate', 'global', 'warming')\n",
      "\n",
      "52639\n",
      "('to', 'accelerate', 'the', 'load', 'inertia', 'to')\n",
      "\n",
      "52643\n",
      "('to', 'accelerate', 'changes', 'occurring', 'at', 'market', 'conditions')\n",
      "\n",
      "52646\n",
      "('accelerate', 'for', 'each', 'one')\n",
      "\n",
      "52647\n",
      "('To', 'accelerate', 'their', 'move', 'toward', 'the')\n",
      "\n",
      "52649\n",
      "('accelerate', 'the', 'expansion', 'of', 'the', 'Internet')\n",
      "\n",
      "52651\n",
      "('to', 'accelerate', 'the', 'problem', 'solving', 'process')\n",
      "\n",
      "52652\n",
      "('to', 'accelerate', 'this', 'process', 'with', 'a', 'host', 'of', 'infrastructure', 'projects')\n",
      "\n",
      "52653\n",
      "('the', 'System', 'can', 'accelerate', 'rapidly')\n",
      "\n",
      "52655\n",
      "('at', 'least', 'accelerate')\n",
      "\n",
      "52656\n",
      "('sunbeds', 'accelerate')\n",
      "\n",
      "52657\n",
      "('to', 'accelerate', 'against', 'miserly', 'seam', 'bowling')\n",
      "\n",
      "52658\n",
      "('to', 'accelerate', 'the', 'load', 'inertia')\n",
      "\n",
      "52659\n",
      "('accelerate', 'moves', 'towards', 'quality', 'labelling', 'and', 'higher', 'standards')\n",
      "\n",
      "52660\n",
      "('to', 'accelerate', 'the', 'coming', 'of', 'reform')\n",
      "\n",
      "52662\n",
      "('if', 'he', 'does', 'not', 'accelerate', 'the', 'introduction', 'of', 'democracy')\n",
      "\n",
      "52663\n",
      "('may', 'accelerate', 'atherosclerosis')\n",
      "\n",
      "52665\n",
      "('to', 'accelerate', 'rump-Yugoslavia', \"'s\", 'descent', 'from')\n",
      "\n",
      "52666\n",
      "('to', '``', 'accelerate', 'the', 'pace', 'of', 'reform')\n",
      "\n",
      "52667\n",
      "('as', 'this', 'will', 'accelerate', 'their', 'installation')\n",
      "\n",
      "52668\n",
      "('to', 'accelerate', 'strongly', 'to', '140', 'mph')\n",
      "\n",
      "52669\n",
      "('to', 'accelerate', 'with', 'the', 'more', 'sex', 'you', 'have')\n",
      "\n",
      "52670\n",
      "('to', 'accelerate', 'in', 'the', 'laboratory')\n",
      "\n",
      "52671\n",
      "('as', 'you', 'accelerate')\n",
      "\n",
      "52672\n",
      "('to', 'accelerate', 'right', 'from', 'the', 'commencement', 'of', 'the', 'downswing')\n",
      "\n",
      "52673\n",
      "('to', 'accelerate', 'particles', 'to', 'the', 'grand', 'unification', 'energy')\n",
      "\n",
      "52674\n",
      "('to', 'accelerate', 'Daimler', \"'s\", 'hesitant', 'steps')\n",
      "\n",
      "52675\n",
      "('accelerate', 'or', 'slow', 'down', 'dredging', 'programmes')\n",
      "\n",
      "52678\n",
      "('to', 'accelerate', 'testing')\n",
      "\n",
      "52679\n",
      "('as', 'we', 'accelerate')\n",
      "\n",
      "52680\n",
      "('that', 'the', 'Community', 'will', 'deliberately', 'accelerate', 'progress', 'to', 'supra-national', 'monetary')\n",
      "\n",
      "52682\n",
      "('accelerate', 'the', 'change-over')\n",
      "\n",
      "52683\n",
      "('accelerate', 'as', 'fast', 'as', 'feared')\n",
      "\n",
      "52686\n",
      "('to', 'accelerate', 'to', 'full', 'speed')\n",
      "\n",
      "52687\n",
      "('us', 'accelerate')\n",
      "\n",
      "52688\n",
      "('this', 'decline', 'accelerate')\n",
      "\n",
      "52690\n",
      "('to', 'accelerate', 'this', 'programme', ',', 'as')\n",
      "\n",
      "52691\n",
      "('that', 'Conservative', 'policies', 'would', 'accelerate', 'economic', 'recovery')\n",
      "\n",
      "52692\n",
      "('to', 'accelerate', 'rather', 'than', 'slacken', 'after', '1905')\n",
      "\n",
      "52693\n",
      "('accelerate', 'a', 'moving', 'ion', 'into')\n",
      "\n",
      "52694\n",
      "('will', 'likely', 'accelerate')\n",
      "\n",
      "52695\n",
      "('to', 'accelerate', 'the', 'detoxification', 'process', '(', '79', 'per', 'cent', ')')\n",
      "\n",
      "52696\n",
      "('that', 'will', 'accelerate', 'a', 'building', 'at', '40')\n",
      "\n",
      "52697\n",
      "('Kaiser', \"'s\", 'decision', 'will', 'accelerate', 'a', 'race', 'by', 'insurers')\n",
      "\n",
      "52698\n",
      "('to', 'accelerate', 'its', 'five-year', 'timetable', 'for')\n",
      "\n",
      "52700\n",
      "('accelerate', 'related', 'developments', 'within', 'schools')\n",
      "\n",
      "52701\n",
      "('to', 'accelerate', 'transmutations')\n",
      "\n",
      "52703\n",
      "('to', 'accelerate', 'the', 'measures', 'already', 'under')\n",
      "\n",
      "52704\n",
      "('to', 'accelerate', 'the', 'development', 'of', 'this')\n",
      "\n",
      "52705\n",
      "('to', 'accelerate', 'declines', 'in', 'crime')\n",
      "\n",
      "52706\n",
      "('accelerate', 'our', 'learning', 'of', 'new')\n",
      "\n",
      "52707\n",
      "('to', 'accelerate', 'economic', 'integration', 'among', 'member', 'states')\n",
      "\n",
      "52708\n",
      "('to', 'accelerate', 'the', 'eradication', 'of', 'ozone', 'depleting', 'substances')\n",
      "\n",
      "52709\n",
      "('a', 'man', 'of', 'influence', 'would', 'accelerate', 'their', 'own')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, item in tqdm(repl_df.orig[repl_df.word == word].iteritems(), \n",
    "                     total = len(repl_df[repl_df.word == word])):\n",
    "    if repl_df.at[idx, 'repl'] != None:\n",
    "        continue\n",
    "    print(idx)\n",
    "    print(item)\n",
    "    #print(nltk.pos_tag(item))\n",
    "    print()\n",
    "    #if idx in do_these:\n",
    "    #    repl_df.at[idx, 'repl'] = replace(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_df.to_pickle('data/lexical_repl/repl_df-tbd.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
